[{"content":"Redis Redis持久化机制 redis提供了三种持久化方式：\nRDB： 原理：定期生成内存数据快照，保存为二进制文件。 Redis 提供了两个命令来生成RDB文件，分别是save和bgsave。 save ：在主线程生成RDB文件，如果写入文件时间过长，会阻塞主线程。 bgsave：会创建一个子进程来生成RDB文件，避免主进程阻塞。 AOF： 原理：记录所有写的操作命令（如：SET、DEL）以追加方式写入文件。（先执行操作，后追加写入；有丢失风险） Redis提供了3种写回硬盘的策略。在Redis.conf配置文件中的appendfsync配置项可以有以下3种参数可填： Always（总是）：每次写操作命令执行完后，同步将AOF日志数据写回硬盘； Everysec（每秒）：先将命令写入到AOF文件的内核缓冲区，然后每隔一秒将缓冲区里的内容写回到硬盘； No：不由Redis控制回写时机，先将命令写入到AOF文件的内核缓冲区，再由操作系统决定何时将缓冲区内容写回硬盘。 当AOF文件的大小超过所设定的阈值后，Redis就会启用AOF重写机制，来压缩AOF文件。 混合模式： RDB优点是数据恢复速度快，但是快照的频率不好把握。频率太低，丢失的数据就会比较多，频率太高，就会影响性能。 AOF优点是丢失数据少，但是数据恢复不快。 Redis 4.0 提出了混合使用AOF日志和内存快照； 混合持久化工作在AOF日志重写过程，当开启了混合持久化时，在AOF重写日志时，fork出来的重写子进程会先将与主线程共享的内存数据以RDB方式写入到AOF文件，然后主线程处理的操作命令会被记录在重写缓冲区里，重写缓冲区里的增量命令会以AOF方式写入到AOF文件，写入完成后通知主进程将新的含有RDB格式和AOF格式的AOF文件替换旧的AOF文件。也就是说，使用了混合持久化，AOF文件的前半部分是RDB格式的全量数据，后半部分是AOF格式的增量数据。 Redis线程模型 Redis是单线程吗？ Redis单线程指的是[接收请求\u0026ndash;\u0026gt;解析请求\u0026ndash;\u0026gt;进行数据读写操作\u0026ndash;\u0026gt;发送数据给客户端]这个过程是由一个主线程完成的。\n但是，Redis程序并不是单线程的：\n2.6版本，会启动两个后台线程分别处理关闭文件、AOF刷盘； 4.0版本后，新增了lazyfree线程，用来异步释放Redis内存；unlinkkey/flushdbasync/flushallasync等命令，会把这些删除操作交给后台线程来执行，不会导致主线程卡顿。 因此，当我们要删除一个大key的时候，不要使用del命令删除，因为del是在主线程处理的，这样会导致Redis主线程卡顿，因此我们应该使用unlink命令来异步删除大key。\n后台线程相当于一个消费者，生产者把耗时任务丢到任务队列中，消费者（BIO）不停轮询这个队列，拿出任务就去执行对应的方法即可。\nRedis6.0之前的单线程模式(网络I/O与执行命令)如下图（没理解）：\n在Redis6.0版本之后，也采用了多个I/O线程来处理网络请求，这是因为随着网络硬件的性能提升，Redis的性能瓶颈有时会出现在网络I/O的处理上。\nRedis采用单线程(网络I/O与执行命令)为什么能这么快？ Redis线程吞吐量能达到10w/每秒。\n之所以采用Redis单线程(网络I/O与执行命令)那么快有以下原因：\n大部分操作都在内存中完成。 单线程模型可以避免多线程竞争。 采用I/O多路复用机制，多路复用机制是指一个线程处理多个IO流，就是我们经常听到的select/epoll机制。简单来说，在Redis只运行单线程的情况下，该机制允许内核中，同时存在多个监听Socket和已连接Socket。内核会一直监听这些Socket上的连接请求或数据请求。一旦有请求到达，就会交给Redis线程处理，这就实现了一个Redis线程处理多个IO流的效果。 Redis集群 一个高可用的Redis服务，一定要从Redis的多服务节点来考虑，比如Redis的主从复制、哨兵模式、切片集群。\n主从复制： 主从复制是Redis高可用的最基础保证。实现方案就是将一台Redis服务器，同步数据到多台从服务器上，且主从服务器采用读写分离的方式。\n主服务可以进行读写操作，从服务器一般为只读，并接收主服务器同步过来写操作命令，然后执行。所以，修改操作只在主服务器上进行，然后同步给从服务器，使得主从服务器数据一致。\n但是！主从服务器之间的命令复制操作是异步的。所以无法保证强一致性，数据不一致是难以避免的。\n哨兵模式： 哨兵模式(RedisSentinel）监控主从服务器，当主从服务器出现宕机时，提供主从节点故障转移功能。\n哨兵以集群方式部署，最少部署三台，哨兵定时Ping服务器，若服务器未在规定时间内响应则判断为下线。\n详细看哨兵模式。\n切片集群模式： 当Redis缓存数据量大到一台服务器无法缓存时，就需要使用Redis切片集群(RedisCluster)方案。将数据分布在不同服务器上，降低系统对单主节点的依赖。\nRedis Cluster方案采用哈希槽(HashSlot)来处理数据和节点之间的映射关系。在RedisCluster方案中，一个切片共有16384个哈希槽，哈希槽类似于数据分区，每个键值对都会根据他的key被映射到一个哈希槽中，分为两步：\n根据Key按照CRC16算法计算一个16bit的值，在对16384取模，得到一个0~16384范围内的模数，每个数代表一个相应的编号的哈希槽。 将哈希槽按平均分配或者手动分配映射到具体Redis节点上。 集群脑裂导致数据丢失怎么办？ 什么是脑裂？ 如果主节点网络出现问题，与所有从节点失联，但主节点与客户端连接是正常的，客户端依旧向主节点缓存数据。这时，哨兵也发现主节点挂了(实际没挂，只是网络出问题了)，于是在从节点中选出新的主节点，此时，集群就有两个主节点了。\u0026mdash;\u0026mdash;\u0026ndash;脑裂出现\n然后，旧主节点A网络突然好了，哨兵会将旧主节点A点降级为从节点，节点A会向新主节点请求同步数据，因为第一次同步是全量同步，所以节点A会清空自己本地的所有数据，失联期间客户端缓存的数据将会丢失。也就是集群脑裂导致数据丢失问题。\n解决方案： 当主节点发现从节点下线或者通信超时时那么禁止主节点写入数据。 在Redis配置文件中有两个参数： min-slavers-to-write x:主节点必须有x个从节点连接，小于x主节点禁止写入。 min-slavers-max-lag-x:主从数据复制不能超过x秒，超过x秒主节点禁止写入。 将这两个配置组合使用可解决数据丢失。 Redis过期删除与内存淘汰 过期删除 当我们对一个Key设置过期时间，redis会将该Key带上过期时间存在过期字典中（expiresDict）。\n我们查询一个key时，会先查询过期字典中是否存在该key：\n不存在：读取该key； 存在：检查该key过期时间与当前系统时间进行对比，若大于系统时间就没有过期，否则判定该key过期； redis过期删除策略为惰性删除+定期删除搭配使用；\n惰性删除： 不主动删除过期key，每次数据库访问key时，都检测key是否过期，过期则删除key。 优点：只有每次访问时才检测是否有过期key，节省系统资源； 缺点：若过期key一直不被访问，会一直占用内存空间； 定期删除： 每隔一段时间，随机从数据库中取出一定量的key检查，并删除其中过期key。 流程： 从过期字典中随机取20个key； 检查key是否过期，删除其中过期key； 若过期key数量大于5个(25%)，则重复1步骤，若小于5个，则停止删除。 为了保证redis删除不会出现循环过度，导致线程卡死，为此增加了循环时间上线默认不会超过25ms； 优点：限制删除执行时间与频率，减少删除操作对cpu的影响，同时也能删除一部分过期key，减少对空间的无效占用； 缺点：若删除太频繁，对cpu不太友好，若频率太低，与惰性删除效果差不多； 所以Redis采用惰性+定期在合理使用cpu与避免内存浪费中取得平衡。 持久化时对过期键的处理 RDB： 快照文件生成阶段：会对key进行过期检查，过期key不会被保存到RDB文件中； 快照文件写入阶段(会分为主服务器与从服务器两种情况): 主服务器：会对key进行检查，过期key不会被写入数据库中； 从服务器：所有数据都加载(包括过期)，但主从服务器数据同步时会将数据清空，所以不会造成影响。 AOF： AOF写入阶段：若在持久化时该过期key没被删除，AOF会保存此key，当过期key被删除后，redis会向AOF显式的追加一条DEL删除该key； AOF重写阶段：会检查过期key，过期key不会被写入； Redis内存淘汰策略： 当redis内存达到某个阈值，就会触发内存淘汰策略，这个阈值就是我们设置的最大运行内存，此值在redis配置文件中的配置项为maxmemory；\n内存淘汰策略为8种：\n不淘汰： noeviction：不淘汰，返回错误； 进行数据淘汰策略： 设置了过期时间key范围内淘汰： volatile-random：随机淘汰； volatile-ttl：优先淘汰过期时间更早的key； volatile-lru：（3.0默认淘汰策略）淘汰最久未使用的； volatile-lfu：（4.0新增）淘汰使用最少的； 所有数据中淘汰： allkeys-random：随机淘汰; allkeys-lru:最久未使用； allkeys-lfu:（4.0新增）使用最少； redis缓存设计 为了保证redis数据与与数据种的数据一致性，会给redis里的数据设置过期时间，当缓存数据过期后，用户访问不到缓存中的数据就会直接访问数据库中的数据，并更新缓存中的数据。\n如何避免缓存雪崩、缓存击穿、缓存穿透？ 缓存雪崩： 当大量的数据在同一时间过期，若此时有大量用户请求，请求直接全部访问到数据库导致服务器宕机，从而造成一系列连锁反应导致系统崩溃，这就是雪崩问题。\n解决方案：\n将缓存失效时间随机打散：在原有失效时间上增加一个随机值(如1~10分钟)，降低集体失效的概率； 不设置过期时间：通过后台服务来更新数据，避免失效； 缓存击穿： 业务中通常有几个数据被频繁访问，比如秒杀活动。若某个热点数据过期了，此时大量请求直接访问数据库，数据库被高并发请求冲垮，这就缓存穿透问题。\n解决方案：\n互斥锁方案（redis中使用setNX方法设置一个状态位，表示锁定状态），保证同一时间只有一个业务线程请求; 不设置过期时间，或是在key过期前提前通知后台更新缓存； 缓存穿透： 当访问数据即不在缓存中也不在数据库中，导致缓存无法命中，数据库也不存在。当有大量这样的请求来到数据库中，导致数据库压力剧增，这就是缓存穿透问题。\n解决方案：\n非法请求限制：在API接口处判断请求参数是否合理，是否包含非法值等； 设置空值或默认值：后续请求就可以从缓存中读取到空值或者默认值； 使用布隆过滤器：将数据写入缓存时，使用布隆过滤器做个标记，当请求来到时确认缓存失效后，通过布隆过滤器快速判断数据是否存在过，若不存在则不访问数据库； 如何保证数据库一致性 在更新数据库数据时，为保证数据一致性，需要将缓存中的数据更新，否则用户会一直访问缓存中的旧数据。在更新数据库数据与缓存数据时，无论先更新数据库，后更新缓存；还是先更新缓存，后更新数据库；在并发下都会造成数据不一致。所以redis常用缓存更新策略为旁路缓存策略，即先更新数据库操作，后删除缓存，等到用户读取数据时再写入缓存。\n旁路缓存策略（CacheAside策略） 该策略可细分为读策略与写策略。\n写策略步骤：先更新数据库，再删除缓存； 读策略步骤：读取数据若命中缓存则直接返回，未命中缓存则更新缓存数据并返回数据； 注意：写策略顺序不能变(会有并发安全)，且先更新数据库，再删除缓存一样有并发安全;但概率并不高，因为缓存删除速度远快于数据库写入速度。\n适合场景：旁路缓存适合读多写少的场景，因为如果频繁写入，缓存中的数据会被频繁的清理，对缓存命中率有一些影响。\n","date":"2025-07-04T17:19:54+08:00","permalink":"http://localhost:1313/p/myredis/","title":"MyRedis"},{"content":"Java笔记 集合框架 Collection集合体系特点 List(接口)：添加元素有序、可重复、有索引 ArrayList(实现类)： 基于数组实现 查询快，删除/添加慢（需移动元素） LinkedList(实现类)： 基于双链表实现 查询慢，增删快，首尾操作极快 新增了许多首尾操作方法 Set(接口)：无序、不可重复、无索引 HashSet(实现类)： 无序、不可重复、无索引 JDK8前：数组+链表，JDK8后：数组+链表+红黑树 可重写hashCode和equals保证自定义对象去重 LinkedHashSet(实现类)： 有序、不可重复、无索引 底层数组+链表+红黑树+双链表机制 占用内存大，CRUD性能好 TreeSet(实现类)： 默认升序排序、不可重复、无索引 底层红黑树 自定义类型需实现Comparable或传Comparator 遍历集合 迭代器 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 //1.从集合对象中获取迭代器对象 Collection\u0026lt;String\u0026gt;C=newArrayList\u0026lt;\u0026gt;(); c.add(\u0026#34;赵敏\u0026#34;); c.add(\u0026#34;小昭\u0026#34;); c.add(\u0026#34;素素\u0026#34;); c.add(\u0026#34;灭绝\u0026#34;); //手动遍历 Iterator\u0026lt;String\u0026gt; it = c.iterator(); System.out.println(it.next()); System.out.println(it.next()); System.out.println(it.next()); System.out.println(it.next()); //循环结合迭代器 while(it.hashNext()){ String ele = it.next(); System.out.println(ele); } 增强for循环 1 2 3 for(String ele : c){ System.out.println(ele); } Lambda表达式 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 //原始代码 c.forEach(new Consumer\u0026lt;String\u0026gt;()){ @Override public void accept(String s){ System.out.println(s); } } //可简化为↓ c.forEach((String s){ System.out.println(s); }); //只有一个参数小括号类型可省略且循环体只有一条语句大括号可省略↓ c.forEach(s -\u0026gt; System.out.println(s)); //最终可省略为↓ c.forEach(System.out::println); 集合并发修改异常 使用迭代器遍历集合同时删除元素会抛出异常 解决方法： 用迭代器自己的remove方法删除 for循环倒序遍历删除，或正序遍历时删除后i\u0026ndash; Map集合体系 Map(接口) HashMap(实现类)： 无序、不重复、无索引 JDK8前：数组+链表，JDK8后：数组+链表+红黑树 可重写hashCode和equals保证自定义对象去重 LinkedHashMap(实现类)： 有序、不可重复、无索引 底层数组+链表+红黑树+双链表机制 占用内存大，CRUD性能好 TreeMap(实现类)： 默认升序排序、不可重复、无索引 底层红黑树 自定义类型需实现Comparable或传Comparator 遍历Map集合 键找值： 用keySet获取所有键，遍历Set用get方法取值 键值对： 用entrySet获取Set\u0026lt;Map.Entry\u0026lt;K,V\u0026raquo;，遍历Entry用getKey/getValue Lambda表达式： 1 map.forEach((k, v) -\u0026gt; System.out.println(k + \u0026#34;:\u0026#34; + v)); Stream流 JDK8新增API(java.util.stream.*)用于操作集合或数组 优势：结合Lambda，代码简洁、可读性好 常用操作 ​中间操作​​： filter(Predicate)：过滤 map(Function)：映射转换 distinct()：去重 sorted()：排序 limit(long)：限制数量 skip(long)：跳过元素 终端操作​​： forEach(Consumer)：遍历 count()：计数 collect(Collector)：收集 reduce()：归约 anyMatch()/allMatch()/noneMatch()：匹配检查 findFirst()/findAny()：查找 static静态修饰符 可修饰变量、方法、内部类 静态变量/方法可通过类名访问，变量存储在静态区 静态方法不能直接访问非静态变量 静态内部类可直接实例化 锁 Java锁分为两类： Synchronized同步锁 ​​锁升级过程​​： 无锁 -\u0026gt; 偏向锁 -\u0026gt; 轻量级锁 -\u0026gt; 重量级锁 JDK6后引入锁消除、锁粗化等优化 使用方式​​： 同步代码块：synchronized(obj) {\u0026hellip;} 同步方法：public synchronized void method() {\u0026hellip;} 静态同步方法：锁的是类对象 JUC包下各种锁（如ReentrantLock可重入锁） ReentrantLock 特点： 可重入 可中断 公平/非公平可选 可设置超时 ReentrantLock基本用法 1 2 3 4 5 6 7 Lock lock = new ReentrantLock(); lock.lock(); try { // 临界区代码 } finally { lock.unlock(); } 特性 Synchronized ReentrantLock 实现方式 JVM层面 JDK层面 锁获取 自动 手动 可中断 不支持 支持 公平锁 非公平 可配置 条件队列 单一 多个Condition 性能 JDK6后优化良好 高竞争时更优 ThreadLocal 线程局部变量，为每个线程提供独立副本 解决多线程共享变量的数据竞争，无需加锁 可用于方法调用链中传递上下文信息 局部变量仅用于单方法，ThreadLocal可在单线程多方法间共享 局部变量线程安全（栈帧独立），但引用共享对象时需注意 内存泄漏问题： ThreadLocal对象为弱引用，value为强引用，若Thread未终止，Entry会一直存在 示例： 1 2 3 ThreadLocal\u0026lt;String\u0026gt; tl = new ThreadLocal\u0026lt;\u0026gt;(); tl.set(\u0026#34;value\u0026#34;); tl = null; // ThreadLocal对象失去强引用，Entry.key=null但value还在 CAS 什么是CAS？\nCAS(Compare-And-Swap)是一种无锁的原子操作机制，它包含三个操作数：内存位置(V)、预期原值(A)和新值(B)。当且仅当V的值等于A时，CAS才会将V的值更新为B，否则不做任何操作。\nCAS原理\n​​比较并交换​​：比较当前内存值与预期值，如果相同则更新为新值 ​​原子性​​：整个操作是一个不可分割的原子操作 ​​乐观锁​​：假设没有冲突，失败则重试\n常用原子类\nAtomicInteger/AtomicLong：整型原子类 AtomicBoolean：布尔型原子类 AtomicReference：引用类型原子类 AtomicIntegerArray/AtomicLongArray：数组原子类\nCAS优缺点\n优点: 非阻塞，线程无需挂起 避免锁带来的上下文切换开销 适合低竞争场景，性能高 缺点: ABA问题​​：值从A变B又变回A，CAS会认为没变化 解决方案：使用版本号（AtomicStampedReference）循环时间长开销大​​竞争激烈时可能长时间自旋 只能保证一个变量的原子性，​​多个变量需额外处理 CAS应用场景\n计数器（如AtomicInteger） 乐观锁实现 无锁数据结构（如ConcurrentHashMap的部分实现） ","date":"2025-03-11T00:00:00Z","image":"http://localhost:1313/p/java%E7%AC%94%E8%AE%B0/bg2_hu_86c750a017f32df0.png","permalink":"http://localhost:1313/p/java%E7%AC%94%E8%AE%B0/","title":"Java笔记"},{"content":"弹幕视频网站笔记 Maven 多模块项目的 POM 文件配置详解 这个文件是一个 Maven 的 POM (Project Object Model) 文件，它是 Maven 项目的核心配置文件，用于定义项目的结构、依赖关系、构建配置等信息。下面是对这个文件中各个部分的详细解释：\n1.基本配置 1 2 3 4 5 6 \u0026lt;project xmlns=\u0026#34;http://maven.apache.org/POM/4.0.0\u0026#34; ...\u0026gt; \u0026lt;modelVersion\u0026gt;4.0.0\u0026lt;/modelVersion\u0026gt; \u0026lt;groupId\u0026gt;com.easylive\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;easylive\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.0\u0026lt;/version\u0026gt; \u0026lt;packaging\u0026gt;pom\u0026lt;/packaging\u0026gt; • modelVersion: 指定 POM 模型的版本（固定为 4.0.0）。\n• groupId: 项目的组织标识（通常是公司或组织的域名反转，如 com.easylive）。\n• artifactId: 项目的唯一标识符（如 easylive）。\n• version: 项目的版本号（如 1.0）。\n• packaging: 项目的打包类型，这里是 pom，表示这是一个多模块项目的父 POM。\n2. 父项目继承 1 2 3 4 5 6 \u0026lt;parent\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-parent\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.7.18\u0026lt;/version\u0026gt; \u0026lt;relativePath/\u0026gt; \u0026lt;/parent\u0026gt; 继承 Spring Boot 的父 POM，提供了默认的依赖管理、插件配置等。 relativePath 为空表示从本地仓库或远程仓库查找父 POM。 3. 模块定义 1 2 3 4 5 \u0026lt;modules\u0026gt; \u0026lt;module\u0026gt;easylive-common\u0026lt;/module\u0026gt; \u0026lt;module\u0026gt;easylive-admin\u0026lt;/module\u0026gt; \u0026lt;module\u0026gt;easylive-web\u0026lt;/module\u0026gt; \u0026lt;/modules\u0026gt; 定义子模块（多模块项目）： easylive-common: 公共模块（如工具类、通用配置）。 easylive-admin: 后台管理模块。 easylive-web: 前端或 API 模块。 4. 全局属性 1 2 3 4 5 6 7 8 9 10 \u0026lt;properties\u0026gt; \u0026lt;project.build.sourceEncoding\u0026gt;UTF-8\u0026lt;/project.build.sourceEncoding\u0026gt; \u0026lt;maven.compiler.source\u0026gt;1.8\u0026lt;/maven.compiler.source\u0026gt; \u0026lt;maven.compiler.target\u0026gt;1.8\u0026lt;/maven.compiler.target\u0026gt; \u0026lt;skipTests\u0026gt;true\u0026lt;/skipTests\u0026gt; \u0026lt;!-- 依赖版本号 --\u0026gt; \u0026lt;springboot.version\u0026gt;2.7.18\u0026lt;/springboot.version\u0026gt; \u0026lt;mybatis.version\u0026gt;1.3.2\u0026lt;/mybatis.version\u0026gt; ... \u0026lt;/properties\u0026gt; 编码和 JDK 版本：指定源码编码为 UTF-8，编译使用 JDK 1.8。 跳过测试：skipTests=true 表示构建时跳过单元测试。 依赖版本号：集中管理所有依赖的版本号，便于统一升级。 5. 依赖管理 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 \u0026lt;dependencyManagement\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-web\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${springboot.version}\u0026lt;/version\u0026gt; \u0026lt;exclusions\u0026gt; \u0026lt;exclusion\u0026gt; \u0026lt;groupId\u0026gt;ch.qos.logback\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;logback-classic\u0026lt;/artifactId\u0026gt; \u0026lt;/exclusion\u0026gt; \u0026lt;/exclusions\u0026gt; \u0026lt;/dependency\u0026gt; ... \u0026lt;/dependencies\u0026gt; \u0026lt;/dependencyManagement\u0026gt; 作用：统一管理子模块的依赖版本，避免版本冲突。 特点： 子模块使用时无需指定版本号（继承父 POM 的版本）。 可以通过 \u0026lt;exclusions\u0026gt; 排除传递性依赖（如排除默认的 Logback 日志库）。 6. 关键依赖说明 Spring Boot Starter Web：提供 Web 开发支持（如 Spring MVC）。 MyBatis Starter：集成 MyBatis 和 Spring Boot。 MySQL Connector：MySQL 数据库驱动。 Logback：日志框架。 Lombok：简化 Java 代码（如自动生成 Getter/Setter）。 Fastjson：阿里巴巴的 JSON 处理库。 Apache Commons：常用工具库（如 commons-lang3、commons-io）。 Elasticsearch：全文搜索引擎支持。 Easy Captcha：验证码生成库。 7. 文件的作用 多模块管理：通过 \u0026lt;modules\u0026gt; 定义子模块，统一构建。 依赖版本控制：通过 \u0026lt;dependencyManagement\u0026gt; 集中管理依赖版本。 继承 Spring Boot 默认配置：简化 Spring Boot 项目的配置（如插件、默认依赖）。 统一构建规范：指定 JDK 版本、编码等全局配置。 补充说明 子模块的 POM 文件会继承父 POM 的配置，无需重复定义版本号。 实际依赖需要子模块显式声明（父 POM 仅管理版本）。 如果某个子模块需要特殊配置，可以在其 POM 中覆盖父 POM 的设置。 这个文件是项目的核心配置，确保了依赖一致性和构建标准化。常用依赖库详细说明：\n1. commons-io（Apache Commons IO） 作用：提供更强大、易用的 I/O（输入/输出）操作工具类。\n典型用途：\n文件/目录的复制、删除、移动（FileUtils）。 流（Stream）的高效读写（IOUtils）。 文件监控（如 FileAlterationMonitor）。 示例代码：\n1 2 3 4 5 import org.apache.commons.io.FileUtils; // 复制文件 FileUtils.copyFile(srcFile, destFile); // 读取文件内容为字符串 String content = FileUtils.readFileToString(file, \u0026#34;UTF-8\u0026#34;); 版本说明：\n当前 POM 中版本为 2.5（较旧，最新版为 2.15.1）。 2. commons-codec（Apache Commons Codec） 作用：提供常见的编码/解码工具，如 Base64、MD5、SHA 等。\n典型用途：\n加密哈希（DigestUtils.md5Hex()）。 Base64 编码/解码（Base64.encodeBase64String()）。 URL 编码/解码。 示例代码：\n1 2 3 import org.apache.commons.codec.digest.DigestUtils; // 生成 MD5 哈希 String md5Hash = DigestUtils.md5Hex(\u0026#34;HelloWorld\u0026#34;); 版本说明：\n当前 POM 中版本为 1.9（较旧，最新版为 1.16.1）。 3. commons-lang3（Apache Commons Lang3） 作用：扩展 Java 标准库的工具类，尤其是 java.lang 包的增强。\n典型用途：\n字符串处理（StringUtils.isEmpty()）。 数组/对象操作（ArrayUtils, ObjectUtils）。 日期格式化（DateUtils）。 随机数生成（RandomStringUtils）。 示例代码：\n1 2 3 import org.apache.commons.lang3.StringUtils; // 检查字符串是否为空（包括 null 和空字符串） boolean isEmpty = StringUtils.isEmpty(str); 版本说明：\n当前 POM 中版本为 3.4（较旧，最新版为 3.14.0）。 4. aspectjweaver（AspectJ 库） 作用：支持面向切面编程（AOP），用于解耦横切关注点（如日志、事务）。\n典型用途：\n配合 Spring AOP 实现方法拦截。 定义切面（@Aspect）、切入点（@Pointcut）、通知（@Before, @After 等）。 示例代码：\n1 2 3 4 5 6 7 8 9 10 import org.aspectj.lang.annotation.Aspect; import org.aspectj.lang.annotation.Before; @Aspect public class LoggingAspect { @Before(\u0026#34;execution(* com.example.service.*.*(..))\u0026#34;) public void logBefore() { System.out.println(\u0026#34;方法执行前记录日志\u0026#34;); } } 版本说明：\n当前 POM 中版本为 1.9.3（较旧，最新版为 1.9.20）。 为什么需要这些库？ 避免重复造轮子：提供现成的工具方法，减少手写通用代码。 标准化：Apache 和 Eclipse 维护的库，稳定性和性能有保障。 与 Spring 生态集成：如 aspectjweaver 是 Spring AOP 的底层依赖。 application.yml 文件作用与常见配置项详解 application.yml 文件是 Spring Boot 应用的核心配置文件，采用 YAML 格式，用于定义应用程序的各种配置参数。以下是各个配置项的详细说明：\n1. 服务器配置（server） 1 2 3 4 server: port: 7070 # 服务器端口号（默认8080，这里设为7070） servlet: context-path: /admin # 应用上下文路径（访问路径需加 `/admin`，如 `http://localhost:7070/admin`） port: 指定应用运行的端口号（默认 8080，这里改为 7070）。 context-path: 设置应用的根路径（如 /admin），所有请求都需要加上这个前缀。 2. 文件上传配置（spring.servlet.multipart） 1 2 3 4 5 spring: servlet: multipart: max-file-size: 10MB # 单个文件最大大小（默认1MB） max-request-size: 15MB # 整个请求的最大大小（默认10MB） max-file-size: 限制单个上传文件的大小（如 10MB）。 max-request-size: 限制整个 HTTP 请求（可能包含多个文件）的最大大小（如 15MB）。 3. 应用名称（spring.application.name） 1 2 3 spring: application: name: easylive-admin # 应用名称（用于服务发现、日志标记等） 用于标识当前应用（如微服务架构中的服务名）。 4. 数据库配置（spring.datasource） 1 2 3 4 5 6 7 8 9 10 11 12 13 14 spring: datasource: url: jdbc:mysql://127.0.0.1:3306/easylive?serverTimezone=GMT%2B8\u0026amp;useUnicode=true\u0026amp;characterEncoding=utf8\u0026amp;autoReconnect=true\u0026amp;allowMultiQueries=true\u0026amp;useSSL=false username: root # 数据库用户名 password: root # 数据库密码 driver-class-name: com.mysql.cj.jdbc.Driver # MySQL JDBC 驱动 hikari: # HikariCP 连接池配置 pool-name: HikariCPDatasource minimum-idle: 5 # 最小空闲连接数 maximum-pool-size: 10 # 最大连接数 idle-timeout: 180000 # 空闲连接超时时间（毫秒） max-lifetime: 1800000 # 连接最大存活时间（毫秒） connection-timeout: 30000 # 连接超时时间（毫秒） connection-test-query: SELECT 1 # 连接测试SQL url: MySQL 数据库连接地址，包含 serverTimezone、编码、自动重连等参数。 hikari: HikariCP 是 Spring Boot 默认的高性能数据库连接池，这里配置了连接池参数。 5. Redis 配置（spring.redis） 1 2 3 4 5 6 7 8 9 10 11 12 spring: redis: database: 0 # Redis 数据库索引（默认0） host: 127.0.0.1 # Redis 服务器地址 port: 6379 # Redis 端口 jedis: pool: max-active: 20 # 最大活跃连接数 max-wait: -1 # 最大等待时间（-1表示无限等待） max-idle: 10 # 最大空闲连接数 min-idle: 0 # 最小空闲连接数 timeout: 2000 # 连接超时时间（毫秒） 配置 Redis 连接信息，使用 Jedis 作为客户端。 6. MyBatis 配置（mybatis） 1 2 3 mybatis: configuration: map-underscore-to-camel-case: true # 数据库字段下划线转驼峰命名（如 `user_name` → `userName`） map-underscore-to-camel-case: 自动将数据库的 snake_case 字段名映射为 Java 的 camelCase 属性名。 7. 自定义配置（project、log、admin） 1 2 3 4 5 6 7 8 9 10 project: folder: D:/work-webser/myapps/easylive # 自定义项目文件存储路径 log: root: level: debug # 日志级别（debug、info、warn、error） admin: account: admin # 管理员账号 password: admin123 # 管理员密码 project.folder: 自定义文件存储路径（如上传的文件存放位置）。 log.root.level: 设置日志级别（debug 会打印更详细的日志）。 admin.account/password: 可能是用于后台管理的默认账号密码。 总结 application.yml 文件可以根据实际业务需求，灵活扩展和定制。常见配置还包括安全（security）、第三方服务（如短信、支付）、自定义参数等。通过集中管理这些配置，可以让 Spring Boot 项目更易于维护和部署。\nHikariCP 介绍 HikariCP 是目前 Java 生态中最快、最轻量级的高性能 JDBC 连接池，被 Spring Boot 2.x 及更高版本选为默认数据库连接池。它的名字来源于日语\u0026quot;光\u0026quot;（Hikari），意为\u0026quot;快速、高效\u0026quot;。\n1. 为什么选择 HikariCP？ 特性 说明 极高性能 比传统的 C3P0、Tomcat JDBC、DBCP 快很多 轻量级 代码精简（约 130KB），无额外依赖 零开销 优化了字节码，减少 JVM 垃圾回收压力 自动优化 智能调整连接池大小，避免资源浪费 健康检查 自动检测失效连接，避免应用因数据库问题崩溃 Spring Boot 默认 无需额外配置，开箱即用 2. HikariCP 核心配置参数 在你的 application.yml 中，HikariCP 的配置如下：\n1 2 3 4 5 6 7 8 9 10 11 spring: datasource: hikari: pool-name: HikariCPDatasource # 连接池名称（用于监控） minimum-idle: 5 # 最小空闲连接数（默认等于 maximum-pool-size） maximum-pool-size: 10 # 最大连接数（推荐值：CPU核心数 * 2 + 1） idle-timeout: 180000 # 空闲连接超时时间（毫秒，默认 60000） max-lifetime: 1800000 # 连接最大存活时间（毫秒，默认 1800000） auto-commit: true # 是否自动提交事务（默认 true） connection-timeout: 30000 # 连接超时时间（毫秒，默认 30000） connection-test-query: SELECT 1 # 连接测试 SQL（用于检查连接是否有效） 关键参数说明 参数 推荐值 作用 maximum-pool-size CPU核心数 * 2 + 1 避免连接数过多导致数据库性能下降 minimum-idle ≤ maximum-pool-size 保持的最小空闲连接数（默认等于最大值） idle-timeout 60000（1分钟） 空闲连接超过此时间会被回收 max-lifetime 1800000（30分钟） 连接最大存活时间，避免长时间占用 connection-timeout 30000（30秒） 获取连接的超时时间，超时抛异常 connection-test-query SELECT 1 检查连接是否有效的 SQL（MySQL 可用） 3. HikariCP 的优势 (1) 性能极致优化\n无锁并发：采用 ConcurrentBag 数据结构，减少锁竞争。 字节码优化：减少 JVM 方法调用开销。 智能缓存：复用 PreparedStatement，减少 SQL 解析时间。 (2) 自动维护连接健康\n心跳检测：定期检查连接是否有效，避免使用已断开的连接。 快速失败：如果数据库宕机，HikariCP 会立即抛出异常，而不是无限等待。 (3) 与 Spring Boot 完美集成\nSpring Boot 2.x 默认使用 HikariCP，只需配置 spring.datasource.hikari.* 即可。 4. 常见问题 Q1: HikariCP 和 Druid 哪个更好？\n对比项 HikariCP Druid 性能 ⚡ 更快 稍慢 功能 基础连接池 带监控、SQL 防火墙等 适用场景 高性能需求 需要监控和扩展功能 推荐选择：\n如果只需要高性能连接池 → HikariCP（默认推荐）。 如果需要监控、SQL 防注入 → Druid。 Q2: 如何监控 HikariCP？\n可以通过 Spring Boot Actuator 或 JMX 监控连接池状态：\n1 2 3 4 5 management: endpoints: web: exposure: include: health,metrics,hikaricp 访问 http://localhost:7070/actuator/hikaricp 查看连接池状态。\n5. 总结 HikariCP 是 Spring Boot 默认的高性能连接池，适合绝大多数场景。 关键配置：maximum-pool-size、minimum-idle、connection-timeout。 优势：速度快、轻量级、自动维护连接健康。 监控：可通过 Actuator 或 JMX 查看状态。 如果你的应用不需要 Druid 的额外功能，HikariCP 是最佳选择！\nJDBC 连接池（Connection Pool）详解 JDBC（Java Database Connectivity）是 Java 连接数据库的标准 API，而 JDBC 连接池是一种数据库连接管理技术，用于高效复用数据库连接，避免频繁创建和销毁连接带来的性能开销。\n1. 为什么需要连接池？ （1）直接 JDBC 的问题\n如果每次访问数据库都直接创建新连接：\n1 2 3 4 // 传统方式：每次操作数据库都新建连接（低效！） Connection conn = DriverManager.getConnection(url, username, password); // 执行SQL... conn.close(); // 关闭连接 缺点：\n频繁创建/关闭连接消耗大量资源（TCP 三次握手、数据库认证等）。 高并发时，数据库可能因连接数过多而崩溃。 （2）连接池的解决方案\n连接池预先创建一批连接，应用需要时直接从池中获取，用完归还（而不是关闭）：\n1 2 3 4 // 使用连接池（高效！） Connection conn = dataSource.getConnection(); // 从池中获取 // 执行SQL... conn.close(); // 实际是归还到连接池，并非真正关闭 优点：\n复用连接，避免重复创建的开销。 控制最大连接数，防止数据库过载。 支持健康检查，自动剔除失效连接。 2. 连接池的核心工作原理 （1）初始化阶段\n启动时创建一定数量的连接（如 minimum-idle=5），放入池中备用。 （2）运行阶段\n步骤 说明 应用请求连接 从池中分配一个空闲连接 执行 SQL 使用连接操作数据库 归还连接 调用 conn.close()，连接回到池中（未真正关闭） （3）连接管理\n空闲超时：长时间未使用的连接会被回收（idle-timeout）。 最大生命周期：连接超过存活时间（max-lifetime）会被销毁并新建。 健康检查：定期用 SELECT 1 测试连接是否有效。 3. 常见 JDBC 连接池对比 连接池 特点 适用场景 HikariCP 速度最快、轻量级 Spring Boot 默认，高性能需求 Druid 带监控、防 SQL 注入 需要监控和扩展功能 Tomcat JDBC 轻量级 嵌入式 Tomcat 应用 C3P0 老牌连接池，稳定性高 传统项目（已逐渐被取代） 4. 代码示例（Spring Boot + HikariCP） （1）application.yml 配置\n1 2 3 4 5 6 7 8 spring: datasource: url: jdbc:mysql://localhost:3306/test username: root password: 123456 hikari: maximum-pool-size: 10 connection-timeout: 30000 （2）Java 代码使用\n1 2 3 4 5 6 7 8 9 10 11 12 @Autowired private DataSource dataSource; // 自动注入 HikariCP 数据源 public void queryData() { try (Connection conn = dataSource.getConnection(); // 从池中获取 Statement stmt = conn.createStatement()) { ResultSet rs = stmt.executeQuery(\u0026#34;SELECT * FROM users\u0026#34;); while (rs.next()) { System.out.println(rs.getString(\u0026#34;name\u0026#34;)); } } // 此处自动调用 conn.close()，连接归还到池中 } 5. 总结 JDBC 连接池是数据库连接的缓存池，核心目标是复用连接、提升性能。 HikariCP 是目前最快的连接池，适合大多数 Java 应用。 关键配置：maximum-pool-size、idle-timeout、connection-timeout。 SpringBoot 启动类——EasyLiveWebRunApplication 详解 这段代码是 Spring Boot 应用的主启动类，包含了多个关键注解，用于配置和启动整个应用程序。以下是各个部分的详细解析：\n1. @SpringBootApplication 1 @SpringBootApplication(scanBasePackages = {\u0026#34;com.easylive\u0026#34;}) 作用：标记该类为 Spring Boot 应用的入口，整合了以下 3 个核心注解： @SpringBootConfiguration：标识这是一个 Spring Boot 配置类。 @EnableAutoConfiguration：启用 Spring Boot 的自动配置（如自动配置数据源、Web MVC 等）。 @ComponentScan：扫描指定包（com.easylive）下的组件（@Controller、@Service、@Repository 等）。 参数： scanBasePackages：显式指定扫描的包路径（覆盖默认扫描当前包及其子包）。 2. @MapperScan 1 @MapperScan(basePackages = {\u0026#34;com.easylive.mappers\u0026#34;}) 作用：告诉 MyBatis 扫描指定包（com.easylive.mappers）下的 Mapper 接口，并自动生成其实现类（无需手动写实现）。 背景：MyBatis 需要将接口与 XML/SQL 映射文件关联，此注解省去了逐个添加 @Mapper 注解的麻烦。 3. @EnableTransactionManagement 1 @EnableTransactionManagement 作用：启用 Spring 的声明式事务管理（基于 @Transactional 注解）。 效果： 方法或类上添加 @Transactional 后，Spring 会自动管理数据库事务（如提交、回滚）。 默认使用 JDBC 或 JPA 的事务管理器。 4. @EnableScheduling 1 @EnableScheduling 作用：启用 Spring 的定时任务功能。 用法：在方法上添加 @Scheduled(cron=\u0026ldquo;0 * * * * ?\u0026rdquo;) 即可定义定时任务（如每天凌晨执行数据统计）。 5. main 方法 1 2 3 public static void main(String[] args) { SpringApplication.run(EasyLiveWebRunApplication.class, args); } 作用：启动 Spring Boot 应用的入口方法。 流程： 初始化 Spring 容器。 加载自动配置（如 Web 服务器、数据库连接池等）。 扫描并注册所有 Spring 组件（如 Controller、Service）。 6. 排除自动配置（未使用但需注意） 1 2 // 示例：排除数据源自动配置（多数据源场景可能需要） @SpringBootApplication(exclude = {DataSourceAutoConfiguration.class}) 用途：如果应用不需要数据库（或需自定义数据源），可通过 exclude 禁用 Spring Boot 的默认配置。 总结：核心功能 注解/代码 作用 @SpringBootApplication 启动自动配置 + 组件扫描 @MapperScan 自动注册 MyBatis Mapper 接口 @EnableTransactionManagement 启用事务管理 @EnableScheduling 启用定时任务 main() 启动 Spring Boot 应用 补充说明 包扫描范围：scanBasePackages 确保扫描整个项目（而不仅是当前包）。 MyBatis 集成：@MapperScan 需配合 mybatis-spring-boot-starter 依赖使用。 事务控制：在 Service 层方法添加 @Transactional 即可实现事务（如回滚异常操作）。 这个启动类是 Spring Boot 应用的\u0026quot;大脑\u0026quot;，通过注解驱动了整个框架的协作运行。\nHttpServletRequest、HttpServletResponse、HttpSession 介绍 这三个是 Java Web 开发（Servlet/JSP）的核心接口，用于处理 HTTP 请求和响应以及用户会话管理。在 Spring MVC（@Controller）中也被广泛使用。\n1. HttpServletRequest（请求对象） 作用\n封装客户端（浏览器）发送的 HTTP 请求信息，包括： 请求参数（GET/POST） 请求头（Headers） 会话（Session） 客户端信息（IP、User-Agent） 常用方法\n方法 说明 String getParameter(\u0026ldquo;name\u0026rdquo;) 获取请求参数（如 ?id=123 或表单 POST 数据） String[] getParameterValues(\u0026ldquo;name\u0026rdquo;) 获取复选框等同名参数（返回数组） String getHeader(\u0026ldquo;User-Agent\u0026rdquo;) 获取请求头信息 String getMethod() 获取请求方法（GET/POST/PUT/DELETE） String getRequestURI() 获取请求路径（如 /user/login） Cookie[] getCookies() 获取客户端发送的 Cookie HttpSession getSession() 获取或创建会话（Session） String getRemoteAddr() 获取客户端 IP 地址 代码示例\n1 2 3 4 5 6 @GetMapping(\u0026#34;/user\u0026#34;) public String getUser(HttpServletRequest request) { String username = request.getParameter(\u0026#34;username\u0026#34;); // 获取参数 String ip = request.getRemoteAddr(); // 获取客户端IP return \u0026#34;User: \u0026#34; + username + \u0026#34;, IP: \u0026#34; + ip; } 2. HttpServletResponse（响应对象） 作用\n封装服务器返回给客户端的 HTTP 响应信息，包括： 设置响应状态码（200/404/500） 添加响应头（Headers） 写入响应体（HTML/JSON） 重定向或转发 常用方法\n方法 说明 void setStatus(200) 设置 HTTP 状态码（如 404、500） void setContentType(\u0026ldquo;text/html\u0026rdquo;) 设置响应内容类型（如 application/json） PrintWriter getWriter() 获取输出流，向客户端发送文本（HTML/JSON） void sendRedirect(\u0026quot;/new-url\u0026quot;) 重定向到新地址（302 跳转） void addCookie(Cookie cookie) 向客户端添加 Cookie void setHeader(\u0026ldquo;Cache-Control\u0026rdquo;, \u0026ldquo;no-cache\u0026rdquo;) 设置响应头 代码示例\n1 2 3 4 5 6 7 8 9 10 @GetMapping(\u0026#34;/hello\u0026#34;) public void sayHello(HttpServletResponse response) throws IOException { response.setContentType(\u0026#34;text/html\u0026#34;); response.getWriter().write(\u0026#34;\u0026lt;h1\u0026gt;Hello World!\u0026lt;/h1\u0026gt;\u0026#34;); } @GetMapping(\u0026#34;/redirect\u0026#34;) public void redirect(HttpServletResponse response) throws IOException { response.sendRedirect(\u0026#34;https://example.com\u0026#34;); // 重定向 } 3. HttpSession（会话对象） 作用\n用于在多次 HTTP 请求间存储用户数据（如登录状态、购物车信息）。 基于 Cookie（JSESSIONID）或 URL 重写实现会话跟踪。 常用方法\n方法 说明 void setAttribute(\u0026ldquo;key\u0026rdquo;, value) 存储会话数据 Object getAttribute(\u0026ldquo;key\u0026rdquo;) 获取会话数据 void removeAttribute(\u0026ldquo;key\u0026rdquo;) 删除会话数据 void invalidate() 销毁当前会话（用户注销） String getId() 获取会话 ID long getCreationTime() 获取会话创建时间 代码示例\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 // 登录时存储用户信息 @PostMapping(\u0026#34;/login\u0026#34;) public String login(HttpServletRequest request, @RequestParam String username) { HttpSession session = request.getSession(); // 获取或创建Session session.setAttribute(\u0026#34;user\u0026#34;, username); // 存储用户信息 return \u0026#34;Login success!\u0026#34;; } // 获取会话数据 @GetMapping(\u0026#34;/profile\u0026#34;) public String profile(HttpSession session) { String user = (String) session.getAttribute(\u0026#34;user\u0026#34;); // 获取用户信息 return \u0026#34;Current user: \u0026#34; + user; } // 注销 @GetMapping(\u0026#34;/logout\u0026#34;) public String logout(HttpSession session) { session.invalidate(); // 销毁会话 return \u0026#34;Logged out!\u0026#34;; } 4. 三者的关系 请求流程：\n浏览器发送请求 → HttpServletRequest 接收数据。 服务器处理请求 → 使用 HttpSession 存储用户状态。 服务器返回响应 → HttpServletResponse 输出结果。 典型场景：\n登录认证：通过 Session 保存用户登录状态。 表单提交：通过 Request 获取参数，通过 Response 返回结果。 权限控制：检查 Session 中是否存在用户信息。 5. 在 Spring MVC 中的简化用法 Spring 提供了更简洁的替代方式（底层仍依赖这三个对象）：\n(1) 直接注入\n1 2 3 4 5 6 7 8 9 @GetMapping(\u0026#34;/example\u0026#34;) public String example( @RequestParam String param, // 替代 request.getParameter() @CookieValue String cookie, // 替代 request.getCookies() HttpSession session // 直接注入 Session ) { session.setAttribute(\u0026#34;key\u0026#34;, \u0026#34;value\u0026#34;); return \u0026#34;OK\u0026#34;; } (2) 使用 @ModelAttribute 绑定对象\n1 2 3 4 5 @PostMapping(\u0026#34;/user\u0026#34;) public String addUser(@ModelAttribute User user) { // 自动将请求参数绑定到 User 对象 return \u0026#34;Saved: \u0026#34; + user.getName(); } 6. 总结 对象 作用 典型用途 HttpServletRequest 封装客户端请求 获取参数、请求头、客户端信息 HttpServletResponse 封装服务器响应 设置状态码、返回数据、重定向 HttpSession 跨请求存储用户数据 登录状态、购物车、用户偏好 掌握这三个对象是 Java Web 开发的基础，无论是传统 Servlet 还是 Spring MVC 都离不开它们！\n获取 HttpServletRequest 对象的两种方式 在 Spring Web 开发中，获取 request 对象主要有两种常用方式：\n1. 通过方法参数直接注入（Spring MVC 推荐） 在 Controller 方法中直接声明 HttpServletRequest 参数，Spring 会自动注入当前请求的 request 对象：\n1 2 3 4 5 @GetMapping(\u0026#34;/example\u0026#34;) public String example(HttpServletRequest request) { String param = request.getParameter(\u0026#34;name\u0026#34;); return \u0026#34;Param: \u0026#34; + param; } 优点： 简单直接，无需手动处理。\n2. 通过 RequestContextHolder 工具类获取 在任何地方（如 Service 层、工具类）通过 Spring 的 RequestContextHolder 静态方法获取：\n1 2 3 4 5 6 7 8 9 10 11 import org.springframework.web.context.request.RequestContextHolder; import org.springframework.web.context.request.ServletRequestAttributes; public class MyUtils { public static void logRequest() { HttpServletRequest request = ((ServletRequestAttributes) RequestContextHolder.getRequestAttributes()) .getRequest(); System.out.println(\u0026#34;Request URI: \u0026#34; + request.getRequestURI()); } } 例如：\n1 2 3 4 5 protected TokenUserInfoDto getTokenUserInfoDto(){ HttpServletRequest request = ((ServletRequestAttributes) RequestContextHolder.getRequestAttributes()).getRequest(); String token = request.getHeader(Constants.TOKEN_WEB); return redisComponent.getTokenInfo(token); } 适用场景： 非 Controller 层（如 Service、AOP、工具类）需要获取 request 时。\nTokenUserInfoDto 中 @JsonIgnoreProperties 和 Serializable 的作用 这段代码定义了一个名为 TokenUserInfoDto 的 DTO（数据传输对象），用于封装用户令牌信息。以下是对 @JsonIgnoreProperties 和 Serializable 接口作用的详细解释：\n1. @JsonIgnoreProperties(ignoreUnknown = true) 作用\n这是 Jackson 库提供的注解，用于控制 JSON 序列化/反序列化时的行为。 ignoreUnknown = true 表示：当 JSON 字符串中包含 DTO 类中没有的字段时，忽略这些字段而不报错。 为什么需要它？\n场景：如果后端接收的 JSON 数据比 DTO 的字段多（例如前端传了 extraField，但 DTO 未定义该字段），默认情况下 Jackson 会抛出 UnrecognizedPropertyException。 解决：添加此注解后，多余的字段会被静默忽略，确保反序列化不会因字段不匹配而失败。 示例\n1 2 3 4 5 // JSON 数据（包含 DTO 中没有的字段 \u0026#34;age\u0026#34;） String json = \u0026#34;{\\\u0026#34;userId\\\u0026#34;:\\\u0026#34;123\\\u0026#34;, \\\u0026#34;nickName\\\u0026#34;:\\\u0026#34;Alice\\\u0026#34;, \\\u0026#34;age\\\u0026#34;:25}\u0026#34;; // 反序列化时，\u0026#34;age\u0026#34; 会被忽略，不会报错 TokenUserInfoDto dto = objectMapper.readValue(json, TokenUserInfoDto.class); 2. implements Serializable 作用\n标记该类为可序列化的，表示该类的对象可以被转换为字节流（例如存储到文件、通过网络传输或存入 Redis 等缓存）。 需要定义一个 serialVersionUID 字段作为版本控制标识符。 为什么需要它？\n网络传输：在 RPC（如 Dubbo）或分布式系统中，对象需要跨 JVM 传输，必须实现 Serializable。 持久化存储：将对象保存到磁盘或数据库（如 Redis 的 value 需要实现序列化）。 兼容性：serialVersionUID 用于验证序列化和反序列化的类是否兼容（如果类结构变更但未更新 UID，会抛出 InvalidClassException）。 示例\n1 2 3 4 5 6 7 8 9 10 // 序列化对象到字节数组 ByteArrayOutputStream bos = new ByteArrayOutputStream(); ObjectOutputStream oos = new ObjectOutputStream(bos); oos.writeObject(dto); byte[] bytes = bos.toByteArray(); // 从字节数组反序列化 ByteArrayInputStream bis = new ByteArrayInputStream(bytes); ObjectInputStream ois = new ObjectInputStream(bis); TokenUserInfoDto deserializedDto = (TokenUserInfoDto) ois.readObject(); 3. 其他代码说明 字段含义： userId：用户唯一标识。 nickName：用户昵称。 avatar：用户头像 URL。 expireAt：令牌过期时间（时间戳）。 token：用户认证令牌（如 JWT）。 Getter/Setter：提供标准的 Java Bean 方法，便于框架（如 Spring、Jackson）通过反射访问字段。 总结 特性 作用 使用场景 @JsonIgnoreProperties(ignoreUnknown = true) 忽略 JSON 中的未知字段 防止前端多传字段导致反序列化失败 implements Serializable 支持对象序列化 网络传输、缓存存储、RPC 调用 serialVersionUID 版本控制 确保序列化兼容性 实际应用场景：\n该 DTO 可能用于用户登录后返回的令牌信息（通过 JSON 响应给前端）。 也可能被序列化后存入 Redis（作为缓存或分布式会话）。 服务端操作 Cookie 的完整流程（结合案例解析） 以下通过 saveToken2Cookie 方法说明服务端如何通过 HttpServletResponse 操作 Cookie，并附上完整案例和关键点解析。\n1. 代码逐行解析 1 2 3 4 5 6 7 8 9 10 protected void saveToken2Cookie(HttpServletResponse response, String token) { // 1. 创建一个新的 Cookie 对象 Cookie cookie = new Cookie(Constants.TOKEN_WEB, token); // 2. 设置 Cookie 过期时间（7天） cookie.setMaxAge(Constants.TIME_SECONDS_DAY * 7); // 3. 设置 Cookie 的生效路径（根路径，全站有效） cookie.setPath(\u0026#34;/\u0026#34;); // 4. 将 Cookie 添加到响应中（通过 Set-Cookie 头发给浏览器） response.addCookie(cookie); } 2. 关键操作说明 操作 作用 对应 HTTP 协议行为 new Cookie(name, value) 创建 Cookie 无（仅内存对象） setMaxAge(seconds) 设置 Cookie 有效期 Set-Cookie: token=abc; Max-Age=604800 setPath(\u0026quot;/\u0026quot;) 设置 Cookie 的作用路径 Set-Cookie: token=abc; Path=/ response.addCookie() 将 Cookie 写入响应 浏览器收到后自动保存 3. 完整案例场景 场景描述\n需求：用户登录成功后，服务端生成一个身份令牌（Token），并通过 Cookie 自动保存到浏览器。 技术实现：调用 saveToken2Cookie 方法。 代码示例（Spring MVC Controller）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 @PostMapping(\u0026#34;/login\u0026#34;) public String login( @RequestParam String username, @RequestParam String password, HttpServletResponse response ) { // 1. 验证用户名密码（伪代码） boolean isValid = userService.checkLogin(username, password); if (!isValid) { return \u0026#34;登录失败\u0026#34;; } // 2. 生成 Token（伪代码） String token = jwtUtil.generateToken(username); // 3. 将 Token 保存到 Cookie（关键操作！） saveToken2Cookie(response, token); return \u0026#34;登录成功\u0026#34;; } // 复用之前的 Cookie 操作方法 protected void saveToken2Cookie(HttpServletResponse response, String token) { Cookie cookie = new Cookie(\u0026#34;AUTH_TOKEN\u0026#34;, token); cookie.setMaxAge(7 * 24 * 60 * 60); // 7天有效期 cookie.setPath(\u0026#34;/\u0026#34;); // 全站有效 cookie.setHttpOnly(true); // 防止 XSS 攻击（可选） response.addCookie(cookie); } 4. 浏览器与服务器的交互流程 请求登录：\n1 2 3 4 POST /login HTTP/1.1 Content-Type: application/x-www-form-urlencoded username=admin\u0026amp;password=123456 服务端响应（设置 Cookie）：\n1 2 3 4 5 HTTP/1.1 200 OK Set-Cookie: AUTH_TOKEN=xyz123; Max-Age=604800; Path=/; HttpOnly Content-Type: text/html 登录成功 后续请求（浏览器自动携带 Cookie）：\n1 2 GET /profile HTTP/1.1 Cookie: AUTH_TOKEN=xyz123 5. 关键注意事项 (1) Cookie 安全性\n配置 作用 推荐值 setHttpOnly(true) 禁止 JavaScript 读取 Cookie 必须启用 setSecure(true) 仅通过 HTTPS 传输 生产环境启用 setDomain(\u0026ldquo;example.com\u0026rdquo;) 限制 Cookie 的作用域名 按需设置 (2) 其他常见操作\n删除 Cookie： 1 2 3 Cookie cookie = new Cookie(\u0026#34;AUTH_TOKEN\u0026#34;, null); cookie.setMaxAge(0); // 立即过期 response.addCookie(cookie); 读取客户端 Cookie： 1 Cookie[] cookies = request.getCookies(); // 从 HttpServletRequest 获取 6. 总结 服务端操作 Cookie 的核心步骤： 创建 Cookie 对象 → 2. 设置属性 → 3. 通过 response.addCookie() 下发。 实际应用场景：用户认证（Token）、会话管理、个性化设置等。 安全建议：始终启用 HttpOnly 和 Secure（HTTPS 环境下）。 通过这种方式，服务端可以轻松管理浏览器端的持久化数据！\nAppInterceptor 和 WebAppConfigurer 基于 Token 的请求拦截验证机制 这两个类共同实现了一个基于 Token 的请求拦截验证机制，主要用于用户身份认证和权限控制。以下是详细解析：\n1. AppInterceptor（核心拦截器类） 类作用\n实现 HandlerInterceptor 接口，对符合条件的请求进行拦截。 主要功能：验证请求中的 Token 是否有效（从 Header 或 Cookie 获取），无效则拒绝访问。 关键代码解析\n(1) 成员变量\n1 2 private static final String URL_ACCOUNT = \u0026#34;/account\u0026#34;; private static final String URL_FILE = \u0026#34;/file\u0026#34;; 作用：定义不需要 Token 验证的白名单路径（如登录、文件公开访问）。 (2) preHandle() 方法（核心逻辑）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) { // 1. 检查 handler 是否有效 if (null == handler) { return false; // 直接拒绝 } // 2. 只处理 HandlerMethod 类型请求（如 @Controller 或 @RestController 定义的处理器方法,Spring 管理的控制器方法） if (!(handler instanceof HandlerMethod)) { return true; // 其他类型（如静态资源）直接放行 } // 3. 白名单路径放行 if (request.getRequestURI().contains(URL_ACCOUNT)) { return true; // 如登录接口无需 Token } // 4. 获取 Token（优先从 Header，文件请求从 Cookie） String token = request.getHeader(Constants.TOKEN_ADMIN); if (request.getRequestURI().contains(URL_FILE)) { token = getTokenFromCookie(request); // 文件请求特殊处理 } // 5. Token 为空或无效时抛出异常 if (StringTools.isEmpty(token)) { throw new BusinessException(ResponseCodeEnum.CODE_901); // Token 缺失 } Object sessionObj = redisComponent.getTokenInfo4Admin(token); if (null == sessionObj) { throw new BusinessException(ResponseCodeEnum.CODE_901); // Token 无效 } return true; // 验证通过 } (3) getTokenFromCookie() 方法\n1 2 3 4 5 6 7 8 9 10 private String getTokenFromCookie(HttpServletRequest request) { Cookie[] cookies = request.getCookies(); if (cookies == null) return null; for (Cookie cookie : cookies) { if (cookie.getName().equals(Constants.TOKEN_ADMIN)) { return cookie.getValue(); // 返回匹配的 Token } } return null; } 作用：从 Cookie 中提取 Token（用于文件请求等特殊场景）。 (4) 其他方法\npostHandle() 和 afterCompletion()：空实现，用于拦截后处理（如日志记录），当前未使用。 2. WebAppConfigurer（拦截器配置类） 类作用\n实现 WebMvcConfigurer 接口，注册拦截器并配置拦截规则。 核心功能：将 AppInterceptor 应用到所有请求路径（/**）。 关键代码解析\n1 2 3 4 5 6 7 8 9 10 11 @Configuration public class WebAppConfigurer implements WebMvcConfigurer { @Resource private AppInterceptor appInterceptor; // 注入拦截器 @Override public void addInterceptors(InterceptorRegistry registry) { registry.addInterceptor(appInterceptor) .addPathPatterns(\u0026#34;/**\u0026#34;); // 拦截所有路径 } } addPathPatterns(\u0026quot;/\u0026quot;)：表示拦截所有请求（可通过 excludePathPatterns() 排除特定路径，如 /api/public/）。 3. 协作流程 请求到达 Spring MVC → 先经过 WebAppConfigurer 注册的 AppInterceptor。 拦截器验证逻辑： 白名单放行：如 /account/login 直接通过。 Token 检查： 普通请求从 Header 的 TOKEN_ADMIN 获取 Token。 文件请求（/file/**）从 Cookie 获取 Token。 Redis 验证：检查 Token 是否有效（如是否过期或被踢出）。 验证结果处理： 成功：继续执行后续拦截器或 Controller。 失败：抛出 BusinessException（最终会被全局异常处理器转换为错误响应）。 4. 设计亮点 灵活 Token 获取：支持 Header 和 Cookie 两种方式，适应不同场景（如 API 调用和浏览器文件下载）。 白名单机制：公开接口（如登录）无需 Token，避免循环验证。 Redis 集中管理：Token 状态（如有效期、强制失效）由 Redis 控制，实现分布式会话。 5. 典型应用场景 用户登录态校验：访问 /admin/* 时要求携带有效 Token。 文件安全下载：文件接口（/file/*）通过 Cookie 传递 Token，确保只有登录用户可访问。 权限控制扩展：可在 preHandle() 中进一步检查用户角色（如从 sessionObj 解析权限）。 总结 类名 职责 核心方法 AppInterceptor 拦截请求并验证 Token preHandle() WebAppConfigurer 注册拦截器到 Spring MVC addInterceptors() 通过这两个类，系统实现了统一、可扩展的认证层，确保只有合法请求能访问受保护资源。\n为什么文件请求和其他请求分开处理 Token 的获取方式？ 1. 技术限制：浏览器对文件请求的 Header 处理 (1) 普通 API 请求（使用 Header 传递 Token）\n场景：前后端分离架构中，前端（如 Vue/React）通过 AJAX/Fetch 调用 API。 Token 传递方式：通过 HTTP 请求头（如 Authorization: Bearer 或自定义头 TOKEN_ADMIN）传递。 优势： 安全性高：Header 不会被浏览器自动缓存或记录在日志中。 适合 RESTful API：符合无状态认证的最佳实践。 (2) 文件请求（使用 Cookie 传递 Token）\n场景：浏览器直接访问文件下载链接（如 或 标签）。 问题： 浏览器在发起非 AJAX 的文件请求（如直接访问 URL、、 标签）时： 无法自定义 Header：浏览器不会允许通过普通 HTML 标签或跳转设置自定义头。 自动携带 Cookie：浏览器会自动在请求中附加当前域的 Cookie（如果 Cookie 的 Path 和 Domain 匹配）。 解决方案： 对于文件请求，改用 Cookie 传递 Token，因为： 浏览器会自动管理 Cookie 的发送。 无需前端代码显式设置 Header。 2. 实际应用场景示例 (1) 普通 API 请求\n1 2 3 4 // 前端调用 API（可自定义 Header） fetch(\u0026#34;/api/data\u0026#34;, { headers: { \u0026#34;TOKEN_ADMIN\u0026#34;: \u0026#34;xyz123\u0026#34; } }); 服务端：从 Header 提取 Token。 (2) 文件下载请求\n1 2 3 4 \u0026lt;!-- 浏览器直接访问文件链接 --\u0026gt; \u0026lt;a href=\u0026#34;/file/123.pdf\u0026#34;\u0026gt;下载PDF\u0026lt;/a\u0026gt; \u0026lt;!-- 或图片加载 --\u0026gt; \u0026lt;img src=\u0026#34;/file/456.jpg\u0026#34;\u0026gt; 服务端：从 Cookie 提取 Token（因为浏览器不会为这些请求设置自定义 Header）。 saveCategory 方法中的 if 判断（对应增加和修改）详解 这个判断逻辑用于防止分类编号（categoryCode）重复，覆盖了两种业务场景：新增分类时检查编号是否已存在，修改分类时检查编号是否被其他分类占用。\n1. 判断条件分解 1 2 3 4 5 6 7 8 9 if ( // 场景1：新增时发现分类编号已存在 bean.getCategoryId() == null \u0026amp;\u0026amp; null != dbBean || // 场景2：修改时发现分类编号被其他分类占用 bean.getCategoryId() != null \u0026amp;\u0026amp; dbBean != null \u0026amp;\u0026amp; !bean.getCategoryId().equals(dbBean.getCategoryId()) ) { throw new BusinessException(\u0026#34;分类编号已经存在\u0026#34;); } 2. 场景1：新增分类时的检查 条件：bean.getCategoryId() == null \u0026amp;\u0026amp; null != dbBean 逻辑：当前操作是新增分类（categoryId 尚未生成），dbBean 非空说明该 categoryCode 已被其他分类占用。 示例：用户尝试新增 categoryCode = \u0026ldquo;ELECTRONICS\u0026rdquo;，但数据库已存在该编号，抛出异常。 3. 场景2：修改分类时的检查 条件：bean.getCategoryId() != null \u0026amp;\u0026amp; dbBean != null \u0026amp;\u0026amp; !bean.getCategoryId().equals(dbBean.getCategoryId()) 逻辑：当前操作是修改已有分类，且数据库中存在与 categoryCode 匹配的分类，但不是当前分类本身，说明编号被其他分类占用。 示例：用户尝试将 categoryId = 1 的分类编号改为已被 categoryId = 2 占用的编号，抛出异常。 4. 为什么需要两个场景分开判断？ 新增时只需检查 categoryCode 是否存在。 修改时需额外检查 categoryCode 是否被其他分类占用（允许修改为自己的原值）。 5. 逻辑优化建议 更清晰的写法：\n1 2 3 4 5 6 7 8 boolean isAdd = (bean.getCategoryId() == null); boolean isUpdate = !isAdd; if (isAdd \u0026amp;\u0026amp; dbBean != null) { throw new BusinessException(\u0026#34;分类编号已存在\u0026#34;); } if (isUpdate \u0026amp;\u0026amp; dbBean != null \u0026amp;\u0026amp; !bean.getCategoryId().equals(dbBean.getCategoryId())) { throw new BusinessException(\u0026#34;分类编号已被其他分类使用\u0026#34;); } 提前返回减少嵌套：\n1 2 3 4 5 6 7 if (dbBean == null) { // 无冲突，直接继续后续逻辑 } else if (bean.getCategoryId() == null) { throw new BusinessException(\u0026#34;分类编号已存在\u0026#34;); } else if (!bean.getCategoryId().equals(dbBean.getCategoryId())) { throw new BusinessException(\u0026#34;分类编号已被其他分类使用\u0026#34;); } 6. 总结 目的：确保分类编号的唯一性，避免数据冲突。 新增时：禁止使用已存在的 categoryCode。 修改时：禁止将 categoryCode 改为其他分类的编号。 关键技巧：通过 categoryId 是否为 null 区分操作类型，结合查询结果 dbBean 判断冲突。 file.transferTo(new File(filePath)) 代码解析 作用\n这行代码是将客户端上传的 MultipartFile 文件保存到服务器的指定路径。 file：Spring MVC 接收到的上传文件对象（MultipartFile 类型）。 transferTo()：将文件内容从内存或临时目录永久保存到目标路径。 new File(filePath)：指定文件在服务器上的存储位置（绝对路径）。 详细执行流程 文件接收：用户通过 HTTP 请求上传文件，Spring MVC 将其封装为 MultipartFile 对象。 路径准备：代码中通过 folder 和 realFileName 拼接出完整的存储路径，确保目标目录存在（通过 mkdirs() 创建）。 文件保存：transferTo() 方法将文件流写入到 filePath 对应的物理文件中。 关键注意事项 文件覆盖风险：filePath 已存在同名文件会被覆盖，建议追加随机字符串或时间戳避免冲突。 异常处理：transferTo() 可能抛出 IOException，需捕获异常并返回友好提示。 性能优化：大文件上传建议分块或异步处理，避免阻塞请求线程。 示例：完整安全版代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 @RequestMapping(\u0026#34;/uploadImage\u0026#34;) public ResponseVO uploadImage(@NotNull MultipartFile file, @NotNull Boolean createThumbnail) throws IOException { if (file.isEmpty()) { throw new BusinessException(\u0026#34;上传文件不能为空\u0026#34;); } String month = DateUtil.format(new Date(), \u0026#34;yyyyMM\u0026#34;); String folder = appConfig.getProjectFolder() + \u0026#34;/upload/cover/\u0026#34; + month; File folderFile = new File(folder); if (!folderFile.exists()) { folderFile.mkdirs(); } String originalName = file.getOriginalFilename(); String suffix = originalName.substring(originalName.lastIndexOf(\u0026#34;.\u0026#34;)); String newFileName = UUID.randomUUID() + suffix; String filePath = folder + \u0026#34;/\u0026#34; + newFileName; try { file.transferTo(new File(filePath)); } catch (IOException e) { throw new BusinessException(\u0026#34;文件保存失败: \u0026#34; + e.getMessage()); } if (createThumbnail) { fFmpegUtils.createImageThumbnail(filePath); } return getSuccessResponseVO(\u0026#34;/upload/cover/\u0026#34; + month + \u0026#34;/\u0026#34; + newFileName); } 常见问题解答 为什么不用 file.getBytes() 再手动写入？ transferTo() 已优化文件流处理，直接操作文件系统，更高效。 文件保存后如何让外部访问？ 返回相对路径，配合静态资源映射。 分片上传视频文件 uploadVideo 方法详解 该方法实现了分片上传视频文件的功能，主要用于处理大文件上传。以下是逐行解析：\n1. 方法签名 1 2 3 @RequestMapping(\u0026#34;/uploadVideo\u0026#34;) @GlobalInterceptor(checkLogin = true) public ResponseVO uploadVideo(@NotNull MultipartFile chunkFile, @NotNull Integer chunkIndex, @NotEmpty String uploadId) throws IOException { chunkFile：当前上传的文件分片。 chunkIndex：当前分片的索引。 uploadId：本次上传的唯一标识。 2. 用户身份验证 1 TokenUserInfoDto tokenUserInfoDto = getTokenUserInfoDto(); 从请求头或 Cookie 获取当前登录用户的信息。 3. 检查上传任务是否存在 1 2 3 4 UploadingFileDto fileDto = redisComponent.getUploadVideoFile(tokenUserInfoDto.getUserId(), uploadId); if (fileDto == null) { throw new BusinessException(\u0026#34;文件不存在请重新上传\u0026#34;); } Redis 中没有找到对应的上传任务，需重新上传。 4. 检查文件大小限制 1 2 3 4 SysSettingDto sysSettingDto = redisComponent.getSysSettingDto(); if (fileDto.getFileSize() \u0026gt; sysSettingDto.getVideoSize() * Constants.MB_SIZE) { throw new BusinessException(\u0026#34;文件超过最大文件限制\u0026#34;); } 超过系统允许的最大视频文件大小则拒绝。 5. 检查分片序号合法性 1 2 3 if ((chunkIndex - 1) \u0026gt; fileDto.getChunkIndex() || chunkIndex \u0026gt; fileDto.getChunks() - 1) { throw new BusinessException(ResponseCodeEnum.CODE_600); } 防止乱序上传或恶意传超出范围的分片。 6. 保存分片文件 1 2 3 String folder = appConfig.getProjectFolder() + Constants.FILE_FOLDER + Constants.FILE_FOLDER_TEMP + fileDto.getFilePath(); File targetFile = new File(folder + \u0026#34;/\u0026#34; + chunkIndex); chunkFile.transferTo(targetFile); 分片文件保存到临时目录。 7. 更新上传进度 1 2 3 fileDto.setChunkIndex(chunkIndex); fileDto.setFileSize(fileDto.getFileSize() + chunkFile.getSize()); redisComponent.updateVideoFileInfo(tokenUserInfoDto.getUserId(), fileDto); 记录当前上传进度，确保断点续传。 8. 返回成功响应 1 return getSuccessResponseVO(null); 表示当前分片上传成功。 完整流程总结 客户端将大文件切分为多个分片，依次上传。 服务端检查分片顺序、大小限制，保存分片到临时目录，更新 Redis 上传进度。 所有分片上传完成后，调用合并接口将临时文件拼接为完整视频。 优化建议 断点续传、分片校验、清理临时文件、并发控制。 适用场景：视频网站、云存储服务、大文件上传。 saveVideoInfo 方法详细解析 saveVideoInfo 方法用于保存视频信息及其关联文件，处理视频信息的创建、更新以及文件管理。\n1. 方法概述 1 2 3 @Override @Transactional(rollbackFor = Exception.class) public void saveVideoInfo(VideoInfoPost videoInfoPost, List\u0026lt;VideoInfoFilePost\u0026gt; uploadFileList) @Transactional：遇到任何异常都会回滚。 videoInfoPost：视频主信息。 uploadFileList：视频关联的文件列表。 2. 分P数校验 1 2 3 if (uploadFileList.size() \u0026gt; redisComponent.getSysSettingDto().getVideoPCount()) { throw new BusinessException(ResponseCodeEnum.CODE_600); } 检查上传的视频分P数是否超过系统设置的最大限制。 3. 视频ID存在性校验 1 2 3 4 5 6 7 8 9 if(!StringTools.isEmpty(videoInfoPost.getVideoId())){ VideoInfoPost videoInfoPostDb = this.videoInfoPostMapper.selectByVideoId(videoInfoPost.getVideoId()); if (videoInfoPostDb == null) { throw new BusinessException(ResponseCodeEnum.CODE_600); } if (ArrayUtils.contains(new Integer[]{VideoStatusEnum.STATUS0.getStatus(), VideoStatusEnum.STATUS2.getStatus()}, videoInfoPostDb.getStatus())) { throw new BusinessException(ResponseCodeEnum.CODE_600); } } 检查视频是否存在及状态是否允许修改。 4. 初始化变量 1 2 3 4 Date curDate = new Date(); String videoId = videoInfoPost.getVideoId(); List\u0026lt;VideoInfoFilePost\u0026gt; deleteFileList = new ArrayList\u0026lt;\u0026gt;(); List\u0026lt;VideoInfoFilePost\u0026gt; addFileList = uploadFileList; curDate：当前时间。 videoId：视频ID。 deleteFileList：待删除的文件列表。 addFileList：待添加的文件列表。 5. 新增视频逻辑 1 2 3 4 5 6 7 8 if (StringTools.isEmpty(videoId)) { videoId = StringTools.getRandomString(Constants.LENGTH_10); videoInfoPost.setVideoId(videoId); videoInfoPost.setCreateTime(curDate); videoInfoPost.setLastUpdateTime(curDate); videoInfoPost.setStatus(VideoStatusEnum.STATUS0.getStatus()); this.videoInfoPostMapper.insert(videoInfoPost); } videoId 为空表示新增视频。 生成随机 videoId，设置创建/更新时间、初始状态，插入数据库。 6. 更新视频逻辑 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 else { VideoInfoFilePostQuery fileQuery = new VideoInfoFilePostQuery(); fileQuery.setVideoId(videoId); fileQuery.setUserId(videoInfoPost.getUserId()); List\u0026lt;VideoInfoFilePost\u0026gt; dbInfoFileList = this.videoInfoFilePostMapper.selectList(fileQuery); Map\u0026lt;String, VideoInfoFilePost\u0026gt; uploadFileMap = uploadFileList.stream() .collect(Collectors.toMap(item -\u0026gt; item.getUploadId(), Function.identity(), (data1, data2) -\u0026gt; data2)); Boolean updateFileName = false; for(VideoInfoFilePost fileInfo : dbInfoFileList){ VideoInfoFilePost updateFile = uploadFileMap.get(fileInfo.getUploadId()); if (updateFile == null) { deleteFileList.add(fileInfo); } else if (!updateFile.getFileName().equals(fileInfo.getFileName())) { updateFileName = true; } } addFileList = uploadFileList.stream() .filter(item-\u0026gt;item.getFileId()==null) .collect(Collectors.toList()); videoInfoPost.setLastUpdateTime(curDate); Boolean changeVideoInfo = this.changeVideoInfo(videoInfoPost); if (addFileList != null \u0026amp;\u0026amp; !addFileList.isEmpty()) { videoInfoPost.setStatus(VideoStatusEnum.STATUS0.getStatus()); } else if (changeVideoInfo || updateFileName) { videoInfoPost.setStatus(VideoStatusEnum.STATUS2.getStatus()); } this.videoInfoPostMapper.updateByVideoId(videoInfoPost, videoInfoPost.getVideoId()); } 查询数据库中该视频已有的文件列表。 比较数据库文件和上传文件，识别新增、删除和修改的文件。 根据情况设置视频状态，更新主表信息。 7. 处理待删除文件 1 2 3 4 5 6 7 8 9 10 if (!deleteFileList.isEmpty()) { List\u0026lt;String\u0026gt; delFileList = deleteFileList.stream() .map(item-\u0026gt;item.getFileId()) .collect(Collectors.toList()); this.videoInfoFilePostMapper.deleteBatchByFileId(delFileList, videoInfoPost.getUserId()); List\u0026lt;String\u0026gt; delFilePathList = deleteFileList.stream() .map(item-\u0026gt;item.getFilePath()) .collect(Collectors.toList()); redisComponent.addFile2DelQueue(videoId, delFilePathList); } 批量删除数据库记录，将待删除文件路径加入 Redis 队列。 8. 处理文件索引和新增文件 1 2 3 4 5 6 7 8 9 10 11 12 Integer index = 1; for (VideoInfoFilePost videoInfoFile : uploadFileList) { videoInfoFile.setFileIndex(index++); videoInfoFile.setVideoId(videoId); videoInfoFile.setUserId(videoInfoPost.getUserId()); if (videoInfoFile.getFileId() == null) { videoInfoFile.setFileId(StringTools.getRandomString(Constants.LENGTH_20)); videoInfoFile.setUpdateType(VideoFileUpdateTypeEnum.UPDATE.getStatus()); videoInfoFile.setTransferResult(VideoFileTransferResultEnum.TRANSFER.getStatus()); } } this.videoInfoFilePostMapper.insertOrUpdateBatch(uploadFileList); 为每个文件设置索引、视频ID、用户ID。 对新文件生成 fileId 并设置属性。 批量插入或更新文件表。 9. 处理新增文件传输 1 2 3 4 5 6 7 if (addFileList != null \u0026amp;\u0026amp; !addFileList.isEmpty()) { for (VideoInfoFilePost file : addFileList) { file.setUserId(videoInfoPost.getUserId()); file.setVideoId(videoId); } redisComponent.addFile2TransferQueue(addFileList); } 将新增文件加入传输队列（如转码、转存等异步处理）。 方法总结 参数校验：检查分P数限制、视频状态是否允许修改。 新增视频：生成ID、设置初始状态、插入数据库。 更新视频：比较新旧文件列表，识别新增、删除和修改的文件，根据修改情况设置视频状态，更新主信息。 文件处理：删除不再需要的文件记录和实际文件，为新增文件生成ID并设置属性，批量保存文件信息，将新增文件加入处理队列。 通过精细的状态管理和文件比较，实现了视频信息的完整保存流程，同时考虑了事务一致性和异步处理的需求。 saveVideoInfo 方法中 stream() 的详细用法解析 在 saveVideoInfo 方法中，stream() 方法被多次用于对集合进行函数式操作。下面详细解析每个 stream() 的使用场景和实现逻辑。\n1. 将上传文件列表转为 Map 1 2 3 4 5 6 Map\u0026lt;String, VideoInfoFilePost\u0026gt; uploadFileMap = uploadFileList.stream() .collect(Collectors.toMap( item -\u0026gt; item.getUploadId(), // Key 映射函数 Function.identity(), // Value 映射函数 (data1, data2) -\u0026gt; data2 // 合并函数（解决键冲突） )); 解析：\n目的：将 List\u0026lt;VideoInfoFilePost\u0026gt; 转换为 Map\u0026lt;String, VideoInfoFilePost\u0026gt;，以便通过 uploadId 快速查找文件。 分解： uploadFileList.stream() - 将列表转为流。 Collectors.toMap() - 收集器，将流元素转为 Map。 第一个参数 item -\u0026gt; item.getUploadId()：指定使用 uploadId 作为 Map 的键。 第二个参数 Function.identity()：使用元素本身作为 Map 的值。 第三个参数 (data1, data2) -\u0026gt; data2：如果键冲突（相同 uploadId），保留后面的值。 等价传统写法：\n1 2 3 4 Map\u0026lt;String, VideoInfoFilePost\u0026gt; uploadFileMap = new HashMap\u0026lt;\u0026gt;(); for (VideoInfoFilePost item : uploadFileList) { uploadFileMap.put(item.getUploadId(), item); } 2. 筛选新增文件 1 2 3 addFileList = uploadFileList.stream() .filter(item -\u0026gt; item.getFileId() == null) .collect(Collectors.toList()); 解析：\n目的：从上传文件列表中筛选出新增的文件（fileId 为 null 的文件）。 分解： uploadFileList.stream() - 创建流。 .filter(item -\u0026gt; item.getFileId() == null) - 过滤条件。 .collect(Collectors.toList()) - 收集为 List。 等价传统写法：\n1 2 3 4 5 6 List\u0026lt;VideoInfoFilePost\u0026gt; addFileList = new ArrayList\u0026lt;\u0026gt;(); for (VideoInfoFilePost item : uploadFileList) { if (item.getFileId() == null) { addFileList.add(item); } } 3. 提取待删除文件的 ID 列表 1 2 3 List\u0026lt;String\u0026gt; delFileList = deleteFileList.stream() .map(item -\u0026gt; item.getFileId()) .collect(Collectors.toList()); 解析：\n目的：从待删除文件列表中提取所有 fileId 组成新列表。 分解： deleteFileList.stream() - 创建流。 .map(item -\u0026gt; item.getFileId()) - 映射转换，从对象中提取 fileId。 .collect(Collectors.toList()) - 收集为 List。 等价传统写法：\n1 2 3 4 List\u0026lt;String\u0026gt; delFileList = new ArrayList\u0026lt;\u0026gt;(); for (VideoInfoFilePost item : deleteFileList) { delFileList.add(item.getFileId()); } 4. 提取待删除文件的路径列表 1 2 3 List\u0026lt;String\u0026gt; delFilePathList = deleteFileList.stream() .map(item -\u0026gt; item.getFilePath()) .collect(Collectors.toList()); 解析：\n目的：从待删除文件列表中提取所有 filePath 组成新列表。 实现：与上一个例子类似，只是提取的是 filePath 而非 fileId。 等价传统写法：\n1 2 3 4 List\u0026lt;String\u0026gt; delFilePathList = new ArrayList\u0026lt;\u0026gt;(); for (VideoInfoFilePost item : deleteFileList) { delFilePathList.add(item.getFilePath()); } Stream API 核心概念总结 操作类型 方法 说明 示例 创建流 stream() 从集合创建流 list.stream() 中间操作 filter() 过滤元素 .filter(x -\u0026gt; x \u0026gt; 0) map() 转换元素 .map(x -\u0026gt; x.getName()) 终止操作 collect() 收集结果 .collect(Collectors.toList()) forEach() 遍历元素 .forEach(System.out::println) 为什么使用 Stream API？ 代码简洁：用声明式的方式表达复杂的数据处理逻辑。 可读性强：链式调用更直观表达数据处理流程。 并行处理：只需将 stream() 改为 parallelStream() 即可实现并行。 惰性求值：中间操作不会立即执行，提高效率。 性能考虑 虽然 Stream API 很强大，但在简单循环就能完成的任务中，传统 for 循环可能更高效。Stream 适合处理复杂的数据转换和过滤场景。\n完整流程示例 假设有以下数据：\n1 2 3 4 5 List\u0026lt;VideoInfoFilePost\u0026gt; uploadFileList = Arrays.asList( new VideoInfoFilePost(\u0026#34;f1\u0026#34;, \u0026#34;u1\u0026#34;, \u0026#34;p1\u0026#34;), // fileId 不为 null，视为已有文件 new VideoInfoFilePost(null, \u0026#34;u2\u0026#34;, \u0026#34;p2\u0026#34;), // fileId 为 null，视为新增文件 new VideoInfoFilePost(null, \u0026#34;u3\u0026#34;, \u0026#34;p3\u0026#34;) // fileId 为 null，视为新增文件 ); 执行：\n1 2 3 List\u0026lt;VideoInfoFilePost\u0026gt; addFileList = uploadFileList.stream() .filter(item -\u0026gt; item.getFileId() == null) .collect(Collectors.toList()); 结果：\n1 2 3 4 addFileList = [ VideoInfoFilePost(null, \u0026#34;u2\u0026#34;, \u0026#34;p2\u0026#34;), VideoInfoFilePost(null, \u0026#34;u3\u0026#34;, \u0026#34;p3\u0026#34;) ] 通过 Stream API，我们简洁地实现了数据筛选和转换，代码更加清晰易读。\nMyBatis 批量插入或更新语句 insertOrUpdateBatch 解析 这段代码是一个 MyBatis 的 Mapper XML 配置，实现了批量插入或更新视频文件信息的功能。下面详细解析这个 SQL 语句的各个部分：\n1. 基本结构 1 2 3 4 \u0026lt;insert id=\u0026#34;insertOrUpdateBatch\u0026#34; parameterType=\u0026#34;com.easylive.entity.po.VideoInfoFilePost\u0026#34;\u0026gt; INSERT INTO video_info_file_post(...) VALUES (...) ON DUPLICATE KEY UPDATE ... \u0026lt;/insert\u0026gt; 这是一个典型的 MyBatis 批量操作语句，使用了 MySQL 的 INSERT ... ON DUPLICATE KEY UPDATE 语法。 2. 插入部分详解 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 INSERT INTO video_info_file_post( file_id, upload_id, user_id, video_id, file_index, file_name, file_size, file_path, update_type, transfer_result, duration ) VALUES \u0026lt;foreach collection=\u0026#34;list\u0026#34; item=\u0026#34;item\u0026#34; separator=\u0026#34;,\u0026#34;\u0026gt; ( #{item.fileId}, #{item.uploadId}, #{item.userId}, #{item.videoId}, #{item.fileIndex}, #{item.fileName}, #{item.fileSize}, #{item.filePath}, #{item.updateType}, #{item.transferResult}, #{item.duration} ) \u0026lt;/foreach\u0026gt; 关键点：\n\u0026lt;foreach\u0026gt; 标签：MyBatis 的循环标签，用于处理集合 collection=\u0026quot;list\u0026quot;：表示参数是一个 List 集合 item=\u0026quot;item\u0026quot;：定义循环变量名 separator=\u0026quot;,\u0026quot;：每次循环后用逗号分隔 #{} 表达式：MyBatis 的参数占位符，会预编译防止 SQL 注入 使用 item.属性名 访问集合元素的属性 3. 冲突更新部分详解 1 2 3 ON DUPLICATE KEY UPDATE file_index = VALUES(file_index), file_name = VALUES(file_name) 关键点：\nON DUPLICATE KEY UPDATE：MySQL 特有语法，当主键或唯一键冲突时执行更新 VALUES() 函数：引用 INSERT 语句中尝试插入的值 这里只更新了 file_index 和 file_name 两个字段，其他字段保持不变 4. 完整逻辑流程 尝试批量插入多条记录到 video_info_file_post 表 如果某条记录的 file_id（假设是主键）已存在，则执行更新操作 更新时只修改 file_index 和 file_name 字段 其他字段保持原值不变 5. 实际执行示例 假设传入的 List 包含两个元素：\n1 2 3 4 List\u0026lt;VideoInfoFilePost\u0026gt; list = Arrays.asList( new VideoInfoFilePost(\u0026#34;id1\u0026#34;, \u0026#34;up1\u0026#34;, \u0026#34;user1\u0026#34;, \u0026#34;vid1\u0026#34;, 1, \u0026#34;name1\u0026#34;, 100, \u0026#34;path1\u0026#34;, 0, 0, 100), new VideoInfoFilePost(\u0026#34;id2\u0026#34;, \u0026#34;up2\u0026#34;, \u0026#34;user1\u0026#34;, \u0026#34;vid1\u0026#34;, 2, \u0026#34;name2\u0026#34;, 200, \u0026#34;path2\u0026#34;, 0, 0, 200) ); 生成的 SQL 语句类似：\n1 2 3 4 5 6 7 8 9 INSERT INTO video_info_file_post( file_id, upload_id, user_id, video_id, file_index, file_name, file_size, file_path, update_type, transfer_result, duration ) VALUES (\u0026#39;id1\u0026#39;, \u0026#39;up1\u0026#39;, \u0026#39;user1\u0026#39;, \u0026#39;vid1\u0026#39;, 1, \u0026#39;name1\u0026#39;, 100, \u0026#39;path1\u0026#39;, 0, 0, 100), (\u0026#39;id2\u0026#39;, \u0026#39;up2\u0026#39;, \u0026#39;user1\u0026#39;, \u0026#39;vid1\u0026#39;, 2, \u0026#39;name2\u0026#39;, 200, \u0026#39;path2\u0026#39;, 0, 0, 200) ON DUPLICATE KEY UPDATE file_index = VALUES(file_index), file_name = VALUES(file_name) 6. 设计考虑 性能优化：批量操作减少数据库往返次数 原子性：整个操作在一个事务中完成 灵活性：只更新需要变更的字段 幂等性：重复执行不会产生副作用 7. 使用场景 这种批量插入或更新操作特别适合：\n初始化数据 批量导入 数据同步 需要处理大量记录的定时任务 8. 注意事项 确保表有主键或唯一键约束，否则 ON DUPLICATE KEY UPDATE 不会生效 大批量操作时可能需要分批处理，避免单条 SQL 过大 在高并发环境下注意锁竞争问题 transferVideoFile 方法详细解析 transferVideoFile 方法是一个视频文件转码和处理的核心方法，主要完成视频文件从临时目录转移到正式目录、合并分片、获取视频信息、更新状态等一系列操作。下面详细解析这个方法的每个部分。\n首先，方法被@Override注解标记，说明这是一个重写的方法。方法接收一个VideoInfoFilePost对象作为参数，这应该是一个包含视频文件相关信息的实体类。方法内部首先创建了一个updateFilePost对象，用于后续更新数据库中的文件信息。接着进入一个try块，开始主要的业务逻辑。 在try块中，首先通过redisComponent.getUploadVideoFile方法从Redis获取上传文件的信息，这里需要传入用户ID和上传ID。这表明系统使用Redis来临时存储上传过程中的文件信息，可能是为了支持断点续传或分片上传。 接下来，构建了临时文件路径tempFilePath和目标文件路径targetFilePath。这里用到了appConfig.getProjectFolder()获取项目根目录，然后拼接上常量FILE_FOLDER、FILE_FOLDER_TEMP和FILE_VIDEO，以及从Redis获取的fileDto.getFilePath()。这说明系统有明确的目录结构来管理临时文件和最终存储的视频文件。 检查目标目录是否存在，如果不存在则创建，确保目录结构正确。然后使用FileUtils.copyDirectory将临时目录下的文件复制到目标目录。这一步可能是将上传完成的文件从临时位置移动到正式存储位置。之后，删除临时目录，释放存储空间，并从Redis中删除对应的文件信息，避免数据冗余。 接下来调用this.union方法合并文件，生成完整的视频文件路径completeVideo。union方法可能负责将分片上传的视频文件合并成一个完整的文件。合并完成后，使用fFmpegUtils.getVideoInfoDuration获取视频时长，并更新updateFilePost的相关属性，包括时长、文件大小、文件路径和转码结果状态为成功。 然后调用this.convertVideo2Ts方法将视频转换为TS格式，可能是为了支持流媒体播放，比如HLS协议。转换完成后删除原始视频文件，保留转换后的TS分片。 如果在上述过程中出现异常，catch块会捕获异常并记录错误日志，同时将转码结果状态设置为失败。无论成功或失败，finally块都会执行，更新数据库中的文件状态。 在finally块中，首先通过videoInfoFilePostMapper.updateByUploadIdAndUserId更新文件信息。接着，构建查询条件，检查是否存在转码失败的文件。如果有失败的文件，更新整个视频的状态为STATUS1（可能表示转码失败）。如果没有失败的文件，再检查是否还有正在转码中的文件。如果所有文件都已处理完成，计算视频总时长并更新视频状态为STATUS2（转码完成），同时记录总时长。\n方法概述 1 2 3 4 @Override public void transferVideoFile(VideoInfoFilePost videoInfoFilePost) { // 方法实现 } 功能： 处理视频文件转码和转移流程，包括：\n从临时目录转移视频到正式目录 合并视频分片（如果有） 获取视频元信息（时长等） 更新数据库状态 处理转码失败情况 检查并更新视频整体状态 1. 初始化与准备 1 2 3 4 5 6 7 8 9 10 11 12 13 VideoInfoFilePost updateFilePost = new VideoInfoFilePost(); try { // 从Redis获取上传文件信息 UploadingFileDto fileDto = redisComponent.getUploadVideoFile(videoInfoFilePost.getUserId(), videoInfoFilePost.getUploadId()); // 设置临时文件路径 String tempFilePath = appConfig.getProjectFolder() + Constants.FILE_FOLDER + Constants.FILE_FOLDER_TEMP + fileDto.getFilePath(); File tempFile = new File(tempFilePath); // 设置目标文件路径 String targetFilePath = appConfig.getProjectFolder() + Constants.FILE_FOLDER + Constants.FILE_VIDEO + fileDto.getFilePath(); File targetFile = new File(targetFilePath); if (!targetFile.exists()) { targetFile.mkdirs(); } 解析：\n创建 updateFilePost 对象用于后续更新数据库 从 Redis 获取上传文件信息（包含文件路径等） 构造临时文件路径和目标文件路径 确保目标目录存在（不存在则创建） 2. 文件转移与处理 1 2 3 4 5 6 7 8 9 // 将文件从临时目录复制到正式目录 FileUtils.copyDirectory(tempFile, targetFile); // 删除临时目录 FileUtils.forceDelete(tempFile); // 从Redis删除文件信息 redisComponent.delVideoFileInfo(videoInfoFilePost.getUserId(), videoInfoFilePost.getUploadId()); // 合并文件（如果是分片上传） String completeVideo = targetFilePath + Constants.TEMP_VIDEO_NAME; this.union(targetFilePath, completeVideo, true); 解析：\n使用 FileUtils.copyDirectory 将文件从临时目录复制到正式目录 删除临时目录（清理空间） 从 Redis 删除已处理的文件信息 调用 union 方法合并视频分片（如果有） 3. 获取视频信息 1 2 3 4 5 6 7 8 // 获取视频时长 Integer duration = fFmpegUtils.getVideoInfoDuration(completeVideo); updateFilePost.setDuration(duration); updateFilePost.setFileSize(new File(completeVideo).length()); updateFilePost.setFilePath(Constants.FILE_VIDEO + fileDto.getFilePath()); updateFilePost.setTransferResult(VideoFileTransferResultEnum.SUCCESS.getStatus()); // 将视频转换为TS格式（用于HLS流媒体） this.convertVideo2Ts(completeVideo); 解析：\n使用 fFmpegUtils 获取视频时长 设置文件大小、路径和转码结果为成功 调用 convertVideo2Ts 将视频转换为 TS 格式（用于 HTTP Live Streaming） 4. 异常处理 1 2 3 4 } catch (Exception e) { log.error(\u0026#34;文件转码失败\u0026#34;, e); updateFilePost.setTransferResult(VideoFileTransferResultEnum.FAIL.getStatus()); } 解析：\n捕获所有异常并记录日志 设置转码结果为失败状态 5. 状态更新与检查 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 finally { // 更新文件状态 videoInfoFilePostMapper.updateByUploadIdAndUserId(updateFilePost, videoInfoFilePost.getUploadId(), videoInfoFilePost.getUserId()); // 检查是否有转码失败的视频文件 VideoInfoFilePostQuery fileQuery = new VideoInfoFilePostQuery(); fileQuery.setVideoId(videoInfoFilePost.getVideoId()); fileQuery.setTransferResult(VideoFileTransferResultEnum.FAIL.getStatus()); Integer failCount = videoInfoFilePostMapper.selectCount(fileQuery); if (failCount \u0026gt; 0) { // 如果有失败的，设置视频状态为STATUS1（可能是\u0026#34;转码失败\u0026#34;状态） VideoInfoPost videoUpdate = new VideoInfoPost(); videoUpdate.setStatus(VideoStatusEnum.STATUS1.getStatus()); videoInfoPostMapper.updateByVideoId(videoUpdate, videoInfoFilePost.getVideoId()); return; } // 检查是否还有转码中的视频文件 fileQuery.setTransferResult(VideoFileTransferResultEnum.TRANSFER.getStatus()); Integer transferCount = videoInfoFilePostMapper.selectCount(fileQuery); if (transferCount == 0) { // 如果没有转码中的文件，计算总时长并更新视频状态为STATUS2（可能是\u0026#34;转码完成\u0026#34;状态） Integer duration = videoInfoFilePostMapper.sumDuration(videoInfoFilePost.getVideoId()); VideoInfoPost videoUpdate = new VideoInfoPost(); videoUpdate.setStatus(VideoStatusEnum.STATUS2.getStatus()); videoUpdate.setDuration(duration); videoInfoPostMapper.updateByVideoId(videoUpdate, videoInfoFilePost.getVideoId()); } } 解析：\n更新文件状态：无论成功失败，都更新当前文件状态 检查失败情况： 查询该视频下是否有转码失败的文件 如果有，设置视频整体状态为失败（STATUS1） 检查转码完成情况： 查询是否还有转码中的文件 如果没有，计算视频总时长并更新状态为完成（STATUS2） 状态枚举说明 枚举值 可能含义 STATUS0 待审核/待处理 STATUS1 转码失败 STATUS2 转码完成 TRANSFER 转码中 SUCCESS 转码成功 FAIL 转码失败 方法流程图 从临时目录 → 正式目录 清理临时文件、删除 Redis 缓存 合并分片、获取元信息、转码 更新单个文件状态 检查并更新整体视频状态 关键点总结 文件转移流程：从临时目录 → 正式目录，清理临时文件，删除 Redis 缓存 视频处理：合并分片（如需要）、获取元信息（时长、大小）、转换为 TS 格式（用于流媒体） 状态管理：单个文件状态更新、整体视频状态检查、失败处理和成功状态更新 事务完整性：try-catch 确保异常被捕获，finally 块确保状态一定会更新，全面的状态检查机制 优化点 异步处理：视频转码是耗时操作，可以考虑使用消息队列异步处理 进度反馈：可以增加转码进度反馈机制 重试机制：对于失败的转码任务可以加入重试逻辑 资源清理：确保在任何异常情况下都能正确清理临时资源 状态枚举：建议使用更具描述性的枚举名称，如 \u0026ldquo;TRANSCODE_COMPLETED\u0026rdquo; 而非 \u0026ldquo;STATUS2\u0026rdquo; convertVideo2Ts 和 union 方法详细解析 这两个方法是 transferVideoFile 中用于视频文件处理的核心辅助方法，下面结合它们在 transferVideoFile 中的使用场景进行详细解释。\n1. convertVideo2Ts 方法解析 方法签名\n1 private void convertVideo2Ts(String videoFilePath) 功能说明\n负责将视频文件转换为 TS（Transport Stream）格式，主要用于 HLS（HTTP Live Streaming）视频流的分片处理。 执行流程\n获取视频文件信息 1 2 3 File videoFile = new File(videoFilePath); File tsFolder = videoFile.getParentFile(); String codec = fFmpegUtils.getVideoCodec(videoFilePath); HEVC 编码转换 1 2 3 4 5 6 if (Constants.VIDEO_CODE_HEVC.equals(codec)) { String tempFileName = videoFilePath + Constants.VIDEO_CODE_TEMP_FILE_SUFFIX; new File(videoFilePath).renameTo(new File(tempFileName)); fFmpegUtils.convertHevc2Mp4(tempFileName, videoFilePath); new File(tempFileName).delete(); } 如果视频是 HEVC 编码（H.265），先转换为 MP4 格式（H.264）。 使用临时文件进行转换，完成后删除临时文件。 转换为 TS 格式 1 fFmpegUtils.convertVideo2Ts(tsFolder, videoFilePath); 删除原始视频文件 1 videoFile.delete(); 在 transferVideoFile 中的使用\n1 this.convertVideo2Ts(completeVideo); 在文件转移完成后调用，确保视频格式适合流媒体播放，处理特殊编码格式的兼容性问题。 2. union 方法解析 方法签名\n1 private void union(String dirPath, String toFilePath, Boolean delSource) 功能说明\n用于合并分片视频文件，将多个分片文件合并为一个完整的视频文件。 执行流程\n参数验证 1 2 3 4 File dir = new File(dirPath); if (!dir.exists()) { throw new BusinessException(\u0026#34;目录不存在\u0026#34;); } 获取分片文件列表 1 File fileList[] = dir.listFiles(); 创建目标文件 1 File targetFile = new File(toFilePath); 合并文件内容 1 2 3 4 5 6 7 8 9 10 11 12 try (RandomAccessFile writeFile = new RandomAccessFile(targetFile, \u0026#34;rw\u0026#34;)) { byte[] b = new byte[1024 * 10]; // 10KB缓冲区 for (int i = 0; i \u0026lt; fileList.length; i++) { File chunkFile = new File(dirPath + File.separator + i); try (RandomAccessFile readFile = new RandomAccessFile(chunkFile, \u0026#34;r\u0026#34;)) { int len; while ((len = readFile.read(b)) != -1) { writeFile.write(b, 0, len); } } } } 使用随机访问文件高效读写，按顺序合并所有分片。 使用 try-with-resources 确保资源释放。 清理源文件（可选） 1 2 3 4 5 if (delSource) { for (File file : fileList) { file.delete(); } } 在 transferVideoFile 中的使用\n1 this.union(targetFilePath, completeVideo, true); 用于合并分片上传的视频文件，delSource=true 表示合并后删除分片文件，生成完整的视频文件供后续处理。 3. 两个方法的协作关系 transferVideoFile 中的处理顺序： 文件转移：从临时目录移动到正式目录 文件合并（union 方法）：将分片合并为完整视频，删除分片文件 格式转换（convertVideo2Ts 方法）：检查并转换编码格式，转换为 TS 格式用于流媒体，删除原始文件 4. 设计考虑 分片处理：支持大文件分片上传，合并时确保文件顺序正确 格式兼容性：处理 HEVC 等特殊编码，转换为广泛支持的格式 资源管理：及时清理临时文件，使用缓冲区提高 IO 效率，确保文件句柄正确释放 错误处理：明确的异常抛出，资源清理放在 finally 块 5. 典型使用场景 分片上传处理流程： 用户上传视频分片 所有分片上传完成后触发 transferVideoFile 合并分片 → 转码 → 生成流媒体格式 视频处理流程： 原始视频 → 检查编码 → 转换 → TS 切片，为 HLS 流媒体做准备 6. 潜在优化点 并行处理：分片合并可以使用多线程加速 进度反馈：添加转码进度回调 错误恢复：记录处理进度，支持断点续处理 资源控制：限制并发转码任务数，监控系统负载 这两个方法共同构成了视频处理管道的核心环节，将上传的视频文件最终转换为可流式传输的标准格式。\nauditVideo 方法详细解析 auditVideo 方法是视频审核的核心方法，负责处理视频审核状态的变更、用户积分奖励、数据同步以及文件清理等操作。下面从功能、流程、设计思路等方面进行全面解析。\n1. 方法概述 1 2 3 4 5 @Override @Transactional(rollbackFor = Exception.class) public void auditVideo(String videoId, Integer status, String reason) { // 方法实现 } 功能： 处理视频审核流程，包括：\n验证审核状态合法性 更新视频审核状态 处理审核通过/不通过的逻辑分支 用户积分奖励（首次发布） 数据同步到正式表 清理待删除文件 同步数据到搜索引擎 参数：\nvideoId：视频唯一标识 status：目标审核状态 reason：审核原因（如不通过原因） 事务控制： @Transactional(rollbackFor = Exception.class) 确保方法内所有数据库操作要么全部成功，要么全部回滚\n2. 方法流程详解 2.1 状态验证 1 2 3 4 VideoStatusEnum videoStatusEnum = VideoStatusEnum.getByStatus(status); if (videoStatusEnum == null) { throw new BusinessException(ResponseCodeEnum.CODE_600); } 验证传入的审核状态是否合法，非法状态直接抛出业务异常。 使用枚举 VideoStatusEnum 管理所有可能的视频状态。 2.2 更新视频状态（带条件） 1 2 3 4 5 6 7 8 9 10 11 VideoInfoPost videoInfoPost = new VideoInfoPost(); videoInfoPost.setStatus(status); VideoInfoPostQuery videoInfoPostQuery = new VideoInfoPostQuery(); videoInfoPostQuery.setStatus(VideoStatusEnum.STATUS2.getStatus()); videoInfoPostQuery.setVideoId(videoId); Integer auditCount = this.videoInfoPostMapper.updateByParam(videoInfoPost, videoInfoPostQuery); if (auditCount == 0) { throw new BusinessException(\u0026#34;审核失败，请稍后重试\u0026#34;); } 将视频从\u0026quot;待审核\u0026quot;状态更新为目标审核状态。 乐观锁机制：更新条件包含当前状态（STATUS2 表示待审核），防止并发修改导致状态混乱。 如果影响行数为 0，说明视频不满足更新条件（可能已被其他审核员处理）。 2.3 更新关联文件状态 1 2 3 4 5 6 VideoInfoFilePost videoInfoFilePost = new VideoInfoFilePost(); videoInfoFilePost.setUpdateType(VideoFileUpdateTypeEnum.NO_UPDATE.getStatus()); VideoInfoFilePostQuery filePostQuery = new VideoInfoFilePostQuery(); filePostQuery.setVideoId(videoId); this.videoInfoFilePostMapper.updateByParam(videoInfoFilePost, filePostQuery); 将所有关联文件的 updateType 标记为\u0026quot;无需更新\u0026quot;，表示这些文件已经完成审核流程。 2.4 处理审核不通过情况 1 2 3 if (VideoStatusEnum.STATUS4 == videoStatusEnum) { // 审核不通过 return; } 如果审核状态为\u0026quot;不通过\u0026quot;(STATUS4)，直接返回，不执行后续的积分奖励、数据同步等操作。 2.5 首次发布奖励积分 1 2 3 4 5 6 VideoInfoPost infoPost = this.videoInfoPostMapper.selectByVideoId(videoId); VideoInfo dbVideoInfo = this.videoInfoMapper.selectByVideoId(videoId); if (dbVideoInfo == null) { SysSettingDto sysSettingDto = redisComponent.getSysSettingDto(); userInfoMapper.updateCoinCountInfo(infoPost.getUserId(), sysSettingDto.getPostVideoCoinCount()); } 检查视频是否首次发布（正式表中不存在记录），如果是首次发布，给视频作者增加相应积分。 奖励机制鼓励用户发布内容，积分数量配置在系统设置中，便于灵活调整。 2.6 同步数据到正式表 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 // 将发布信息复制到正式表 VideoInfo videoInfo = CopyTools.copy(infoPost, VideoInfo.class); this.videoInfoMapper.insertOrUpdate(videoInfo); // 先删除旧文件信息 VideoInfoFileQuery videoInfoFileQuery = new VideoInfoFileQuery(); videoInfoFileQuery.setVideoId(videoId); this.videoInfoFileMapper.deleteByParam(videoInfoFileQuery); // 从发布表查询并插入到正式表 VideoInfoFilePostQuery videoInfoFilePostQuery = new VideoInfoFilePostQuery(); videoInfoFilePostQuery.setVideoId(videoId); List\u0026lt;VideoInfoFilePost\u0026gt; videoInfoFilePostList = this.videoInfoFilePostMapper.selectList(videoInfoFilePostQuery); List\u0026lt;VideoInfoFile\u0026gt; videoInfoFileList = CopyTools.copyList(videoInfoFilePostList, VideoInfoFile.class); this.videoInfoFileMapper.insertBatch(videoInfoFileList); 主表同步：将发布表（VideoInfoPost）数据拷贝到正式表（VideoInfo）。 文件表同步：先删除正式文件表中该视频的所有记录，再从发布文件表查询所有相关文件，批量插入到正式文件表。 使用 CopyTools 实现对象深拷贝，先删除后插入确保数据一致性。 2.7 清理待删除文件 1 2 3 4 5 6 7 8 9 10 11 12 13 14 List\u0026lt;String\u0026gt; filePathList = redisComponent.getDelFileList(videoId); if (filePathList != null) { for (String path : filePathList) { File file = new File(appConfig.getProjectFolder() + Constants.FILE_FOLDER + path); if (file.exists()) { try { FileUtils.deleteDirectory(file); } catch (IOException e) { log.error(\u0026#34;删除文件失败\u0026#34;, e); } } } } redisComponent.cleanDelFileList(videoId); 从 Redis 获取该视频的待删除文件列表，遍历列表删除实际文件，清理 Redis 中的记录。 业务场景：用户编辑视频时删除的旧文件、转码过程中生成的临时文件、审核通过后不再需要的中间文件。 2.8 同步到搜索引擎 1 esSearchComponent.saveDoc(videoInfo); 将视频信息索引到 Elasticsearch，使视频可被搜索，支持复杂的搜索条件和排序。 3. 状态机设计 状态枚举 状态含义 可流转至 STATUS0 待处理/初始状态 STATUS2 STATUS2 待审核 STATUS3/STATUS4 STATUS3 审核通过 - STATUS4 审核不通过 - 只有 STATUS2（待审核）状态的视频才能被审核，审核后变为 STATUS3（通过）或 STATUS4（不通过）。 状态变更采用乐观锁控制。 4. 数据表设计分析 发布表（待审核数据）：\nvideo_info_post：视频主信息 video_info_file_post：视频文件信息 正式表（已审核数据）：\nvideo_info：视频主信息 video_info_file：视频文件信息 用户表：\nuser_info：存储用户积分 发布与正式数据隔离，避免审核中数据污染生产环境。\n两套表结构相同，便于使用工具类拷贝。\n审核通过后才同步到正式表，保证数据质量。\n5. 异常处理设计 业务异常：非法状态参数立即抛出，更新行数为 0 视为并发冲突，提示重试。 系统异常：文件删除失败记录日志但不中断流程，其他异常由事务注解处理自动回滚。 方法级事务保证数据一致性，非关键操作（如文件删除）在事务外处理。 6. 潜在优化建议 审核日志：建议增加审核人和审核原因的审计日志。 性能优化：大批量文件删除可考虑异步化，Elasticsearch 同步可加入队列异步处理。 状态扩展：可增加\u0026quot;审核中\u0026quot;状态，避免长时间审核导致的并发问题。 文件清理：增加删除重试机制，提高文件清理成功率。 配置灵活性：审核通过后的操作（如积分奖励）可通过策略模式实现动态配置。 7. 总结 auditVideo 方法是一个完整的视频审核解决方案，具有以下特点： 严谨的状态管理：通过枚举和乐观锁确保状态流转安全 数据隔离设计：发布数据与正式数据物理分离 完整的业务流程：涵盖状态更新、积分奖励、数据同步、文件清理等 良好的异常处理：区分业务异常和系统异常，关键操作事务保障 可扩展性：模块化设计便于新增审核后操作 该方法体现了生产级审核系统的核心设计思想，兼顾了功能性、安全性和可维护性。 MySQL中LEFT JOIN与INNER JOIN的使用场景 在MySQL数据库查询中，JOIN操作是最常用的操作之一，而LEFT JOIN和INNER JOIN是两种最基础的JOIN类型。理解它们的区别和适用场景对于编写高效、准确的SQL查询至关重要。\n核心区别 特性 INNER JOIN LEFT JOIN 结果集 只返回两表中匹配的行 返回左表所有行，右表不匹配则为NULL 数据丢失 不匹配的行会被过滤掉 保留左表所有数据 性能 通常更快 通常稍慢 使用频率 高 高 INNER JOIN（内连接）使用场景 1. 需要严格匹配关系的查询 1 2 3 4 -- 查询有订单的客户信息 SELECT customers.name, orders.order_date FROM customers INNER JOIN orders ON customers.id = orders.customer_id; 适用情况：\n只关心两个表中都存在关联记录的数据 需要排除任何一边没有匹配项的数据 2. 多表关联且需要所有表都有匹配 1 2 3 4 5 -- 查询同时有订单和付款记录的客户 SELECT c.name, o.order_date, p.amount FROM customers c INNER JOIN orders o ON c.id = o.customer_id INNER JOIN payments p ON o.id = p.order_id; 3. 性能优先的查询 INNER JOIN 通常比 LEFT JOIN 性能更好，特别是在大表关联时。 LEFT JOIN（左连接）使用场景 1. 需要包含左表所有记录的查询 1 2 3 4 -- 查询所有客户及其订单(包括没有订单的客户) SELECT customers.name, orders.order_date FROM customers LEFT JOIN orders ON customers.id = orders.customer_id; 适用情况：\n需要保留左表所有记录，无论右表是否有匹配 需要统计\u0026quot;有\u0026quot;和\u0026quot;没有\u0026quot;的情况 2. 检测缺失数据的查询 1 2 3 4 5 -- 查找没有订单的客户 SELECT customers.name FROM customers LEFT JOIN orders ON customers.id = orders.customer_id WHERE orders.id IS NULL; 3. 分级数据查询 1 2 3 4 -- 查询部门及员工(包括没有员工的部门) SELECT departments.name, employees.employee_name FROM departments LEFT JOIN employees ON departments.id = employees.dept_id; 选择依据 业务需求： 是否需要保留不匹配的记录？ 是否要计算存在/不存在的记录？ 数据完整性： 如果右表数据必须存在，用 INNER JOIN 如果右表数据可选，用 LEFT JOIN 性能考虑： 大表关联优先考虑 INNER JOIN 必要时可以用 LEFT JOIN 配合索引优化 性能优化建议 为JOIN条件建立索引： 1 ALTER TABLE orders ADD INDEX (customer_id); 限制结果集大小： 1 2 3 SELECT * FROM large_table l LEFT JOIN small_table s ON l.id = s.large_id LIMIT 1000; 避免不必要的LEFT JOIN： 如果业务上右表数据必须存在，使用 INNER JOIN 更高效 实际案例对比 场景：电商系统中的订单查询\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 -- 方案1: INNER JOIN (只查询有客户的订单) SELECT o.order_id, c.customer_name FROM orders o INNER JOIN customers c ON o.customer_id = c.customer_id; -- 方案2: LEFT JOIN (查询所有订单，包括客户信息缺失的) SELECT o.order_id, c.customer_name FROM orders o LEFT JOIN customers c ON o.customer_id = c.customer_id; -- 方案3: LEFT JOIN查找异常数据 (客户信息缺失的订单) SELECT o.order_id FROM orders o LEFT JOIN customers c ON o.customer_id = c.customer_id WHERE c.customer_id IS NULL; 总结 使用 INNER JOIN： 当你确定关联数据必须存在，且只需要匹配成功的记录时 使用 LEFT JOIN： 当需要保留左表所有记录，无论是否匹配，或者需要查找缺失关联数据时 正确选择 JOIN 类型不仅能确保查询结果的准确性，还能显著影响查询性能。在设计查询时，应先明确业务需求，再决定使用哪种 JOIN 方式。\n跨系统事务处理策略 在分布式系统或微服务架构下，常常需要在一个业务流程中同时操作本地数据库和远程系统（如调用外部接口写入其它服务器数据库）。如何保证数据一致性和高可用，是实际开发中的常见难题。\n执行顺序建议：先本地后远程 性能考虑： 本地操作通常比远程调用更快，先完成快速操作可减少资源锁定时间。 错误处理： 本地操作失败可直接回滚，避免不必要的远程调用。 数据一致性： 先保证本地数据一致，远程调用作为后续补偿的基础。 超时处理方案 1. 本地事务+异步通知（推荐） 1 2 3 4 5 6 7 8 9 10 11 12 13 14 @Transactional public void processTransaction() { // 1. 先执行本地数据库操作 localRepository.save(data); try { // 2. 尝试同步调用远程接口（设置合理超时时间） remoteService.callWithTimeout(remoteData, 3, TimeUnit.SECONDS); } catch (TimeoutException e) { // 3. 如果超时，将任务放入重试队列 mqService.sendToRetryQueue(remoteData); // 本地事务仍然提交 } // 其他本地操作... } 配套措施：\n建立消息队列和重试机制 监控未完成的远程调用 提供人工干预接口 2. 两阶段提交模式 图\n本地数据库预提交（不实际生效） 远程服务预提交（资源预留） 确认都成功后最终提交，否则回滚两边 超时具体处理策略 1. 短超时+快速失败 1 2 3 // 设置合理的超时时间（根据业务需求调整） HttpClient client = HttpClient.create() .responseTimeout(Duration.ofSeconds(2)); 2. 重试机制 1 2 3 4 5 RetryPolicy retryPolicy = new RetryPolicy() .withMaxAttempts(3) .withDelay(1, TimeUnit.SECONDS); Failsafe.with(retryPolicy) .get(() -\u0026gt; remoteService.call(remoteData)); 3. 补偿事务 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 @Transactional public void mainOperation() { // 记录操作流水 auditLogRepository.logOperationStart(); // 本地数据库操作 localRepository.update(data); } // 补偿任务（定时执行） public void compensateOperation() { List\u0026lt;UnfinishedOperation\u0026gt; operations = auditLogRepository.findUnfinished(); operations.forEach(op -\u0026gt; { try { remoteService.retry(op.getData()); auditLogRepository.markAsCompleted(op.getId()); } catch (Exception e) { // 报警通知人工处理 alertService.notifyAdmin(op, e); } }); } 架构设计建议 最终一致性模式 使用事件溯源（Event Sourcing） 实现可靠事件总线 服务降级方案 1 2 3 4 5 6 7 8 9 10 public void process() { try { remoteService.call(remoteData); } catch (Exception e) { // 降级处理：记录到本地待处理表 fallbackRepository.savePendingTask(remoteData); // 触发告警 monitoringService.alert(\u0026#34;Remote call failed\u0026#34;, e); } } 监控指标 远程调用成功率 平均响应时间 待补偿事务数量 补偿成功率 决策流程图 总结建议 常规场景： 采用\u0026quot;先本地后远程+异步重试\u0026quot;方案 金融等严格场景： 考虑两阶段提交或Saga模式 必须保证： 本地操作的可回滚性 远程调用的幂等性 完善的监控报警机制 通过这种设计，即使在远程调用超时的情况下，系统仍能保持最终一致性，同时避免长时间的资源锁定和用户等待。\n关于Spring事务内部调用的问题 在代码中，topComment方法调用cancelTopComment方法，这种内部调用不会导致事务失效，因为：\ntopComment方法有@Transactional注解，创建了一个事务 cancelTopComment方法被topComment调用时，是在同一个类内部的方法调用 Spring的事务代理是基于AOP实现的，内部调用不会经过代理对象\n1. 方法内部调用（最常见） 1 2 3 4 5 6 7 8 9 10 @Service public class MyService { public void outerMethod() { innerMethod(); // 事务失效 } @Transactional public void innerMethod() { // 数据库操作 } } 失效原因：内部调用绕过了Spring的代理机制。 2. 事务方法不是public 1 2 3 4 @Transactional private void myMethod() { // 事务失效 // ... } 失效原因：Spring AOP无法代理非public方法。 3. 异常被捕获未抛出 1 2 3 4 5 6 7 8 @Transactional public void myMethod() { try { // 数据库操作 } catch (Exception e) { // 捕获异常但不抛出 } } 失效原因：事务回滚需要异常传播到事务管理器。 4. 异常类型不匹配 1 2 3 4 @Transactional(rollbackFor = RuntimeException.class) public void myMethod() throws Exception { throw new Exception(); // 事务不会回滚 } 失效原因：抛出的异常类型不在rollbackFor指定的范围内。 5. 多线程调用 1 2 3 4 5 6 @Transactional public void myMethod() { new Thread(() -\u0026gt; { // 数据库操作 - 事务失效 }).start(); } 失效原因：事务信息绑定在线程本地变量(ThreadLocal)中，新线程无法获取。 6. 数据库引擎不支持事务 例如使用MyISAM引擎的MySQL表，天然不支持事务。 如何确保事务有效 将需要事务的方法提取到单独的Service类中 通过注入的Service代理对象调用方法（而不是内部调用） 确保方法为public 正确处理异常 使用支持事务的数据库引擎\n视频在线人数统计系统实现详解 1. 系统架构概述 本系统基于 Redis 实现，主要包含：\n心跳上报接口：客户端定期调用以维持在线状态 Redis 存储结构：使用两种键存储在线信息 过期监听机制：通过 Redis 的键过期事件自动减少在线人数 计数维护逻辑：确保在线人数的准确性 2. 核心实现细节 2.1 数据结构设计 用户播放键 (userPlayOnlineKey) 格式：video:play:user:{fileId}:{deviceId} 作用：标记特定设备是否在线 过期时间：8秒 在线计数键 (playOnlineCountKey) 格式：video:play:online:{fileId} 作用：存储当前视频的在线人数 过期时间：10秒 2.2 心跳上报流程 1 2 3 4 5 6 7 8 9 10 11 12 public Integer reportVideoPlayOnline(String fileId, String deviceId) { String userPlayOnlineKey = String.format(Constants.REDIS_KEY_VIDEO_PLAY_COUNT_USER, fileId, deviceId); String playOnlineCountKey = String.format(Constants.REDIS_KEY_VIDEO_PLAY_COUNT_ONLINE, fileId); if (!redisUtils.keyExists(userPlayOnlineKey)) { redisUtils.setex(userPlayOnlineKey, fileId, Constants.REDIS_KEY_EXPIRES_ONE_SECONDS * 8); return redisUtils.incrementex(playOnlineCountKey, Constants.REDIS_KEY_EXPIRES_ONE_SECONDS * 10).intValue(); } redisUtils.expire(playOnlineCountKey, Constants.REDIS_KEY_EXPIRES_ONE_SECONDS * 10); redisUtils.expire(userPlayOnlineKey, Constants.REDIS_KEY_EXPIRES_ONE_SECONDS * 8); Integer count = (Integer) redisUtils.get(playOnlineCountKey); return count == null ? 1 : count; } 客户端每5-7秒调用一次接口 新用户：创建用户键并增加计数 已有用户：续期两个键 返回当前在线人数 2.3 过期监听机制 1 2 3 4 5 6 7 8 9 10 @Override public void onMessage(Message message, byte[] pattern) { String key = message.toString(); if (!key.startsWith(Constants.REDIS_KEY_VIDEO_PLAY_COUNT_ONLINE_PREIFX + Constants.REDIS_KEY_VIDEO_PLAY_COUNT_USER_PREFIX)) { return; } Integer userKeyIndex = key.indexOf(Constants.REDIS_KEY_VIDEO_PLAY_COUNT_USER_PREFIX) + Constants.REDIS_KEY_VIDEO_PLAY_COUNT_USER_PREFIX.length(); String fileId = key.substring(userKeyIndex, userKeyIndex + Constants.LENGTH_20); redisComponent.decrementPlayOnlineCount(String.format(Constants.REDIS_KEY_VIDEO_PLAY_COUNT_ONLINE, fileId)); } 用户键过期时自动减少对应视频的在线人数 2.4 计数递减逻辑 1 2 3 public void decrementPlayOnlineCount(String key) { redisUtils.decrement(key); } 3. 关键设计原理 双键设计：用户键作为心跳，计数键集中存储人数，过期时间错开防止竞态 时间参数：8秒用户键，10秒计数键，客户端建议5-7秒上报 容错机制：计数键续期，空值处理，精确递减 4. 系统优势 实时性高：秒级检测用户离线 性能优异：完全基于Redis内存操作 扩展性强：支持大量并发用户 资源节约：自动清理不活跃用户 5. 潜在优化方向 批量上报、分布式锁、异常重试、监控报警、动态过期 WebSocket及其在在线人数统计中的应用 1. WebSocket 基础介绍 WebSocket 是一种全双工通信协议，支持服务端主动推送数据。 与 HTTP 轮询相比，WebSocket 连接持久、实时性高、资源消耗低。 特性 WebSocket HTTP 轮询 连接方式 持久化连接 每次新建连接 通信方向 全双工 半双工 实时性 毫秒级 秒级 服务器推送 支持 不支持 资源消耗 初期开销大，后期小 每次请求都高 2. 基于 WebSocket 的在线人数统计实现 2.1 服务端实现（Spring Boot） 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 @ServerEndpoint(\u0026#34;/online/{videoId}\u0026#34;) @Component public class VideoOnlineEndpoint { private static ConcurrentMap\u0026lt;String, Set\u0026lt;Session\u0026gt;\u0026gt; videoSessions = new ConcurrentHashMap\u0026lt;\u0026gt;(); private static RedisTemplate\u0026lt;String, String\u0026gt; redisTemplate; @Autowired public void setRedisTemplate(RedisTemplate\u0026lt;String, String\u0026gt; redisTemplate) { VideoOnlineEndpoint.redisTemplate = redisTemplate; } @OnOpen public void onOpen(Session session, @PathParam(\u0026#34;videoId\u0026#34;) String videoId) { videoSessions.computeIfAbsent(videoId, k -\u0026gt; ConcurrentHashMap.newKeySet()).add(session); String redisKey = \u0026#34;video:online:\u0026#34; + videoId; redisTemplate.opsForValue().increment(redisKey); redisTemplate.expire(redisKey, 10, TimeUnit.MINUTES); broadcastOnlineCount(videoId); } @OnClose public void onClose(Session session, @PathParam(\u0026#34;videoId\u0026#34;) String videoId) { Set\u0026lt;Session\u0026gt; sessions = videoSessions.get(videoId); if (sessions != null) { sessions.remove(session); String redisKey = \u0026#34;video:online:\u0026#34; + videoId; redisTemplate.opsForValue().decrement(redisKey); broadcastOnlineCount(videoId); } } @OnError public void onError(Session session, Throwable error) { error.printStackTrace(); } private void broadcastOnlineCount(String videoId) { String count = redisTemplate.opsForValue().get(\u0026#34;video:online:\u0026#34; + videoId); String message = \u0026#34;ONLINE_COUNT:\u0026#34; + (count != null ? count : \u0026#34;0\u0026#34;); Set\u0026lt;Session\u0026gt; sessions = videoSessions.get(videoId); if (sessions != null) { sessions.forEach(session -\u0026gt; { try { session.getBasicRemote().sendText(message); } catch (IOException e) { e.printStackTrace(); } }); } } } 2.2 客户端实现（JavaScript） 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 const videoId = \u0026#39;12345\u0026#39;; const socket = new WebSocket(`wss://yourdomain.com/online/${videoId}`); socket.onopen = function(e) { console.log(\u0026#34;WebSocket连接已建立\u0026#34;); }; socket.onmessage = function(event) { if(event.data.startsWith(\u0026#34;ONLINE_COUNT:\u0026#34;)) { const count = event.data.split(\u0026#34;:\u0026#34;)[1]; updateOnlineCountDisplay(count); } }; socket.onclose = function(event) { if (event.wasClean) { console.log(`连接正常关闭，code=${event.code} reason=${event.reason}`); } else { setTimeout(() =\u0026gt; connectWebSocket(), 5000); } }; socket.onerror = function(error) { console.log(`WebSocket错误: ${error.message}`); }; function updateOnlineCountDisplay(count) { document.getElementById(\u0026#39;online-count\u0026#39;).innerText = count; } 2.3 心跳机制 1 2 3 4 5 setInterval(() =\u0026gt; { if(socket.readyState === WebSocket.OPEN) { socket.send(\u0026#34;HEARTBEAT\u0026#34;); } }, 30000); 服务端：\n1 2 3 4 5 6 @OnMessage public void onMessage(Session session, String message) { if(\u0026#34;HEARTBEAT\u0026#34;.equals(message)) { session.getAsyncRemote().sendText(\u0026#34;HEARTBEAT_ACK\u0026#34;); } } 3. 方案优势分析 实时性极佳，精确计数，扩展功能容易，减少无效请求 支持自动重连、心跳检测、集群扩展、协议优化、资源控制、监控体系、优雅降级 4. 适用场景建议 WebSocket适合高实时性、精确计数、互动场景 Redis方案适合简单、兼容性强、对实时性要求不高的场景 可采用混合方案：WebSocket客户端用本地计数，非WebSocket客户端用Redis计数 Netty与视频在线人数统计的结合 1. Netty基础介绍 Netty是高性能、异步事件驱动的网络应用框架，适合高并发、低延迟场景。 支持TCP/UDP、WebSocket等协议，适合实现长连接、实时通信。 2. 为什么用Netty实现在线人数统计？ HTTP轮询开销大、实时性有限、服务器压力大 Netty支持长连接、毫秒级实时、低协议开销、超高并发 3. 基于Netty的在线人数统计设计 3.1 系统架构 客户端App/Web → Netty服务器集群 → Redis集群 WebSocket/TCP长连接，用户行为数据实时上报 3.2 核心组件实现 Netty服务器初始化 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 public class VideoOnlineServer { public void start(int port) { EventLoopGroup bossGroup = new NioEventLoopGroup(); EventLoopGroup workerGroup = new NioEventLoopGroup(); try { ServerBootstrap b = new ServerBootstrap(); b.group(bossGroup, workerGroup) .channel(NioServerSocketChannel.class) .childHandler(new ChannelInitializer\u0026lt;SocketChannel\u0026gt;() { @Override protected void initChannel(SocketChannel ch) { ChannelPipeline pipeline = ch.pipeline(); pipeline.addLast(\u0026#34;idleStateHandler\u0026#34;, new IdleStateHandler(15, 0, 0, TimeUnit.SECONDS)); pipeline.addLast(\u0026#34;decoder\u0026#34;, new OnlineMessageDecoder()); pipeline.addLast(\u0026#34;encoder\u0026#34;, new OnlineMessageEncoder()); pipeline.addLast(\u0026#34;handler\u0026#34;, new OnlineMessageHandler()); } }); ChannelFuture f = b.bind(port).sync(); f.channel().closeFuture().sync(); } finally { workerGroup.shutdownGracefully(); bossGroup.shutdownGracefully(); } } } 消息处理器实现 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 public class OnlineMessageHandler extends SimpleChannelInboundHandler\u0026lt;OnlineMessage\u0026gt; { private static Map\u0026lt;String, ChannelGroup\u0026gt; videoGroups = new ConcurrentHashMap\u0026lt;\u0026gt;(); @Override protected void channelRead0(ChannelHandlerContext ctx, OnlineMessage msg) { switch (msg.getType()) { case CONNECT: handleConnect(ctx, msg.getVideoId(), msg.getDeviceId()); break; case HEARTBEAT: handleHeartbeat(ctx, msg.getVideoId(), msg.getDeviceId()); break; case DISCONNECT: handleDisconnect(ctx, msg.getVideoId(), msg.getDeviceId()); break; } } private void handleConnect(ChannelHandlerContext ctx, String videoId, String deviceId) { ChannelGroup group = videoGroups.computeIfAbsent(videoId, k -\u0026gt; new DefaultChannelGroup(GlobalEventExecutor.INSTANCE)); group.add(ctx.channel()); long count = RedisUtils.increment(\u0026#34;video:online:\u0026#34; + videoId); broadcastCount(videoId, count); } private void handleHeartbeat(ChannelHandlerContext ctx, String videoId, String deviceId) { RedisUtils.setex(\u0026#34;device:active:\u0026#34; + videoId + \u0026#34;:\u0026#34; + deviceId, \u0026#34;1\u0026#34;, 15); ctx.writeAndFlush(new OnlineMessage(HEARTBEAT_ACK, getOnlineCount(videoId))); } } 客户端断连处理 1 2 3 4 5 6 7 8 9 10 11 12 13 14 @Override public void channelInactive(ChannelHandlerContext ctx) { videoGroups.values().forEach(group -\u0026gt; group.remove(ctx.channel())); String deviceId = getDeviceId(ctx.channel()); String videoId = getVideoId(ctx.channel()); long count = RedisUtils.decrement(\u0026#34;video:online:\u0026#34; + videoId); broadcastCount(videoId, count); } @Override public void userEventTriggered(ChannelHandlerContext ctx, Object evt) { if (evt instanceof IdleStateEvent) { ctx.close(); } } 4. 与传统方案的对比 特性 Netty实现方案 HTTP轮询+Redis方案 实时性 毫秒级 秒级 协议开销 低 高 并发能力 10万+ 受限于HTTP服务器 实现复杂度 较高 简单 5. 适用场景建议 Netty适合高实时互动、超高并发、长连接场景 HTTP轮询适合实时性要求不高、开发资源有限、兼容性要求高的场景 Netty与WebSocket的关系及在实时统计中的应用 1. Netty与WebSocket的基础关系 维度 Netty WebSocket 二者关系 定位 网络应用框架 通信协议 Netty是实现WebSocket协议的底层框架之一 层级 传输层/应用层框架 应用层协议 Netty提供了对WebSocket协议的支持 功能 处理TCP/UDP连接、编解码、并发等 提供全双工通信能力 Netty帮助高效实现WebSocket的通信能力 典型使用 可作为WebSocket服务器的基础实现 运行在Netty等框架之上 开发者通过Netty API构建WebSocket服务 2. 技术栈组合原理 WebSocket客户端 ←WebSocket协议→ Netty WebSocket服务端 ←TCP→ 操作系统网络栈 Netty内置WebSocketServerProtocolHandler等组件，自动处理握手、帧编解码 Netty的Reactor线程模型优化WebSocket连接管理 3. 在视频在线统计中的联合实现 基于Netty的WebSocket服务端示例 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 public class VideoWebSocketServer { public void start(int port) { EventLoopGroup bossGroup = new NioEventLoopGroup(); EventLoopGroup workerGroup = new NioEventLoopGroup(); try { ServerBootstrap b = new ServerBootstrap(); b.group(bossGroup, workerGroup) .channel(NioServerSocketChannel.class) .childHandler(new ChannelInitializer\u0026lt;SocketChannel\u0026gt;() { @Override protected void initChannel(SocketChannel ch) { ChannelPipeline pipeline = ch.pipeline(); pipeline.addLast(new HttpServerCodec()); pipeline.addLast(new HttpObjectAggregator(65536)); pipeline.addLast(new WebSocketServerProtocolHandler(\u0026#34;/ws\u0026#34;)); pipeline.addLast(new OnlineStatsHandler()); } }); ChannelFuture f = b.bind(port).sync(); f.channel().closeFuture().sync(); } finally { workerGroup.shutdownGracefully(); bossGroup.shutdownGracefully(); } } } 在线统计业务处理器 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 public class OnlineStatsHandler extends SimpleChannelInboundHandler\u0026lt;TextWebSocketFrame\u0026gt; { private static Map\u0026lt;String, ChannelGroup\u0026gt; videoGroups = new ConcurrentHashMap\u0026lt;\u0026gt;(); @Override protected void channelRead0(ChannelHandlerContext ctx, TextWebSocketFrame msg) { JsonObject json = parseJson(msg.text()); String videoId = json.getString(\u0026#34;videoId\u0026#34;); ChannelGroup group = videoGroups.computeIfAbsent(videoId, k -\u0026gt; new DefaultChannelGroup(ctx.executor())); switch (json.getString(\u0026#34;action\u0026#34;)) { case \u0026#34;join\u0026#34;: group.add(ctx.channel()); broadcastCount(videoId, group.size()); break; case \u0026#34;heartbeat\u0026#34;: redis.incr(\u0026#34;active:\u0026#34; + videoId + \u0026#34;:\u0026#34; + ctx.channel().id()); break; } } @Override public void channelInactive(ChannelHandlerContext ctx) { videoGroups.values().forEach(group -\u0026gt; { if (group.remove(ctx.channel())) { broadcastCount(getVideoId(ctx), group.size()); } }); } } 4. 典型消息流程 连接建立：客户端 → HTTP Upgrade请求 → Netty(完成WebSocket握手) → 建立持久连接 心跳维持：客户端定期发送心跳，服务端响应ack 人数推送：服务端主动推送最新在线人数 5. 优化点 连接管理：ChannelGroup管理房间，IdleStateHandler检测死连接 序列化优化：可用二进制协议代替JSON 集群扩展：Redis Pub/Sub同步各节点状态 监控指标：跟踪每个视频频道的连接数、消息吞吐量和延迟 视频删除方法详解 1. 方法整体功能 该 deleteVideo 方法是一个综合性的视频删除操作，主要完成以下功能：\n权限验证：检查视频是否存在及用户是否有权限删除 核心数据删除：删除视频主信息、投稿信息 经济系统调整：扣除用户发布视频获得的硬币 搜索索引清理：从 Elasticsearch 中移除文档 异步清理关联数据：使用线程池异步删除分P视频、弹幕、评论等关联数据及物理文件 2. 异步线程池部分详解 2.1 线程池初始化 1 private static ExecutorService executorService = Executors.newFixedThreadPool(10); 固定大小线程池（10个线程） 适合已知并发量的稳定负载场景 超出线程数的任务会在队列中等待 潜在问题：无界队列可能导致 OOM，静态变量生命周期长可能线程泄漏 2.2 异步任务执行逻辑 1 2 3 executorService.execute(() -\u0026gt; { // 异步任务代码块 }); 使用 Lambda 封装 Runnable 任务 execute() 方法提交任务到线程池 异步任务在新线程中执行，不受主方法 @Transactional 影响 若异步操作需要事务，需在任务内部添加事务注解 2.3 异步任务具体操作 查询和删除分P视频 1 2 3 4 VideoInfoFileQuery videoInfoFileQuery = new VideoInfoFileQuery(); videoInfoFileQuery.setVideoId(videoId); List\u0026lt;VideoInfoFile\u0026gt; videoInfoFileList = this.videoInfoFileMapper.selectList(videoInfoFileQuery); videoInfoFileMapper.deleteByParam(videoInfoFileQuery); 删除关联投稿信息 1 2 3 VideoInfoFilePostQuery videoInfoFilePostQuery = new VideoInfoFilePostQuery(); videoInfoFilePostQuery.setVideoId(videoId); videoInfoFilePostMapper.deleteByParam(videoInfoFilePostQuery); 删除弹幕数据 1 2 3 VideoDanmuQuery videoDanmuQuery = new VideoDanmuQuery(); videoDanmuQuery.setVideoId(videoId); videoDanmuMapper.deleteByParam(videoDanmuQuery); 删除评论数据 1 2 3 VideoCommentQuery videoCommentQuery = new VideoCommentQuery(); videoCommentQuery.setVideoId(videoId); videoCommentMapper.deleteByParam(videoCommentQuery); 物理文件删除 1 2 3 4 5 6 7 for (VideoInfoFile item : videoInfoFileList) { try { FileUtils.deleteDirectory(new File(appConfig.getProjectFolder() + item.getFilePath())); } catch (IOException e) { log.error(\u0026#34;删除文件失败，文件路径:{}\u0026#34;, item.getFilePath()); } } 3. 异步设计优缺点分析 优点： 响应速度快，主线程快速返回 IO密集型操作不影响核心业务 错误隔离，文件删除失败不影响主流程 缺点及风险： 事务不一致：主事务提交后异步任务才执行，失败可能导致系统不一致 错误处理缺失：当前实现没有记录任务执行结果，无法追踪异步操作是否成功 资源竞争：固定线程数可能成为瓶颈，文件删除操作可能阻塞其他任务 4. 改进建议 增强型线程池配置 1 2 3 4 5 6 7 private static ExecutorService executorService = new ThreadPoolExecutor( 5, // 核心线程数 20, // 最大线程数 60, TimeUnit.SECONDS, // 空闲线程存活时间 new ArrayBlockingQueue\u0026lt;\u0026gt;(1000), // 有界队列 new ThreadPoolExecutor.CallerRunsPolicy() // 拒绝策略 ); 添加任务结果处理 1 2 3 4 Future\u0026lt;?\u0026gt; future = executorService.submit(() -\u0026gt; { // 任务代码 }); future.get(10, TimeUnit.SECONDS); // 带超时的等待 事务补偿机制 1 2 3 4 @TransactionalEventListener(phase = AFTER_COMMIT) public void handleAfterCommit(VideoDeleteEvent event) { asyncCleanService.cleanVideoResources(event.getVideoId()); } 完善日志监控 1 2 3 4 5 6 7 8 9 10 11 12 executorService.execute(() -\u0026gt; { MDC.put(\u0026#34;traceId\u0026#34;, UUID.randomUUID().toString()); try { // 任务代码 log.info(\u0026#34;视频资源清理完成: {}\u0026#34;, videoId); } catch (Exception e) { log.error(\u0026#34;视频资源清理失败: {}\u0026#34;, videoId, e); // 发送告警或记录失败状态 } finally { MDC.clear(); } }); 5. 总结 该方法通过线程池实现了核心数据同步删除和资源异步清理，提升了响应速度和系统可扩展性。 关键改进方向：线程池参数优化、完善错误处理和状态跟踪、引入事务事件机制、增加监控和告警能力。 适合对实时性要求高但允许最终一致性的场景，是典型的\u0026quot;快速响应+后台清理\u0026quot;架构模式。 异步线程池及 executorService.execute 详解 一、异步线程池基础 1. 线程池核心概念 线程池是一种线程管理机制，维护多个线程，避免频繁创建和销毁线程带来的性能开销。 Java中主要通过 ExecutorService 及其实现类来使用线程池。 2. 线程池关键参数 参数 说明 示例值 corePoolSize 核心线程数 10 maximumPoolSize 最大线程数 50 keepAliveTime 空闲线程存活时间 60秒 workQueue 任务队列 new LinkedBlockingQueue(1000) threadFactory 线程创建工厂 Executors.defaultThreadFactory() handler 拒绝策略 AbortPolicy 3. 线程池工作流程 提交任务时，优先使用核心线程处理 核心线程全忙时，任务进入队列 队列满时，创建新线程（不超过最大线程数） 线程数达最大值且队列满时，触发拒绝策略 二、executorService.execute 方法详解 1. 方法签名 1 void execute(Runnable command) 2. 核心特点 异步执行，立即返回，不阻塞调用线程 无返回值，适用于不需要获取结果的场景 异常处理：任务异常会传递给未捕获异常处理器 3. 执行流程与示例 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 executorService.execute(() -\u0026gt; { // 1. 查询和删除分P视频 VideoInfoFileQuery videoInfoFileQuery = new VideoInfoFileQuery(); videoInfoFileQuery.setVideoId(videoId); List\u0026lt;VideoInfoFile\u0026gt; videoInfoFileList = this.videoInfoFileMapper.selectList(videoInfoFileQuery); videoInfoFileMapper.deleteByParam(videoInfoFileQuery); // 2. 删除其他关联数据... // 3. 删除物理文件 for (VideoInfoFile item : videoInfoFileList) { try { FileUtils.deleteDirectory(new File(appConfig.getProjectFolder() + item.getFilePath())); } catch (IOException e) { log.error(\u0026#34;删除文件失败，文件路径:{}\u0026#34;, item.getFilePath()); } } }); 4. execute 与 submit 区别 对比项 execute submit 返回值 无 Future对象 异常处理 直接抛出 封装在Future中 适用场景 简单异步任务 需要获取结果的任务 当前场景适合 execute：不需要获取清理操作的结果，简单日志记录已足够 三、线程池配置优化建议 1. 当前实现的潜在问题 1 private static ExecutorService executorService = Executors.newFixedThreadPool(10); 使用无界队列，可能导致 OOM 固定线程数无法应对突发流量 缺少合理的拒绝策略 2. 推荐改进方案 1 2 3 4 5 6 7 private static ExecutorService executorService = new ThreadPoolExecutor( 5, // 核心线程数 20, // 最大线程数 60, TimeUnit.SECONDS, // 空闲线程存活时间 new ArrayBlockingQueue\u0026lt;\u0026gt;(1000), // 有界队列 new ThreadPoolExecutor.CallerRunsPolicy() // 拒绝策略 ); 各参数说明： corePoolSize=5：保持5个常驻线程 maxPoolSize=20：突发流量时可扩展到20线程 keepAliveTime=60s：空闲线程60秒后回收 有界队列(1000)：防止资源耗尽 CallerRunsPolicy：队列满时由调用线程执行任务 四、异常处理机制 1. 当前实现的异常处理 1 2 3 4 5 try { FileUtils.deleteDirectory(...); } catch (IOException e) { log.error(\u0026#34;删除文件失败...\u0026#34;); } 仅记录日志，无恢复机制 异常不会传播到主线程 2. 增强型异常处理方案 全局异常处理器 1 2 3 4 5 6 7 8 9 10 11 12 13 executorService = new ThreadPoolExecutor( // ...其他参数 new ThreadPoolExecutor.AbortPolicy() { @Override public void rejectedExecution(Runnable r, ThreadPoolExecutor e) { log.warn(\u0026#34;Task rejected: {}\u0026#34;, r.toString()); super.rejectedExecution(r, e); } } ); Thread.setDefaultUncaughtExceptionHandler((t, e) -\u0026gt; { log.error(\u0026#34;Uncaught exception in thread: {}\u0026#34;, t.getName(), e); }); 封装任务 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 public class SafeRunnable implements Runnable { private final Runnable task; public SafeRunnable(Runnable task) { this.task = task; } @Override public void run() { try { task.run(); } catch (Exception e) { log.error(\u0026#34;Task execution failed\u0026#34;, e); // 可添加重试或补偿逻辑 } } } // 使用方式 executorService.execute(new SafeRunnable(() -\u0026gt; { // 任务代码 })); 五、性能监控建议 1. 添加线程池监控 1 2 3 4 5 6 7 8 9 10 11 ScheduledExecutorService monitor = Executors.newSingleThreadScheduledExecutor(); monitor.scheduleAtFixedRate(() -\u0026gt; { ThreadPoolExecutor tpe = (ThreadPoolExecutor) executorService; log.info( \u0026#34;Pool stats: active={}, queue={}/{}, completed={}\u0026#34;, tpe.getActiveCount(), tpe.getQueue().size(), tpe.getQueue().remainingCapacity(), tpe.getCompletedTaskCount() ); }, 1, 1, TimeUnit.MINUTES); 关键监控指标： activeCount：活动线程数 queueSize：队列大小 completedTaskCount：已完成任务 rejectedCount：被拒绝任务 六、实际应用场景分析 当前视频删除场景特点： 耗时操作，允许延迟，最终一致性即可 非关键路径，主线程快速返回 可能失败，需日志记录 适合使用线程池： 解耦主业务与清理操作，提升响应速度 通过线程池限制资源使用，方便扩展重试机制 潜在风险及应对： 风险 应对措施 线程泄漏 有界队列，合理配置存活时间 任务丢失 添加持久化队列或任务记录 资源竞争 监控和动态调整线程池参数 异常传播 完善任务级别的异常处理 七、总结 选择合适的线程池类型（fixed/cached/custom） 使用有界队列，防止资源耗尽 配置合理的拒绝策略（如 CallerRunsPolicy） 完善异常处理（任务级别和全局级别） 添加监控，实时了解线程池状态 关键任务建议使用带返回值的 submit 在视频删除场景中，线程池异步处理清理任务是一种合理设计，但需注意参数配置、异常处理、日志记录和资源监控。 Elasticsearch搜索组件详解 一、Elasticsearch基础介绍 Elasticsearch（简称ES）是一个分布式、RESTful风格的搜索和分析引擎，基于Apache Lucene构建。在视频平台中，主要用于：\n全文搜索：快速检索视频标题、标签等内容 结构化查询：支持多种条件组合查询 高亮显示：突出显示匹配的关键词 聚合统计：对播放量、弹幕数等进行统计分析 核心特性：\n近实时搜索：数据变更后1秒内可搜索 分布式架构：支持水平扩展 丰富的API：RESTful接口和多种客户端 强大的查询DSL：灵活的查询语法 二、组件配置解析 1 2 3 4 @Value(\u0026#34;${es.host.port:127.0.0.1:9200}\u0026#34;) private String esHostPort; @Value(\u0026#34;${es.index.video.name:easylive_video}\u0026#34;) private String esIndexVideoName; esHostPort：ES服务器地址，默认本地9200端口 esIndexVideoName：视频索引名称，默认\u0026quot;easylive_video\u0026quot; 三、核心方法详解 1. 索引初始化方法 createIndex() 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 public void createIndex() { try { Boolean existIndex = isExistIndex(); if (existIndex) { return; } CreateIndexRequest request = new CreateIndexRequest(appConfig.getEsIndexVideoName()); request.settings(\u0026#34;{\\\u0026#34;analysis\\\u0026#34;: {\\\u0026#34;analyzer\\\u0026#34;: {\\\u0026#34;comma\\\u0026#34;: {\\\u0026#34;type\\\u0026#34;: \\\u0026#34;pattern\\\u0026#34;,\\\u0026#34;pattern\\\u0026#34;: \\\u0026#34;,\\\u0026#34;}}}}\u0026#34;, XContentType.JSON); request.mapping(\u0026#34;{\\\u0026#34;properties\\\u0026#34;: {...}}\u0026#34;, XContentType.JSON); CreateIndexResponse response = restHighLevelClient.indices().create(request, RequestOptions.DEFAULT); if (!response.isAcknowledged()) { throw new BusinessException(\u0026#34;初始化es失败\u0026#34;); } } catch (Exception e) { log.error(\u0026#34;初始化es失败\u0026#34;, e); throw new BusinessException(\u0026#34;初始化es失败\u0026#34;); } } 字段映射说明： videoId/userId：仅存储不索引 videoName：使用ik中文分词器 tags：使用自定义逗号分析器 数值/日期字段：仅存储不索引 2. 文档操作方法 保存文档 saveDoc() 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 public void saveDoc(VideoInfo videoInfo) { try { if (docExist(videoInfo.getVideoId())) { updateDoc(videoInfo); } else { VideoInfoEsDto dto = CopyTools.copy(videoInfo, VideoInfoEsDto.class); dto.setCollectCount(0); dto.setPlayCount(0); dto.setDanmuCount(0); IndexRequest request = new IndexRequest(appConfig.getEsIndexVideoName()); request.id(videoInfo.getVideoId()) .source(JsonUtils.convertObj2Json(dto), XContentType.JSON); restHighLevelClient.index(request, RequestOptions.DEFAULT); } } catch (Exception e) { log.error(\u0026#34;新增视频到es失败\u0026#34;, e); throw new BusinessException(\u0026#34;保存失败\u0026#34;); } } 更新文档 updateDoc() 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 private void updateDoc(VideoInfo videoInfo) { try { videoInfo.setLastUpdateTime(null); videoInfo.setCreateTime(null); Map\u0026lt;String, Object\u0026gt; dataMap = new HashMap\u0026lt;\u0026gt;(); Field[] fields = videoInfo.getClass().getDeclaredFields(); for (Field field : fields) { Method getter = videoInfo.getClass().getMethod(\u0026#34;get\u0026#34; + StringTools.upperCaseFirstLetter(field.getName())); Object value = getter.invoke(videoInfo); if (value != null \u0026amp;\u0026amp; !(value instanceof String \u0026amp;\u0026amp; ((String)value).isEmpty())) { dataMap.put(field.getName(), value); } } if (!dataMap.isEmpty()) { UpdateRequest updateRequest = new UpdateRequest(appConfig.getEsIndexVideoName(), videoInfo.getVideoId()); updateRequest.doc(dataMap); restHighLevelClient.update(updateRequest, RequestOptions.DEFAULT); } } catch (Exception e) { log.error(\u0026#34;更新视频到es失败\u0026#34;, e); throw new BusinessException(\u0026#34;保存失败\u0026#34;); } } 更新统计字段 updateDocCount() 1 2 3 4 5 6 7 8 9 10 11 12 13 public void updateDocCount(String videoId, String fieldName, Integer count) { try { UpdateRequest updateRequest = new UpdateRequest(appConfig.getEsIndexVideoName(), videoId); Script script = new Script(ScriptType.INLINE, \u0026#34;painless\u0026#34;, \u0026#34;ctx._source.\u0026#34; + fieldName + \u0026#34; += params.count\u0026#34;, Collections.singletonMap(\u0026#34;count\u0026#34;, count)); updateRequest.script(script); restHighLevelClient.update(updateRequest, RequestOptions.DEFAULT); } catch (Exception e) { log.error(\u0026#34;更新数量到es失败\u0026#34;, e); throw new BusinessException(\u0026#34;保存失败\u0026#34;); } } 删除文档 delDoc() 1 2 3 4 5 6 7 8 9 public void delDoc(String videoId) { try { DeleteRequest deleteRequest = new DeleteRequest(appConfig.getEsIndexVideoName(), videoId); restHighLevelClient.delete(deleteRequest, RequestOptions.DEFAULT); } catch (Exception e) { log.error(\u0026#34;从es删除视频失败\u0026#34;, e); throw new BusinessException(\u0026#34;删除视频失败\u0026#34;); } } 3. 搜索方法 search() 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 public PaginationResultVO\u0026lt;VideoInfo\u0026gt; search(Boolean highlight, String keyword, Integer orderType, Integer pageNo, Integer pageSize) { try { SearchSourceBuilder sourceBuilder = new SearchSourceBuilder(); sourceBuilder.query(QueryBuilders.multiMatchQuery(keyword, \u0026#34;videoName\u0026#34;, \u0026#34;tags\u0026#34;)); if (highlight) { HighlightBuilder highlightBuilder = new HighlightBuilder(); highlightBuilder.field(\u0026#34;videoName\u0026#34;) .preTags(\u0026#34;\u0026lt;span class=\u0026#39;highlight\u0026#39;\u0026gt;\u0026#34;) .postTags(\u0026#34;\u0026lt;/span\u0026gt;\u0026#34;); sourceBuilder.highlighter(highlightBuilder); } SearchOrderTypeEnum orderEnum = SearchOrderTypeEnum.getByType(orderType); if (orderType != null) { sourceBuilder.sort(orderEnum.getField(), SortOrder.DESC); } else { sourceBuilder.sort(\u0026#34;_score\u0026#34;, SortOrder.DESC); } pageNo = pageNo == null ? 1 : pageNo; pageSize = pageSize == null ? PageSize.SIZE20.getSize() : pageSize; sourceBuilder.from((pageNo - 1) * pageSize).size(pageSize); SearchRequest searchRequest = new SearchRequest(appConfig.getEsIndexVideoName()); searchRequest.source(sourceBuilder); SearchResponse response = restHighLevelClient.search(searchRequest, RequestOptions.DEFAULT); SearchHits hits = response.getHits(); List\u0026lt;VideoInfo\u0026gt; videoList = Arrays.stream(hits.getHits()) .map(hit -\u0026gt; { VideoInfo info = JsonUtils.convertJson2Obj(hit.getSourceAsString(), VideoInfo.class); if (hit.getHighlightFields().get(\u0026#34;videoName\u0026#34;) != null) { info.setVideoName(hit.getHighlightFields().get(\u0026#34;videoName\u0026#34;).getFragments()[0].string()); } return info; }) .collect(Collectors.toList()); Map\u0026lt;String, UserInfo\u0026gt; userMap = userInfoMapper.selectList( new UserInfoQuery().setUserIdList( videoList.stream().map(VideoInfo::getUserId).collect(Collectors.toList()) ) ).stream().collect(Collectors.toMap(UserInfo::getUserId, Function.identity())); videoList.forEach(video -\u0026gt; { UserInfo user = userMap.get(video.getUserId()); if (user != null) video.setNickName(user.getNickName()); }); return new PaginationResultVO\u0026lt;\u0026gt;( (int)hits.getTotalHits().value, pageSize, pageNo, (int)Math.ceil((double)hits.getTotalHits().value / pageSize), videoList ); } catch (Exception e) { log.error(\u0026#34;查询视频失败\u0026#34;, e); throw new BusinessException(\u0026#34;查询失败\u0026#34;); } } 四、设计亮点分析 优雅的异常处理：统一捕获异常并转换为业务异常，记录详细错误日志 智能的文档操作：自动判断文档存在性，增量更新非空字段 高效的统计更新：使用 painless 脚本实现原子操作 完整的分页支持：支持自定义页码和大小，返回总页数等元信息 关联数据补充：搜索后批量查询用户信息，减少N+1查询问题 五、潜在优化建议 批量操作支持 1 2 3 BulkRequest bulkRequest = new BulkRequest(); // 添加多个操作 restHighLevelClient.bulk(bulkRequest, RequestOptions.DEFAULT); 缓存用户信息：使用Redis缓存频繁访问的用户数据 搜索建议功能 1 2 3 SearchSourceBuilder.suggest(new SuggestBuilder() .addSuggestion(\u0026#34;video-suggest\u0026#34;, SuggestBuilders.completionSuggestion(\u0026#34;videoName.suggest\u0026#34;))); 更复杂的高亮策略：支持多字段高亮，自定义高亮片段长度 索引别名支持：使用别名实现零停机索引重建 六、初始化流程（InitRun） 1 2 3 4 5 6 7 8 9 10 11 12 13 14 @Component(\u0026#34;initRun\u0026#34;) public class InitRun implements ApplicationRunner { @Override public void run(ApplicationArguments args) { try (Connection conn = dataSource.getConnection()) { redisUtils.get(\u0026#34;test\u0026#34;); esSearchComponent.createIndex(); logger.info(\u0026#34;服务启动成功\u0026#34;); } catch (Exception e) { logger.error(\u0026#34;服务启动失败\u0026#34;, e); System.exit(0); } } } 启动验证逻辑： 数据库连接测试 Redis连通性测试 ES索引初始化 任一失败则终止应用启动 该ES搜索组件为视频平台提供了完整、高效的搜索能力，从基础索引管理到复杂的搜索功能都有良好实现，是系统核心功能的重要支撑。\nJava反射机制及其在代码中的应用 一、反射基础概念 反射（Reflection）是Java语言的一种动态能力，允许程序在运行时：\n获取类的完整结构信息 动态创建对象 访问和修改字段值 调用方法 操作数组 核心反射类：\n类 作用 Class 表示类和接口 Field 表示类的字段 Method 表示类的方法 Constructor 表示类的构造方法 二、代码中的反射解析 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 Map\u0026lt;String, Object\u0026gt; dataMap = new HashMap\u0026lt;\u0026gt;(); Field[] fields = videoInfo.getClass().getDeclaredFields(); // 获取所有字段 for (Field field : fields) { // 构造getter方法名（如：getVideoName） String methodName = \u0026#34;get\u0026#34; + StringTools.upperCaseFirstLetter(field.getName()); // 获取Method对象 Method method = videoInfo.getClass().getMethod(methodName); // 调用getter方法获取值 Object object = method.invoke(videoInfo); // 过滤非空值 if (object != null \u0026amp;\u0026amp; ( (object instanceof String \u0026amp;\u0026amp; !StringTools.isEmpty(object.toString())) || !(object instanceof String) )) { dataMap.put(field.getName(), object); } } 三、反射在此处的具体作用 动态获取对象属性 通过 getDeclaredFields() 获取所有字段 无需硬编码每个字段名，自动适应类结构变化 通用属性拷贝 将对象属性转换为 Map 结构 为后续 ES 文档更新提供数据源 空值过滤 跳过 null 值 对 String 类型额外检查空字符串 类型安全处理 区分 String 和非 String 类型的不同处理逻辑 四、反射的工作流程 获取类对象 → 获取字段列表 → 构造 getter 方法名 → 获取 Method → 调用 getter 获取值 → 过滤空值 → 填充 Map 五、反射的优缺点 优点 说明 灵活性 动态处理未知类结构 通用性 可编写通用工具方法 解耦 不依赖具体实现类 缺点 说明 性能开销 比直接调用慢约50-100倍 安全限制 需要运行时权限 代码复杂度 错误难以在编译期发现 六、性能优化建议 缓存反射结果 1 2 3 4 5 6 7 // 类级别缓存 private static Map\u0026lt;Class\u0026lt;?\u0026gt;, Map\u0026lt;String, Method\u0026gt;\u0026gt; methodCache = new ConcurrentHashMap\u0026lt;\u0026gt;(); Method method = methodCache.computeIfAbsent(clazz, k -\u0026gt; { Map\u0026lt;String, Method\u0026gt; map = new HashMap\u0026lt;\u0026gt;(); // 填充method到map return map; }).get(methodName); 使用高性能反射工具 1 2 3 // 例如Spring的BeanWrapper或Apache BeanUtils BeanWrapper wrapper = new BeanWrapperImpl(videoInfo); Object value = wrapper.getPropertyValue(field.getName()); 替代方案比较 方案 性能 易用性 灵活性 直接调用 ★★★★★ ★★★ ★ 反射 ★★ ★★★ ★★★★★ MethodHandle ★★★★ ★★ ★★★★ Bytecode生成 ★★★★★ ★ ★★★ 七、在此场景下的必要性分析 ES文档结构动态，字段可能频繁变化 通用更新逻辑，不同实体可复用相同代码 避免为每个字段编写 set/get，提高开发效率 性能影响可接受（ES更新频率低） 仅调用 getter 方法，无安全风险 建议添加注释说明意图，便于维护 八、完整流程示例 假设 VideoInfo 类有如下字段：\n1 2 3 4 5 6 7 public class VideoInfo { private String videoId; // \u0026#34;123\u0026#34; private String videoName; // \u0026#34;Java教程\u0026#34; private Integer status; // 1 private Date createTime; // new Date() private String desc; // \u0026#34;\u0026#34; } 反射处理后的 dataMap 将是：\n1 2 3 4 5 6 { \u0026#34;videoId\u0026#34;: \u0026#34;123\u0026#34;, \u0026#34;videoName\u0026#34;: \u0026#34;Java教程\u0026#34;, \u0026#34;status\u0026#34;: 1, \u0026#34;createTime\u0026#34;: Date对象 } desc 字段因是空字符串被过滤 所有非空非 String 字段都被包含 这种反射实现为 ES 文档更新提供了灵活、自动化的属性收集机制，是典型且合理的反射使用场景。\nAOP（面向切面编程）基础详解 面向切面编程（Aspect-Oriented Programming，AOP）是一种编程范式，用于将横切关注点（cross-cutting concerns）与核心业务逻辑分离。以下是AOP的核心概念和实现细节：\n一、AOP核心概念 概念 说明 示例 切面(Aspect) 封装横切逻辑的模块 日志记录、权限校验、事务管理 连接点(JoinPoint) 程序执行中的特定点 方法调用、异常抛出、字段修改 通知(Advice) 切面在连接点的动作 @Before、@After、@Around 切点(Pointcut) 匹配连接点的表达式 execution(* com.service..(..)) 目标对象(Target) 被增强的对象 普通的Service实例 织入(Weaving) 将切面应用到目标对象的过程 编译期、类加载期、运行期 二、Spring AOP实现机制 1. 代理模式 Spring AOP默认使用动态代理： JDK动态代理：基于接口（默认） CGLIB代理：基于类继承（需启用） 2. 通知类型 通知类型 注解 执行时机 前置通知 @Before 方法执行前 后置通知 @AfterReturning 方法正常返回后 异常通知 @AfterThrowing 方法抛出异常后 最终通知 @After 方法执行后（无论成败） 环绕通知 @Around 包裹整个方法执行 三、Spring AOP实战 1. 基本配置 1 2 3 4 @Configuration @EnableAspectJAutoProxy // 启用AOP public class AppConfig { } 2. 切面定义示例 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 @Aspect @Component public class LogAspect { // 定义切点（匹配service包下所有方法） @Pointcut(\u0026#34;execution(* com.example.service.*.*(..))\u0026#34;) public void servicePointcut() {} @Before(\u0026#34;servicePointcut()\u0026#34;) public void beforeLog(JoinPoint jp) { String methodName = jp.getSignature().getName(); System.out.println(\u0026#34;调用方法前: \u0026#34; + methodName); } @Around(\u0026#34;servicePointcut()\u0026#34;) public Object aroundLog(ProceedingJoinPoint pjp) throws Throwable { long start = System.currentTimeMillis(); Object result = pjp.proceed(); long time = System.currentTimeMillis() - start; System.out.println(\u0026#34;方法执行耗时: \u0026#34; + time + \u0026#34;ms\u0026#34;); return result; } } 四、切点表达式语法 1. 基本语法 1 execution([修饰符] 返回类型 [类名].方法名(参数) [异常]) 2. 常用表达式示例 表达式 说明 execution(public * *(..)) 所有public方法 execution(* set*(..)) 所有set开头的方法 execution(* com.service..(..)) service包下所有方法 execution(* com.service...(..)) service包及其子包下所有方法 @annotation(com.example.Log) 带有@Log注解的方法 五、获取上下文信息 1. 方法信息获取 1 2 3 4 5 6 7 8 9 @Before(\u0026#34;execution(* com.service.*.*(..))\u0026#34;) public void before(JoinPoint jp) { // 获取方法签名 MethodSignature signature = (MethodSignature) jp.getSignature(); // 获取参数 Object[] args = jp.getArgs(); // 获取目标对象 Object target = jp.getTarget(); } 2. 返回值获取 1 2 3 4 5 6 7 @AfterReturning( pointcut = \u0026#34;execution(* com.service.*.*(..))\u0026#34;, returning = \u0026#34;result\u0026#34; ) public void afterReturning(Object result) { System.out.println(\u0026#34;返回结果: \u0026#34; + result); } 3. 异常获取 1 2 3 4 5 6 7 @AfterThrowing( pointcut = \u0026#34;execution(* com.service.*.*(..))\u0026#34;, throwing = \u0026#34;ex\u0026#34; ) public void afterThrowing(Exception ex) { System.err.println(\u0026#34;发生异常: \u0026#34; + ex.getMessage()); } 六、AOP应用场景 日志记录：自动记录方法调用信息 性能监控：统计方法执行时间 事务管理：声明式事务 权限控制：方法级权限校验 缓存管理：自动缓存方法结果 异常处理：统一异常捕获和处理 七、Spring AOP与AspectJ对比 特性 Spring AOP AspectJ 实现方式 动态代理 字节码增强 织入时机 运行时 编译期/类加载期 性能 较慢 更快 功能 仅支持方法级 支持字段、构造器等 复杂度 简单 复杂 依赖 仅需Spring 需特殊编译器 八、最佳实践建议 切面粒度控制：一个切面只关注一个横切关注点 切点表达式优化：避免过于宽泛的匹配 注意代理限制： 自调用问题（内部方法调用不走代理） final方法不能被代理 性能考量： 尽量减少切面逻辑的复杂度 环绕通知中的耗时操作考虑异步 调试技巧： 使用AopContext.currentProxy()获取当前代理 通过@Order控制多个切面的执行顺序 九、完整示例：方法级权限控制 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 // 自定义权限注解 @Target(ElementType.METHOD) @Retention(RetentionPolicy.RUNTIME) public @interface RequiresPermission { String[] value(); } // 切面实现 @Aspect @Component public class PermissionAspect { @Autowired private AuthService authService; @Around(\u0026#34;@annotation(requiresPermission)\u0026#34;) public Object checkPermission(ProceedingJoinPoint pjp, RequiresPermission requiresPermission) throws Throwable { // 获取当前用户 User user = CurrentUser.get(); // 检查权限 if (!authService.hasPermissions(user, requiresPermission.value())) { throw new AccessDeniedException(\u0026#34;权限不足\u0026#34;); } return pjp.proceed(); } } // 使用示例 @Service public class OrderService { @RequiresPermission(\u0026#34;order:create\u0026#34;) public void createOrder(Order order) { // 业务逻辑 } } 通过AOP，可以将权限校验逻辑与业务代码完全解耦，实现声明式的权限控制。\n使用AOP实现登录校验 一、AOP基础概念 AOP（Aspect-Oriented Programming，面向切面编程）是一种编程范式，用于将横切关注点（如日志、事务、安全等）与业务逻辑分离。核心概念包括：\n概念 说明 对应代码示例 切面(Aspect) 封装横切逻辑的模块 GlobalOperationAspect类 连接点(JoinPoint) 程序执行中的特定点 interceptorDo方法的JoinPoint参数 通知(Advice) 切面在特定连接点的动作 @Before注解的方法 切点(Pointcut) 匹配连接点的表达式 @annotation(com.easylive.web.annotation.GlobalInterceptor) 引入(Introduction) 向现有类添加新方法/属性 本例未使用 目标对象(Target) 被通知的对象 如loadAllVideo方法所在的Controller 二、登录校验实现详解 1. 定义注解（标记需要拦截的方法） 1 2 3 4 5 @Target({ElementType.METHOD, ElementType.TYPE}) @Retention(RetentionPolicy.RUNTIME) public @interface GlobalInterceptor { boolean checkLogin() default false; } 作为元数据标记需要拦截的方法 通过checkLogin属性灵活控制是否进行登录校验 2. 实现切面逻辑 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 @Aspect @Component @Slf4j public class GlobalOperationAspect { @Resource private RedisUtils redisUtils; // 定义切点：拦截带有GlobalInterceptor注解的方法 @Before(\u0026#34;@annotation(com.easylive.web.annotation.GlobalInterceptor)\u0026#34;) public void interceptorDo(JoinPoint point) { Method method = ((MethodSignature) point.getSignature()).getMethod(); GlobalInterceptor interceptor = method.getAnnotation(GlobalInterceptor.class); if (interceptor != null \u0026amp;\u0026amp; interceptor.checkLogin()) { checkLogin(); } } private void checkLogin() { HttpServletRequest request = ((ServletRequestAttributes) RequestContextHolder.getRequestAttributes()).getRequest(); String token = request.getHeader(Constants.TOKEN_WEB); if (StringTools.isEmpty(token)) { throw new BusinessException(ResponseCodeEnum.CODE_901); } TokenUserInfoDto userInfo = (TokenUserInfoDto) redisUtils.get( Constants.REDIS_KEY_TOKEN_WEB + token); if (userInfo == null) { throw new BusinessException(ResponseCodeEnum.CODE_901); } } } 3. 业务方法应用 1 2 3 4 5 @GlobalInterceptor(checkLogin = true) public ResponseVO loadAllVideo() { TokenUserInfoDto userInfo = getTokenUserInfoDto(); // ...业务逻辑 } 三、执行流程分析 方法被调用 → AOP切面拦截 → 判断注解属性 → 校验登录 → 通过则执行业务逻辑，否则抛出异常 四、设计优势分析 解耦性：将安全校验与业务逻辑分离 灵活性：注解开关控制校验，可扩展其他规则 一致性：所有Controller方法统一处理 可维护性：校验逻辑集中管理，修改方便 五、扩展应用场景 添加权限校验 1 2 3 4 5 6 7 8 public @interface GlobalInterceptor { boolean checkLogin() default false; String[] roles() default {}; } // 切面中补充校验 if (interceptor.roles().length \u0026gt; 0) { checkRoles(interceptor.roles()); } 参数校验 1 2 3 4 private void validateParams(JoinPoint point) { Object[] args = point.getArgs(); // 实现参数校验逻辑 } 操作日志记录 1 2 3 4 @AfterReturning(pointcut=\u0026#34;@annotation(interceptor)\u0026#34;, returning=\u0026#34;result\u0026#34;) public void logOperation(JoinPoint point, Object result) { // 记录方法调用日志 } 六、性能优化建议 缓存注解解析结果 1 2 3 private static ConcurrentMap\u0026lt;Method, GlobalInterceptor\u0026gt; cache = new ConcurrentHashMap\u0026lt;\u0026gt;(); GlobalInterceptor interceptor = cache.computeIfAbsent(method, m -\u0026gt; m.getAnnotation(GlobalInterceptor.class)); 减少重复查询 1 request.setAttribute(Constants.USER_INFO_KEY, userInfo); 异步日志记录 1 2 3 4 @Async public void asyncLogOperation(...) { // 异步记录日志 } 七、常见问题解决方案 内部方法调用不走AOP：Spring AOP基于代理，内部调用不经过代理。解决：从ApplicationContext获取代理对象调用 多切面执行顺序：使用@Order注解控制顺序，默认按切面名称字母顺序 异常处理：使用@AfterThrowing处理特定异常，结合全局异常处理器统一处理 这种基于注解和AOP的登录校验实现，是Spring生态中典型的权限控制方案，既保持了代码的简洁性，又提供了足够的灵活性和扩展能力。\n登录校验的多种实现方式 1. 拦截器(Interceptor)实现 基于Spring MVC的拦截器机制，在控制器方法执行前后进行拦截 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 public class AuthInterceptor implements HandlerInterceptor { @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) { String token = request.getHeader(\u0026#34;Authorization\u0026#34;); if(!checkToken(token)) { response.setStatus(401); return false; } return true; } } @Configuration public class WebConfig implements WebMvcConfigurer { @Override public void addInterceptors(InterceptorRegistry registry) { registry.addInterceptor(new AuthInterceptor()) .addPathPatterns(\u0026#34;/api/**\u0026#34;) .excludePathPatterns(\u0026#34;/api/login\u0026#34;); } } 优点：配置简单，基于URL模式匹配，执行时机早于AOP，性能稍好 缺点：无法基于方法粒度控制，难以获取方法上的元数据信息 2. 过滤器(Filter)实现 基于Servlet规范的过滤器，在最外层对请求进行过滤 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 public class AuthFilter implements Filter { @Override public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) { HttpServletRequest req = (HttpServletRequest) request; String token = req.getHeader(\u0026#34;Authorization\u0026#34;); if(!checkToken(token)) { ((HttpServletResponse)response).setStatus(401); return; } chain.doFilter(request, response); } } @Configuration public class FilterConfig { @Bean public FilterRegistrationBean\u0026lt;AuthFilter\u0026gt; authFilter() { FilterRegistrationBean\u0026lt;AuthFilter\u0026gt; reg = new FilterRegistrationBean\u0026lt;\u0026gt;(); reg.setFilter(new AuthFilter()); reg.addUrlPatterns(\u0026#34;/api/*\u0026#34;); return reg; } } 优点：执行时机最早，性能最好，可处理静态资源等非Spring管理的请求 缺点：无法获取Spring上下文信息，配置粒度较粗 3. Spring Security框架 Spring官方安全框架，提供完整认证授权解决方案 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 @Configuration @EnableWebSecurity public class SecurityConfig extends WebSecurityConfigurerAdapter { @Override protected void configure(HttpSecurity http) throws Exception { http.authorizeRequests() .antMatchers(\u0026#34;/api/public/**\u0026#34;).permitAll() .anyRequest().authenticated() .and() .addFilter(new JwtAuthFilter(authenticationManager())); } } public class JwtAuthFilter extends OncePerRequestFilter { @Override protected void doFilterInternal(HttpServletRequest request, HttpServletResponse response, FilterChain filterChain) { // JWT校验逻辑 } } 优点：功能全面，支持多种认证方式，内置CSRF防护，社区支持好 缺点：学习曲线陡峭，配置复杂 4. 网关层统一校验 在API网关(如Spring Cloud Gateway)层统一处理认证 1 2 3 4 5 6 7 8 9 10 11 public class AuthFilter implements GlobalFilter, Ordered { @Override public Mono\u0026lt;Void\u0026gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) { String token = exchange.getRequest().getHeaders().getFirst(\u0026#34;Authorization\u0026#34;); if(!checkToken(token)) { exchange.getResponse().setStatusCode(HttpStatus.UNAUTHORIZED); return exchange.getResponse().setComplete(); } return chain.filter(exchange); } } 优点：统一入口，避免每个服务重复实现，性能损耗最小化 缺点：需要额外维护网关服务，仅适用于微服务架构 5. 方法参数解析器 通过自定义参数解析器自动注入用户信息 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 public class CurrentUserArgumentResolver implements HandlerMethodArgumentResolver { @Override public boolean supportsParameter(MethodParameter parameter) { return parameter.hasParameterAnnotation(CurrentUser.class); } @Override public Object resolveArgument(MethodParameter parameter, ModelAndViewContainer mavContainer, NativeWebRequest webRequest, WebDataBinderFactory binderFactory) { HttpServletRequest request = webRequest.getNativeRequest(HttpServletRequest.class); String token = request.getHeader(\u0026#34;Authorization\u0026#34;); return getUserFromToken(token); } } // 使用注解 @GetMapping(\u0026#34;/userinfo\u0026#34;) public UserInfo getUserInfo(@CurrentUser User user) { return userService.getInfo(user.getId()); } 优点：使用简洁，直接获取用户信息，与业务代码自然集成 缺点：只适用于获取当前用户场景，需要配合其他校验方式使用 6. 对比总结 方式 适用场景 优点 缺点 AOP注解 方法粒度灵活控制 灵活、可扩展性强 性能稍差 拦截器 URL统一校验 配置简单、性能较好 粒度较粗 过滤器 最外层请求过滤 性能最好 无法用Spring特性 Spring Security 完整安全方案 功能全面 复杂、学习成本高 API网关 微服务架构 统一管理、性能好 需额外基础设施 参数解析器 自动注入用户信息 使用简洁 需配合其他方式 7. 选择建议 单体应用：AOP注解 + 拦截器组合 微服务架构：网关统一认证 + 服务内AOP补充 高安全性要求：Spring Security 高性能要求：过滤器 + 参数解析器 快速开发：AOP注解方式最简单直接 实际项目中，通常会组合使用多种方式，比如用过滤器做基础校验，AOP做细粒度控制，参数解析器方便获取用户信息。\nJWT实现登录校验的完整方案 一、JWT基础概念 1. JWT组成结构 1 header.payload.signature Header：包含令牌类型和签名算法 Payload：存放用户信息和其他数据 Signature：防止令牌被篡改的签名 2. 工作流程 用户登录 → 服务端生成JWT → 客户端存储并携带JWT访问API → 服务端校验JWT 二、Spring Boot实现方案 1. 添加依赖 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.jsonwebtoken\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jjwt-api\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.11.5\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.jsonwebtoken\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jjwt-impl\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.11.5\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;runtime\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.jsonwebtoken\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jjwt-jackson\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.11.5\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;runtime\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; 2. JWT工具类 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 @Component public class JwtTokenUtil { @Value(\u0026#34;${jwt.secret}\u0026#34;) private String secret; @Value(\u0026#34;${jwt.expiration}\u0026#34;) private Long expiration; // 生成令牌 public String generateToken(String username) { Map\u0026lt;String, Object\u0026gt; claims = new HashMap\u0026lt;\u0026gt;(); return Jwts.builder() .setClaims(claims) .setSubject(username) .setIssuedAt(new Date()) .setExpiration(new Date(System.currentTimeMillis() + expiration * 1000)) .signWith(getSigningKey(), SignatureAlgorithm.HS256) .compact(); } // 验证令牌 public boolean validateToken(String token) { try { Jwts.parserBuilder() .setSigningKey(getSigningKey()) .build() .parseClaimsJws(token); return true; } catch (Exception e) { return false; } } // 从令牌获取用户名 public String getUsernameFromToken(String token) { return Jwts.parserBuilder() .setSigningKey(getSigningKey()) .build() .parseClaimsJws(token) .getBody() .getSubject(); } private SecretKey getSigningKey() { return Keys.hmacShaKeyFor(secret.getBytes()); } } 3. 登录接口实现 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 @RestController @RequestMapping(\u0026#34;/auth\u0026#34;) public class AuthController { @Autowired private JwtTokenUtil jwtTokenUtil; @PostMapping(\u0026#34;/login\u0026#34;) public ResponseEntity\u0026lt;?\u0026gt; login(@RequestBody LoginRequest loginRequest) { boolean authenticated = authenticate(loginRequest.getUsername(), loginRequest.getPassword()); if (!authenticated) { return ResponseEntity.status(HttpStatus.UNAUTHORIZED).build(); } String token = jwtTokenUtil.generateToken(loginRequest.getUsername()); Map\u0026lt;String, String\u0026gt; response = new HashMap\u0026lt;\u0026gt;(); response.put(\u0026#34;token\u0026#34;, token); return ResponseEntity.ok(response); } private boolean authenticate(String username, String password) { return \u0026#34;admin\u0026#34;.equals(username) \u0026amp;\u0026amp; \u0026#34;123456\u0026#34;.equals(password); } } 4. JWT校验过滤器 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 public class JwtAuthFilter extends OncePerRequestFilter { @Autowired private JwtTokenUtil jwtTokenUtil; @Override protected void doFilterInternal(HttpServletRequest request, HttpServletResponse response, FilterChain filterChain) throws ServletException, IOException { String token = request.getHeader(\u0026#34;Authorization\u0026#34;); if (token != null \u0026amp;\u0026amp; token.startsWith(\u0026#34;Bearer \u0026#34;)) { String jwt = token.substring(7); if (jwtTokenUtil.validateToken(jwt)) { String username = jwtTokenUtil.getUsernameFromToken(jwt); UsernamePasswordAuthenticationToken authentication = new UsernamePasswordAuthenticationToken(username, null, new ArrayList\u0026lt;\u0026gt;()); SecurityContextHolder.getContext().setAuthentication(authentication); } } filterChain.doFilter(request, response); } } 5. 安全配置 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 @Configuration @EnableWebSecurity public class SecurityConfig extends WebSecurityConfigurerAdapter { @Autowired private JwtAuthFilter jwtAuthFilter; @Override protected void configure(HttpSecurity http) throws Exception { http.csrf().disable() .authorizeRequests() .antMatchers(\u0026#34;/auth/login\u0026#34;).permitAll() .anyRequest().authenticated() .and() .sessionManagement().sessionCreationPolicy(SessionCreationPolicy.STATELESS) .and() .addFilterBefore(jwtAuthFilter, UsernamePasswordAuthenticationFilter.class); } } 三、客户端使用方式 1. 登录获取token 1 2 3 4 5 6 POST /auth/login Content-Type: application/json { \u0026#34;username\u0026#34;: \u0026#34;admin\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;123456\u0026#34; } 响应示例：\n1 2 3 { \u0026#34;token\u0026#34;: \u0026#34;eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiJhZG1pbiIsImlhdCI6MTY1...\u0026#34; } 2. 访问受保护API 1 2 GET /api/protected Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9... 四、高级功能实现 令牌刷新机制 1 2 3 4 5 6 7 8 9 10 @PostMapping(\u0026#34;/refresh\u0026#34;) public ResponseEntity\u0026lt;?\u0026gt; refreshToken(HttpServletRequest request) { String oldToken = request.getHeader(\u0026#34;Authorization\u0026#34;); if (oldToken != null \u0026amp;\u0026amp; oldToken.startsWith(\u0026#34;Bearer \u0026#34;)) { String username = jwtTokenUtil.getUsernameFromToken(oldToken.substring(7)); String newToken = jwtTokenUtil.generateToken(username); // 返回新token... } return ResponseEntity.badRequest().build(); } 黑名单实现（注销功能） 1 2 3 4 5 6 7 private Set\u0026lt;String\u0026gt; tokenBlacklist = new HashSet\u0026lt;\u0026gt;(); public void invalidateToken(String token) { tokenBlacklist.add(token); } public boolean isTokenValid(String token) { return !tokenBlacklist.contains(token) \u0026amp;\u0026amp; validateToken(token); } 多设备登录管理 1 2 3 4 5 6 7 8 9 private Map\u0026lt;String, Set\u0026lt;String\u0026gt;\u0026gt; userDeviceTokens = new ConcurrentHashMap\u0026lt;\u0026gt;(); public String generateToken(String username, String deviceId) { // ...生成token userDeviceTokens.computeIfAbsent(username, k -\u0026gt; new HashSet\u0026lt;\u0026gt;()).add(deviceId); return token; } public void logoutDevice(String username, String deviceId) { userDeviceTokens.getOrDefault(username, Collections.emptySet()).remove(deviceId); } 五、安全最佳实践 使用HTTPS：防止令牌被截获 设置合理过期时间：通常2小时-7天 不要存储敏感信息：JWT内容可以被解码 使用强密钥：至少256位的密钥 实现令牌刷新：减少长期有效的风险 防范CSRF：即使JWT不易受CSRF影响也应防范 日志监控：记录异常令牌尝试 六、与其他方案的对比 特性 JWT 传统Session OAuth2 状态 无状态 有状态 可无状态 性能 高 中等 中等 扩展性 强 弱 强 适用场景 API/微服务 传统Web应用 第三方登录 实现复杂度 简单 简单 复杂 JWT特别适合现代前后端分离架构和微服务场景，它的无状态特性可以显著减轻服务器压力，简化横向扩展。但对于需要即时撤销令牌的场景，需要额外实现黑名单机制。\n通过AOP实现消息通知 一、整体设计思路 本实现通过自定义注解 @RecordUserMessage 和 AOP 切面 UserMessageOperationAspect，在用户执行特定操作（如点赞、收藏）后自动记录消息通知。\n注解驱动：通过注解标记需要记录消息的方法 参数自动提取：从方法参数中智能提取消息相关内容 类型动态判断：根据操作类型自动调整消息类型 用户信息自动获取：从请求头中解析当前用户 二、核心组件详解 1. 自定义注解 @RecordUserMessage 1 2 3 4 5 @Target({ElementType.METHOD, ElementType.TYPE}) @Retention(RetentionPolicy.RUNTIME) public @interface RecordUserMessage { MessageTypeEnum messageType(); } 标记需要记录用户消息的 Controller 方法 指定基本消息类型（可在切面中根据条件调整） 2. AOP切面实现 UserMessageOperationAspect 环绕通知主体 1 2 3 4 5 6 7 8 9 10 11 12 13 14 @Around(\u0026#34;@annotation(com.easylive.annotation.RecordUserMessage)\u0026#34;) public ResponseVO interceptorDo(ProceedingJoinPoint point) throws Exception { try { ResponseVO result = (ResponseVO) point.proceed(); Method method = ((MethodSignature) point.getSignature()).getMethod(); RecordUserMessage recordUserMessage = method.getAnnotation(RecordUserMessage.class); if (recordUserMessage != null) { saveUserMessage(recordUserMessage, point.getArgs(), method.getParameters()); } return result; } catch (BusinessException e) { // ...异常处理 } } 使用 @Around 确保在方法执行后处理\n通过 ProceedingJoinPoint 获取方法参数和注解\n保持原方法的返回结果不变\n消息保存逻辑\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 private void saveUserMessage(RecordUserMessage recordUserMessage, Object[] arguments, Parameter[] parameters) { String videoId = extractParameter(PARAMETERS_VIDEO_ID, arguments, parameters); Integer actionType = extractParameter(PARAMETERS_ACTION_TYPE, arguments, parameters); Integer replyCommentId = extractParameter(PARAMETERS_REPLY_COMMENT_ID, arguments, parameters); String content = extractParameter(PARAMETERS_CONTENT, arguments, parameters); MessageTypeEnum messageTypeEnum = recordUserMessage.messageType(); if (UserActionTypeEnum.VIDEO_COLLECT.getType().equals(actionType)) { messageTypeEnum = MessageTypeEnum.COLLECTION; } TokenUserInfoDto userInfo = getTokenUserInfoDto(); userMessageService.saveUserMessage( videoId, userInfo == null ? null : userInfo.getUserId(), messageTypeEnum, content, replyCommentId ); } 参数提取技巧：通过参数名匹配（依赖编译时保留参数名），支持多种参数类型 3. 用户信息获取 1 2 3 4 5 6 private TokenUserInfoDto getTokenUserInfoDto() { HttpServletRequest request = ((ServletRequestAttributes) RequestContextHolder.getRequestAttributes()).getRequest(); String token = request.getHeader(Constants.TOKEN_WEB); return redisComponent.getTokenInfo(token); } 三、工作流程分析 方法被调用 → 切面拦截 → 执行业务逻辑 → 提取参数/用户信息 → 保存消息通知 四、关键实现细节 1. 参数名匹配机制 1 2 3 4 5 6 7 8 private \u0026lt;T\u0026gt; T extractParameter(String paramName, Object[] args, Parameter[] params) { for (int i = 0; i \u0026lt; params.length; i++) { if (paramName.equals(params[i].getName())) { return (T) args[i]; } } return null; } 需编译时保留参数名（-parameters编译选项） 实际代码应添加类型安全检查 2. 消息类型动态判断 1 2 3 if (UserActionTypeEnum.VIDEO_COLLECT.getType().equals(actionType)) { messageTypeEnum = MessageTypeEnum.COLLECTION; } 允许通过注解指定默认类型，也可根据运行时条件调整类型 3. 异常处理策略 1 2 3 4 5 6 7 8 9 try { // 业务逻辑 } catch (BusinessException e) { log.error(\u0026#34;全局拦截器异常\u0026#34;, e); throw e; } catch (Throwable e) { log.error(\u0026#34;全局拦截器异常\u0026#34;, e); throw new BusinessException(ResponseCodeEnum.CODE_500); } 区分业务异常和系统异常，统一错误处理 五、使用示例 1. 基础用法 1 2 3 4 5 @RecordUserMessage(messageType = MessageTypeEnum.LIKE) public ResponseVO likeVideo(String videoId) { // 点赞逻辑 return success(); } 2. 带参数自动提取 1 2 3 4 5 6 7 8 @RecordUserMessage(messageType = MessageTypeEnum.COMMENT) public ResponseVO addComment( @RequestParam String videoId, @RequestParam String content, @RequestParam(required = false) Integer replyCommentId) { // 评论逻辑 return success(); } 切面将自动提取 videoId、content、replyCommentId 用于构建消息记录 六、设计优势 低侵入性：业务代码只需添加注解 集中管理：所有消息记录逻辑在切面中维护 灵活扩展：轻松支持新的消息类型 自动关联：自动关联操作内容和用户信息 一致处理：统一的消息记录方式和错误处理 七、潜在优化方向 性能优化 1 2 3 4 5 6 7 8 // 缓存方法参数索引 private static class MethodParamCache { String videoIdParam; String actionTypeParam; int videoIdIndex = -1; int actionTypeIndex = -1; } private static ConcurrentMap\u0026lt;Method, MethodParamCache\u0026gt; paramCache = new ConcurrentHashMap\u0026lt;\u0026gt;(); 异步处理 1 2 3 4 @Async public void asyncSaveUserMessage(...) { // 异步保存消息 } 更智能的参数提取 1 2 3 4 5 6 // 通过注解标记重要参数 public ResponseVO addComment( @MessageParam(\u0026#34;videoId\u0026#34;) String videoId, @MessageParam(\u0026#34;content\u0026#34;) String content) { // ... } 消息内容模板化 1 2 message.template.like={user}点赞了你的视频 message.template.comment={user}评论了你的视频: {content} 八、与其他方案的对比 方案 优点 缺点 AOP注解 解耦、灵活、易扩展 学习曲线稍高 手动调用 直观、简单 代码重复、易遗漏 事件驱动 完全解耦、异步友好 复杂度高、调试困难 拦截器 执行时机早 难以获取业务参数 该AOP实现方案在灵活性和易用性之间取得良好平衡，适合多业务操作的消息通知场景。 实战AOP时需要重点关注的方面 一、切面设计与实现要点 注解设计规范 1 2 3 4 5 @Target({ElementType.METHOD, ElementType.TYPE}) @Retention(RetentionPolicy.RUNTIME) public @interface RecordUserMessage { MessageTypeEnum messageType(); } 确保 @Retention(RetentionPolicy.RUNTIME) 可考虑设置默认值 属性命名要清晰表达业务意图 切面作用范围控制 1 @Around(\u0026#34;@annotation(com.easylive.annotation.RecordUserMessage)\u0026#34;) 精确限定切点表达式，避免拦截不需要的方法 可用 within() 限定包路径 二、参数处理关键点 参数名匹配机制 1 2 3 4 5 6 7 8 private void saveUserMessage(..., Object[] arguments, Parameter[] parameters) { for (int i = 0; i \u0026lt; parameters.length; i++) { if (PARAMETERS_VIDEO_ID.equals(parameters[i].getName())) { videoId = (String) arguments[i]; } //...其他参数 } } 编译时保留参数名（-parameters） 添加类型检查，避免类型转换异常 可用ConcurrentHashMap缓存参数索引提升性能 敏感参数处理 对content等参数进行脱敏处理 大文本内容可截断后存入消息记录 三、异常处理策略 异常分类处理 1 2 3 4 5 6 7 8 9 try { //... } catch (BusinessException e) { log.error(\u0026#34;全局拦截器异常\u0026#34;, e); throw e; } catch (Exception e) { log.error(\u0026#34;全局拦截器异常\u0026#34;, e); throw new BusinessException(ResponseCodeEnum.CODE_500); } 区分业务异常和系统异常，避免吞没原始异常堆栈 可添加错误码转换逻辑 事务边界注意 切面在方法执行后记录消息，若方法有事务： 确保消息记录与业务操作在同一事务（@Transactional） 或明确分离事务（异步记录消息） 四、性能优化方向 反射操作优化 缓存Method对象和参数索引 可用Spring的CacheableOperation机制 异步处理考虑 1 2 3 4 @Async public void asyncSaveUserMessage(...) { userMessageService.saveUserMessage(...); } 适用于对实时性要求不高或高并发场景 五、安全注意事项 用户信息获取 1 2 3 4 5 6 private TokenUserInfoDto getTokenUserInfoDto() { HttpServletRequest request = ((ServletRequestAttributes) RequestContextHolder.getRequestAttributes()).getRequest(); String token = request.getHeader(Constants.TOKEN_WEB); return redisComponent.getTokenInfo(token); } 验证token有效性（是否过期、是否被撤销） 敏感操作可二次验证 权限校验补充 可在切面中添加基础权限校验，与Spring Security集成 六、可维护性设计 消息类型扩展 1 2 3 if (UserActionTypeEnum.VIDEO_COLLECT.getType().equals(actionType)) { messageTypeEnum = MessageTypeEnum.COLLECTION; } 可用策略模式处理不同类型消息的构建 配置化消息模板 日志记录规范 添加操作流水号，记录详细上下文信息 七、与其他组件的协作 与拦截器的分工 拦截器处理通用校验（登录、基础参数） AOP处理业务相关横切逻辑（如消息记录） 与事务的配合 注意@Transactional和@Around的执行顺序 可用@Order注解明确控制 八、测试相关建议 切面单元测试 模拟各种参数组合，测试异常场景，验证消息记录正确性 集成测试关注 多切面共存时的执行顺序，高并发下线程安全，与事务的交互 九、您的实现亮点 职责划分清晰，消息记录与业务解耦 灵活类型判断，actionType动态调整消息类型 完善异常处理，区分业务/系统异常 上下文信息自动获取 十、总结 Checklist ✅ 注解保留策略正确 ✅ 切点表达式精确匹配目标方法 ✅ 参数名匹配考虑编译选项 ✅ 异常处理覆盖所有场景 ✅ 性能敏感操作有缓存机制 ✅ 事务边界明确划分 ✅ 安全校验充分 ✅ 日志追踪完善 ✅ 易于扩展新消息类型 ✅ 测试用例覆盖各种边界情况 通过关注这些关键点，可确保AOP实现既满足需求，又具备良好可维护性和扩展性。\n定时任务-每日数据统计和临时文件清理 一、系统功能概述 包含每日数据统计和临时文件清理两个核心定时任务 采用Spring Boot @Scheduled注解实现 任务职责分离，便于维护和扩展 二、每日数据统计任务 statisticsData() 执行时机：每天凌晨0点（0 0 0 * * ?） 主要流程： 从Redis获取昨日各视频播放量 关联视频与用户信息 按用户聚合播放量 统计粉丝、评论、互动等多维度数据 批量插入或更新统计结果到数据库 关键代码： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 @Scheduled(cron = \u0026#34;0 0 0 * * ?\u0026#34;) public void statisticsData() { // 1. 准备数据结构 List\u0026lt;StatisticsInfo\u0026gt; statisticsInfoList = new ArrayList\u0026lt;\u0026gt;(); final String statisticsDate = DateUtil.getBeforeDayDate(1); // 昨天日期 // 2. 播放量统计（Redis → DB） Map\u0026lt;String, Integer\u0026gt; videoPlayCountMap = redisComponent.getVideoPlayCount(statisticsDate); List\u0026lt;String\u0026gt; playVideoKeys = videoPlayCountMap.keySet().stream() .map(item -\u0026gt; item.substring(item.lastIndexOf(\u0026#34;:\u0026#34;) + 1)) .collect(Collectors.toList()); VideoInfoQuery query = new VideoInfoQuery(); query.setVideoIdArray(playVideoKeys.toArray(new String[0])); List\u0026lt;VideoInfo\u0026gt; videoInfoList = videoInfoMapper.selectList(query); Map\u0026lt;String, Integer\u0026gt; videoCountMap = videoInfoList.stream() .collect(Collectors.groupingBy( VideoInfo::getUserId, Collectors.summingInt(item -\u0026gt; { String redisKey = Constants.REDIS_KEY_VIDEO_PLAY_COUNT + statisticsDate + \u0026#34;:\u0026#34; + item.getVideoId(); Integer count = videoPlayCountMap.get(redisKey); return count == null ? 0 : count; }) )); videoCountMap.forEach((userId, count) -\u0026gt; { StatisticsInfo info = new StatisticsInfo(); info.setStatisticsDate(statisticsDate); info.setUserId(userId); info.setDataType(StatisticsTypeEnum.PLAY.getType()); info.setStatisticsCount(count); statisticsInfoList.add(info); }); addFansData(statisticsDate, statisticsInfoList); addCommentData(statisticsDate, statisticsInfoList); addInteractionData(statisticsDate, statisticsInfoList); statisticsInfoMapper.insertOrUpdateBatch(statisticsInfoList); } 技术要点： 高频数据先写入Redis，定时批量同步到DB 多维度统计，便于后续扩展 批量操作减少数据库压力 代码结构与聚合逻辑解析 按用户ID分组统计所有视频的总播放量： 1 2 3 4 5 6 7 8 9 Map\u0026lt;String, Integer\u0026gt; videoCountMap = videoInfoList.stream() .collect(Collectors.groupingBy( VideoInfo::getUserId, Collectors.summingInt(item -\u0026gt; { String redisKey = Constants.REDIS_KEY_VIDEO_PLAY_COUNT + statisticsDate + \u0026#34;:\u0026#34; + item.getVideoId(); Integer count = videoPlayCountMap.get(redisKey); return count == null ? 0 : count; }) )); 设计优势： 单次遍历完成分组与求和，效率高 逻辑清晰，易于维护和扩展 可通过parallelStream并行处理大数据量 三、临时文件清理任务 delTempFile() 执行时机：每分钟执行一次（0 */1 * * * ?） 主要流程： 构建临时文件夹路径 获取两天前的日期作为基准 遍历临时文件夹，按日期命名规则清理旧文件 捕获异常，保证任务健壮性 关键代码： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 @Scheduled(cron = \u0026#34;0 */1 * * * ?\u0026#34;) public void delTempFile() { String tempFolder = appConfig.getProjectFolder() + Constants.FILE_FOLDER + Constants.FILE_FOLDER_TEMP; String twodaysAgo = DateUtil.format(DateUtil.getDayAgo(2), \u0026#34;yyyyMMdd\u0026#34;); Integer thresholdDate = Integer.parseInt(twodaysAgo); File folder = new File(tempFolder); File[] files = folder.listFiles(); if (files == null) return; for (File file : files) { try { Integer fileDate = Integer.parseInt(file.getName()); if (fileDate \u0026lt;= thresholdDate) { FileUtils.deleteDirectory(file); } } catch (Exception e) { log.error(\u0026#34;删除临时文件失败\u0026#34;, e); } } } 设计要点： 文件名强制使用日期格式，防止误删 只处理命名合规的文件夹 异常捕获，保证单次失败不影响后续 高频检查但低负载，适合定时清理 四、架构设计亮点 统计服务与业务逻辑解耦，便于维护 文件清理与业务模块隔离，提升安全性 实时数据写入Redis，定时同步DB，兼顾性能与一致性 新增统计维度或清理策略易于扩展 五、潜在优化建议 统计任务可分片处理，适应大用户量 1 2 3 4 @Scheduled(cron = \u0026#34;0 0 1 * * ?\u0026#34;) public void statsUserShard1() { statisticsService.processByUserRange(0, 10000); } 文件清理可增加文件大小监控 1 2 3 if (file.length() \u0026gt; MAX_TEMP_FILE_SIZE) { alertService.notifyOversizeFile(file); } 统计任务异常处理强化，支持延迟重试 1 2 3 4 5 6 7 8 9 @Scheduled(...) public void safeStatistics() { try { statisticsData(); } catch (Exception e) { log.error(\u0026#34;统计任务失败\u0026#34;, e); retryLater(); } } Gateway 路由分配与接口调用机制 一、Gateway 路由分配原理 路由匹配流程： 请求到达网关（如7071端口），Gateway遍历所有路由规则（routes），按predicates条件匹配 示例路由配置： 1 2 3 4 5 6 - id: video uri: lb://easylive-cloud-web # 目标服务名（通过Nacos发现） predicates: - Path=/web/** # 路径匹配规则 filters: - StripPrefix=1 # 去除前缀\u0026#34;/web\u0026#34; 匹配逻辑： localhost:7071/web/test → 匹配Path=/web/** → 转发到easylive-cloud-web服务的/test接口 Nacos服务发现： easylive-cloud-web已在Nacos注册（如7072端口），网关通过lb://前缀从Nacos获取服务实例列表 若有多个实例，Ribbon会轮询选择目标节点 二、接口访问路径差异解析 访问方式与调用链路： localhost:7072/test：直接访问easylive-cloud-web服务，绕过网关，直连服务端口 localhost:7071/web/test：网关路由 → easylive-cloud-web:/test，Gateway的StripPrefix=1生效 关键区别： 网关路径需携带/web前缀（用于路由匹配），实际转发时会剥离 直连服务路径无前缀，但会暴露服务端口（不符合微服务最佳实践） 三、负载均衡实例演示 场景准备： 启动两个easylive-cloud-web实例（端口7072和7073） Nacos服务列表： 1 2 3 easylive-cloud-web: - InstanceA: 127.0.0.1:7072 - InstanceB: 127.0.0.1:7073 请求分发过程： 连续调用localhost:7071/web/test时： 第一次请求 → 转发到InstanceA:7072/test 第二次请求 → 转发到InstanceB:7073/test 第三次请求 → 再次转到InstanceA（默认轮询策略） 底层机制： 1 2 3 4 // Gateway通过Ribbon实现负载均衡 LoadBalancerClient client = SpringContext.getBean(LoadBalancerClient.class); ServiceInstance instance = client.choose(\u0026#34;easylive-cloud-web\u0026#34;); // 返回的实例会轮询变化 四、完整调用链路示例 请求示例： 1 GET http://localhost:7071/web/api/videos/1 网关处理流程： 匹配路由id:video → 剥离/web前缀 → 目标路径变为/api/videos/1 从Nacos获取easylive-cloud-web实例地址（如127.0.0.1:7072） 最终转发请求： 1 GET http://127.0.0.1:7072/api/videos/1 - 服务响应数据通过网关原路返回 总结： 网关路由：通过Path谓词匹配 + StripPrefix过滤实现路径转换 服务发现：依赖Nacos维护动态服务实例列表 负载均衡：由Ribbon自动处理多实例轮询 访问差异：网关路径需保留路由前缀，但实际转发时会被剥离 这种架构既保证了接口调用的灵活性，又隐藏了后端服务细节，符合微服务设计原则 五、网关工作原理 网关如同小区快递驿站，easylive-cloud-web是具体住户 所有请求（快递）先到驿站（网关），由驿站决定送到哪户 路由配置： 1 2 3 4 5 6 7 8 9 10 11 12 server: port: 7071 # 驿站门牌号 feign: okhttp: enabled: true # 智能分拣机 routes: - id: video uri: lb://easylive-cloud-web predicates: - Path=/web/** filters: - StripPrefix=1 工作流程： 快递员送来/web/test，驿站识别后剥离/web，送到/test 直接访问7072端口如同快递员绕开驿站，直送住户，不规范 通过网关7071端口，享受统一管理、鉴权、限流等服务 负载均衡： 多个实例如同双胞胎，驿站轮流分配快递，确保均衡 核心优势： 统一管理，安全可控 灵活扩展，实例自动识别 故障隔离，实例宕机自动切换 AdminFilter 详细解析 一、类定义与基础结构 AdminFilter 是 Spring Cloud Gateway 的过滤器，用于请求到达微服务前进行权限校验（如管理员 Token 验证） 主要结构： 1 2 3 4 5 @Component @Slf4j public class AdminFilter extends AbstractGatewayFilterFactory { // ... } - @Component：声明为 Spring Bean，由 Spring 管理 - @Slf4j：集成 Lombok，提供日志功能 - AbstractGatewayFilterFactory：自定义路由过滤逻辑的基类 二、常量定义 1 2 private final static String URL_ACCOUNT = \u0026#34;/account\u0026#34;; private final static String URL_FILE = \u0026#34;/file\u0026#34;; URL_ACCOUNT：放行路径，访问 /account 的请求无需 Token（如登录、注册接口） URL_FILE：文件相关接口从 Cookie 中提取 Token 三、核心过滤逻辑（apply方法） 1 2 3 4 5 6 7 @Override public GatewayFilter apply(Object config) { return (exchange, chain) -\u0026gt; { ServerHttpRequest request = exchange.getRequest(); // ... }; } apply：覆盖父类方法，返回 GatewayFilter 实例 exchange：封装 HTTP 请求和响应上下文 chain：过滤器链，chain.filter(exchange) 继续后续过滤或路由 1. 路径判断与 Token 提取 放行 /account 路径： 1 2 3 if (request.getURI().getRawPath().contains(URL_ACCOUNT)) { return chain.filter(exchange); // 直接放行 } 文件接口从 Cookie 取 Token： 1 2 3 if (request.getURI().getRawPath().contains(URL_FILE)) { token = getTokenFromCookie(request); } 默认从 Header 取 Token： 1 String token = getToken(request); 2. Token 校验 1 2 3 if (StringTools.isEmpty(token)) { throw new BusinessException(ResponseCodeEnum.CODE_901); // 无权限 } Token 为空抛出业务异常（如 CODE_901 表示未登录/Token 无效） Token 有效则继续后续逻辑 四、Token 提取方法 从 Header 获取： 1 2 3 private String getToken(ServerHttpRequest request) { return request.getHeaders().getFirst(Constants.TOKEN_ADMIN); } 从 Cookie 获取： 1 2 3 private String getTokenFromCookie(ServerHttpRequest request) { return request.getCookies().getFirst(Constants.TOKEN_ADMIN).getValue(); } 五、设计思想与使用场景 职责分离：权限校验逻辑集中在网关层，避免每个微服务重复实现 灵活提取 Token：支持 Header 和 Cookie 两种方式，适配 API 调用和浏览器文件下载 白名单路径：/account 路径免校验，确保登录/注册接口可访问 异常处理：直接抛出业务异常，由网关统一转换为 HTTP 响应（如 401 Unauthorized） 典型使用场景 管理员访问用户列表： 1 2 GET /admin/users HTTP/1.1 X-Admin-Token: valid_token_here - 网关检查路径不匹配 /account 或 /file，从 Header 提取 Token，校验通过转发 用户下载文件： 1 2 GET /file/download/1 HTTP/1.1 Cookie: ADMIN_TOKEN=valid_token_here - 网关识别路径包含 /file，从 Cookie 提取 Token，校验通过转发 未携带 Token 的请求： 1 GET /admin/users HTTP/1.1 - 抛出 CODE_901 异常，返回 401 Unauthorized 使用Seata解决分布式事务问题 一、为什么@Transactional在跨服务调用时不生效 @Transactional 只能管理当前服务的数据库连接，无法控制远程服务的事务 典型场景： 1 2 3 4 // 本地数据库操作（可被@Transactional管理） videoCommentMapper.insert(comment); // 跨服务调用（不受@Transactional控制） videoClient.updateCountInfo(comment.getVideoId(), ...); 问题根源： 事务隔离性：@Transactional 仅作用于本地数据库连接 跨服务调用（如HTTP/Feign）属于独立事务，无法自动回滚 两阶段问题：本地insert成功后，远程调用失败时本地无法回滚 CAP理论：跨服务操作涉及网络分区，传统事务无法保证CP 生活化比喻： 商家（服务A）确认发货（本地事务提交） 快递（服务B）丢件（远程调用失败） 没有平台（Seata）协调时，钱货两失 二、Seata解决方案全流程 第一步：启动Seata服务 下载Seata Server（1.6.1+） 配置注册中心（如Nacos）： 1 2 3 4 5 6 7 registry { type = \u0026#34;nacos\u0026#34; nacos { serverAddr = \u0026#34;127.0.0.1:8848\u0026#34; namespace = \u0026#34;你的命名空间\u0026#34; # 可选 } } - 启动命令：bin/seata-server.sh -p 8091 -h 127.0.0.1 第二步：数据库准备 每个业务库执行undo_log表建表SQL： 1 2 3 4 5 6 7 8 9 10 11 12 CREATE TABLE IF NOT EXISTS `undo_log` ( `id` bigint(20) NOT NULL AUTO_INCREMENT, `branch_id` bigint(20) NOT NULL, `xid` varchar(100) NOT NULL, `context` varchar(128) NOT NULL, `rollback_info` longblob NOT NULL, `log_status` int(11) NOT NULL, `log_created` datetime NOT NULL, `log_modified` datetime NOT NULL, PRIMARY KEY (`id`), UNIQUE KEY `ux_undo_log` (`xid`,`branch_id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8; - Seata Server独立库需建global_table、branch_table、lock_table等 第三步：项目配置 添加依赖： 1 2 3 4 5 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alibaba.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-alibaba-seata\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.2.6.RELEASE\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; - Nacos配置示例： 1 2 3 4 5 6 7 8 9 10 11 12 spring: cloud: alibaba: seata: tx-service-group: video-service-group seata: registry: type: nacos nacos: server-addr: 127.0.0.1:8848 config: type: nacos 第四步：代码改造 在业务方法上添加@GlobalTransactional 1 2 3 4 5 6 7 8 9 10 11 @GlobalTransactional( rollbackFor = Exception.class, // 所有异常都回滚 timeoutMills = 60000, // 超时时间（毫秒） name = \u0026#34;postCommentTx\u0026#34; // 全局事务名 ) public void postComment(VideoComment comment, Integer replyCommentId) { // 原业务逻辑不变 // Seata会自动拦截以下操作： // 1. videoCommentMapper.insert() // 2. videoClient.updateCountInfo() } 关键机制： 事务ID传播：Seata通过XID（全局事务ID）串联各服务，自动通过Feign请求头传递seata_xid 二阶段提交： 第一阶段：Prepare 第二阶段：Commit/Rollback 回滚原理：undo_log表记录回滚日志，失败时自动补偿 三、验证与排查技巧 查看Seata控制台（如http://127.0.0.1:7091），检查事务列表 强制触发异常，观察本地表是否回滚 1 2 3 4 // 在updateCountInfo()中模拟失败 if (Math.random() \u0026gt; 0.5) { throw new RuntimeException(\u0026#34;模拟远程调用失败\u0026#34;); } 常见问题： No available service for cluster：事务组名不匹配，检查tx-service-group一致性 Could not register branch：数据库未建undo_log，需执行建表SQL 回滚失效：方法内捕获异常，需确保异常抛出到@GlobalTransactional层 四、生活化总结 Seata就像跨国贸易的支付宝： 买家付款（本地事务）→ 资金暂存平台（Phase1） 卖家发货（远程调用）→ 平台监控物流（Phase1） 确认收货后双方结算（Phase2 Commit） 卖家不发货，平台退款（Phase2 Rollback） 通过Seata，postComment方法实现全自动保险，评论数据和计数更新要么全部成功，要么全部回滚 五、典型代码示例 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 @Override @GlobalTransactional(name = \u0026#34;postCommentTx\u0026#34;, rollbackFor = Exception.class) public void postComment(VideoComment comment, Integer replyCommentId) { // 1. 获取视频信息 VideoInfo videoInfo = videoClient.getVideoInfoByVideoId(comment.getVideoId()); if (videoInfo == null) { throw new BusinessException(ResponseCodeEnum.CODE_600); } // 2. 检查评论是否关闭 if (videoInfo.getInteraction() != null \u0026amp;\u0026amp; videoInfo.getInteraction().contains(Constants.ZERO.toString())) { throw new BusinessException(\u0026#34;UP主已关闭评论区\u0026#34;); } // 3. 处理回复评论逻辑 if (replyCommentId != null) { VideoComment replyComment = getVideoCommentByCommentId(replyCommentId); if (replyComment == null || !replyComment.getVideoId().equals(comment.getVideoId())) { throw new BusinessException(ResponseCodeEnum.CODE_600); } if (replyComment.getpCommentId() == 0) { comment.setpCommentId(replyComment.getCommentId()); } else { comment.setpCommentId(replyComment.getpCommentId()); comment.setReplyUserId(replyComment.getUserId()); } UserInfo userInfo = videoClient.getUserInfoByUserId(replyComment.getUserId()); comment.setReplyNickName(userInfo.getNickName()); comment.setReplyAvatar(userInfo.getAvatar()); } else { comment.setpCommentId(0); } // 4. 设置评论信息 comment.setPostTime(new Date()); comment.setVideoUserId(videoInfo.getUserId()); // 5. 插入评论 this.videoCommentMapper.insert(comment); // 6. 更新评论计数 if (comment.getpCommentId() == 0) { this.videoClient.updateCountInfo(comment.getVideoId(), UserActionTypeEnum.VIDEO_COMMENT.getField(), 1); } } \u0026lt;/rewritten_file\u0026gt;\n","date":"2024-11-15T17:19:37+08:00","image":"http://localhost:1313/p/%E5%BC%B9%E5%B9%95%E8%A7%86%E9%A2%91%E7%BD%91%E7%AB%99%E7%AC%94%E8%AE%B0/bg_hu_7018b2065dc4a2e1.png","permalink":"http://localhost:1313/p/%E5%BC%B9%E5%B9%95%E8%A7%86%E9%A2%91%E7%BD%91%E7%AB%99%E7%AC%94%E8%AE%B0/","title":"弹幕视频网站笔记"}]